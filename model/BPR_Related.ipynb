{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbf1bbef",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Import library and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e933a87",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3f75fcd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Send Rates</th>\n",
       "      <th>Block Size</th>\n",
       "      <th>Avg Latency</th>\n",
       "      <th>Throughput</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.33</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.85</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>30</td>\n",
       "      <td>1.19</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.22</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>50</td>\n",
       "      <td>1.18</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>200.5</td>\n",
       "      <td>160</td>\n",
       "      <td>1.35</td>\n",
       "      <td>160.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>187.5</td>\n",
       "      <td>170</td>\n",
       "      <td>2.17</td>\n",
       "      <td>158.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>198.9</td>\n",
       "      <td>180</td>\n",
       "      <td>1.31</td>\n",
       "      <td>163.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>197.0</td>\n",
       "      <td>190</td>\n",
       "      <td>1.65</td>\n",
       "      <td>163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>198.3</td>\n",
       "      <td>200</td>\n",
       "      <td>1.63</td>\n",
       "      <td>161.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Send Rates  Block Size  Avg Latency  Throughput\n",
       "0          10.0          10         0.33        10.0\n",
       "1          10.0          20         0.85        10.0\n",
       "2          10.0          30         1.19        10.0\n",
       "3          10.0          40         1.22         9.8\n",
       "4          10.0          50         1.18        10.0\n",
       "..          ...         ...          ...         ...\n",
       "395       200.5         160         1.35       160.8\n",
       "396       187.5         170         2.17       158.4\n",
       "397       198.9         180         1.31       163.5\n",
       "398       197.0         190         1.65       163.0\n",
       "399       198.3         200         1.63       161.6\n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../Data/BPD_related1.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87cc3a5c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10.  ,  10.  ,   0.33,  10.  ],\n",
       "       [ 10.  ,  20.  ,   0.85,  10.  ],\n",
       "       [ 10.  ,  30.  ,   1.19,  10.  ],\n",
       "       ...,\n",
       "       [198.9 , 180.  ,   1.31, 163.5 ],\n",
       "       [197.  , 190.  ,   1.65, 163.  ],\n",
       "       [198.3 , 200.  ,   1.63, 161.6 ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy = df.values\n",
    "xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dea8c34",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0efe76e5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x225b19999f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set random seed\n",
    "seed = 42\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edae8d8c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Read raw data and divide training set and test set\n",
    "raw_data = xy\n",
    "X = raw_data[:, :2]\n",
    "Y1 = raw_data[:, -2:-1]\n",
    "Y2 = raw_data[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34886bb7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10. ,  10. ],\n",
       "       [ 10. ,  20. ],\n",
       "       [ 10. ,  30. ],\n",
       "       [ 10. ,  40. ],\n",
       "       [ 10. ,  50. ],\n",
       "       [ 10. ,  60. ],\n",
       "       [ 10. ,  70. ],\n",
       "       [ 10. ,  80. ],\n",
       "       [ 10. ,  90. ],\n",
       "       [ 10.1, 100. ],\n",
       "       [ 10. , 110. ],\n",
       "       [ 10. , 120. ],\n",
       "       [ 10. , 130. ],\n",
       "       [ 10. , 140. ],\n",
       "       [ 10. , 150. ],\n",
       "       [ 10. , 160. ],\n",
       "       [ 10. , 170. ],\n",
       "       [ 10. , 180. ],\n",
       "       [ 10. , 190. ],\n",
       "       [ 10. , 200. ],\n",
       "       [ 20.1,  10. ],\n",
       "       [ 20.1,  20. ],\n",
       "       [ 20.1,  30. ],\n",
       "       [ 20.1,  40. ],\n",
       "       [ 20.1,  50. ],\n",
       "       [ 20.1,  60. ],\n",
       "       [ 20.1,  70. ],\n",
       "       [ 20.1,  80. ],\n",
       "       [ 20.1,  90. ],\n",
       "       [ 20.1, 100. ],\n",
       "       [ 20.1, 110. ],\n",
       "       [ 20.1, 120. ],\n",
       "       [ 20.1, 130. ],\n",
       "       [ 20.1, 140. ],\n",
       "       [ 20.1, 150. ],\n",
       "       [ 20.1, 160. ],\n",
       "       [ 20.1, 170. ],\n",
       "       [ 20.1, 180. ],\n",
       "       [ 20.1, 190. ],\n",
       "       [ 20.1, 200. ],\n",
       "       [ 30.1,  10. ],\n",
       "       [ 30.1,  20. ],\n",
       "       [ 30.1,  30. ],\n",
       "       [ 30.2,  40. ],\n",
       "       [ 30.1,  50. ],\n",
       "       [ 30.2,  60. ],\n",
       "       [ 30.1,  70. ],\n",
       "       [ 30.1,  80. ],\n",
       "       [ 30.1,  90. ],\n",
       "       [ 30.1, 100. ],\n",
       "       [ 30.2, 110. ],\n",
       "       [ 30.1, 120. ],\n",
       "       [ 30.2, 130. ],\n",
       "       [ 30.1, 140. ],\n",
       "       [ 30.1, 150. ],\n",
       "       [ 30.1, 160. ],\n",
       "       [ 30.1, 170. ],\n",
       "       [ 30.1, 180. ],\n",
       "       [ 30.1, 190. ],\n",
       "       [ 30.1, 200. ],\n",
       "       [ 40.2,  10. ],\n",
       "       [ 40.2,  20. ],\n",
       "       [ 40.2,  30. ],\n",
       "       [ 40.2,  40. ],\n",
       "       [ 40.2,  50. ],\n",
       "       [ 40.2,  60. ],\n",
       "       [ 40.2,  70. ],\n",
       "       [ 40.2,  80. ],\n",
       "       [ 40.2,  90. ],\n",
       "       [ 40.2, 100. ],\n",
       "       [ 40.2, 110. ],\n",
       "       [ 40.2, 120. ],\n",
       "       [ 40.2, 130. ],\n",
       "       [ 40.2, 140. ],\n",
       "       [ 40.2, 150. ],\n",
       "       [ 40.2, 160. ],\n",
       "       [ 40.2, 170. ],\n",
       "       [ 40.2, 180. ],\n",
       "       [ 40.2, 190. ],\n",
       "       [ 40.2, 200. ],\n",
       "       [ 50.2,  10. ],\n",
       "       [ 50.2,  20. ],\n",
       "       [ 50.2,  30. ],\n",
       "       [ 50.2,  40. ],\n",
       "       [ 50.2,  50. ],\n",
       "       [ 50.2,  60. ],\n",
       "       [ 50.2,  70. ],\n",
       "       [ 50.2,  80. ],\n",
       "       [ 50.2,  90. ],\n",
       "       [ 50.2, 100. ],\n",
       "       [ 50.2, 110. ],\n",
       "       [ 50.2, 120. ],\n",
       "       [ 50.3, 130. ],\n",
       "       [ 50.2, 140. ],\n",
       "       [ 50.2, 150. ],\n",
       "       [ 50.2, 160. ],\n",
       "       [ 50.2, 170. ],\n",
       "       [ 50.2, 180. ],\n",
       "       [ 50.2, 190. ],\n",
       "       [ 50.2, 200. ],\n",
       "       [ 60.2,  10. ],\n",
       "       [ 60.3,  20. ],\n",
       "       [ 60.3,  30. ],\n",
       "       [ 60.2,  40. ],\n",
       "       [ 60.3,  50. ],\n",
       "       [ 60.3,  60. ],\n",
       "       [ 60.3,  70. ],\n",
       "       [ 60.3,  80. ],\n",
       "       [ 60.3,  90. ],\n",
       "       [ 60.3, 100. ],\n",
       "       [ 60.2, 110. ],\n",
       "       [ 60.3, 120. ],\n",
       "       [ 60.3, 130. ],\n",
       "       [ 60.3, 140. ],\n",
       "       [ 60.2, 150. ],\n",
       "       [ 60.3, 160. ],\n",
       "       [ 60.3, 170. ],\n",
       "       [ 60.3, 180. ],\n",
       "       [ 60.3, 190. ],\n",
       "       [ 60.3, 200. ],\n",
       "       [ 70.3,  10. ],\n",
       "       [ 70.3,  20. ],\n",
       "       [ 70.3,  30. ],\n",
       "       [ 70.2,  40. ],\n",
       "       [ 70.3,  50. ],\n",
       "       [ 70.2,  60. ],\n",
       "       [ 70.4,  70. ],\n",
       "       [ 70.4,  80. ],\n",
       "       [ 70.3,  90. ],\n",
       "       [ 70.3, 100. ],\n",
       "       [ 70.3, 110. ],\n",
       "       [ 70.3, 120. ],\n",
       "       [ 70.2, 130. ],\n",
       "       [ 70.3, 140. ],\n",
       "       [ 70.2, 150. ],\n",
       "       [ 70.3, 160. ],\n",
       "       [ 70.3, 170. ],\n",
       "       [ 70.2, 180. ],\n",
       "       [ 70.3, 190. ],\n",
       "       [ 70.3, 200. ],\n",
       "       [ 80.4,  10. ],\n",
       "       [ 80.5,  20. ],\n",
       "       [ 80.3,  30. ],\n",
       "       [ 80.4,  40. ],\n",
       "       [ 80.4,  50. ],\n",
       "       [ 80.4,  60. ],\n",
       "       [ 80.3,  70. ],\n",
       "       [ 80.4,  80. ],\n",
       "       [ 80.3,  90. ],\n",
       "       [ 80.2, 100. ],\n",
       "       [ 80.4, 110. ],\n",
       "       [ 80.3, 120. ],\n",
       "       [ 80.4, 130. ],\n",
       "       [ 80.3, 140. ],\n",
       "       [ 80.2, 150. ],\n",
       "       [ 80.2, 160. ],\n",
       "       [ 80.3, 170. ],\n",
       "       [ 80.4, 180. ],\n",
       "       [ 80.2, 190. ],\n",
       "       [ 80.3, 200. ],\n",
       "       [ 90.2,  10. ],\n",
       "       [ 90.4,  20. ],\n",
       "       [ 90.4,  30. ],\n",
       "       [ 90.4,  40. ],\n",
       "       [ 90.1,  50. ],\n",
       "       [ 90.4,  60. ],\n",
       "       [ 90.3,  70. ],\n",
       "       [ 90.4,  80. ],\n",
       "       [ 90.3,  90. ],\n",
       "       [ 90.4, 100. ],\n",
       "       [ 90.4, 110. ],\n",
       "       [ 90.4, 120. ],\n",
       "       [ 90.5, 130. ],\n",
       "       [ 90.3, 140. ],\n",
       "       [ 90.4, 150. ],\n",
       "       [ 90.3, 160. ],\n",
       "       [ 90.4, 170. ],\n",
       "       [ 90.4, 180. ],\n",
       "       [ 90.3, 190. ],\n",
       "       [ 90.3, 200. ],\n",
       "       [100.3,  10. ],\n",
       "       [100.5,  20. ],\n",
       "       [100.5,  30. ],\n",
       "       [100. ,  40. ],\n",
       "       [100.4,  50. ],\n",
       "       [100.4,  60. ],\n",
       "       [100.3,  70. ],\n",
       "       [100.4,  80. ],\n",
       "       [100.3,  90. ],\n",
       "       [100.4, 100. ],\n",
       "       [100.4, 110. ],\n",
       "       [100.4, 120. ],\n",
       "       [100.4, 130. ],\n",
       "       [100.3, 140. ],\n",
       "       [100.5, 150. ],\n",
       "       [100.5, 160. ],\n",
       "       [100.3, 170. ],\n",
       "       [100.4, 180. ],\n",
       "       [100.5, 190. ],\n",
       "       [100.4, 200. ],\n",
       "       [110.5,  10. ],\n",
       "       [110.2,  20. ],\n",
       "       [110.4,  30. ],\n",
       "       [110.6,  40. ],\n",
       "       [110.5,  50. ],\n",
       "       [110.5,  60. ],\n",
       "       [110.3,  70. ],\n",
       "       [110.6,  80. ],\n",
       "       [110.3,  90. ],\n",
       "       [110.4, 100. ],\n",
       "       [110.6, 110. ],\n",
       "       [110.3, 120. ],\n",
       "       [110.5, 130. ],\n",
       "       [110.3, 140. ],\n",
       "       [110.3, 150. ],\n",
       "       [110.6, 160. ],\n",
       "       [110.4, 170. ],\n",
       "       [110.4, 180. ],\n",
       "       [110.4, 190. ],\n",
       "       [110.2, 200. ],\n",
       "       [120.6,  10. ],\n",
       "       [120.5,  20. ],\n",
       "       [120.4,  30. ],\n",
       "       [120.4,  40. ],\n",
       "       [120.4,  50. ],\n",
       "       [120.6,  60. ],\n",
       "       [120.5,  70. ],\n",
       "       [120.5,  80. ],\n",
       "       [120.2,  90. ],\n",
       "       [120.4, 100. ],\n",
       "       [120.3, 110. ],\n",
       "       [120.5, 120. ],\n",
       "       [120.6, 130. ],\n",
       "       [120.6, 140. ],\n",
       "       [120.5, 150. ],\n",
       "       [120.4, 160. ],\n",
       "       [120.4, 170. ],\n",
       "       [120.5, 180. ],\n",
       "       [120.4, 190. ],\n",
       "       [120.2, 200. ],\n",
       "       [130.4,  10. ],\n",
       "       [130.1,  20. ],\n",
       "       [130.4,  30. ],\n",
       "       [130.8,  40. ],\n",
       "       [130.3,  50. ],\n",
       "       [130.6,  60. ],\n",
       "       [130.6,  70. ],\n",
       "       [130.5,  80. ],\n",
       "       [130.3,  90. ],\n",
       "       [130.6, 100. ],\n",
       "       [130.5, 110. ],\n",
       "       [130.5, 120. ],\n",
       "       [130.4, 130. ],\n",
       "       [130.6, 140. ],\n",
       "       [130.2, 150. ],\n",
       "       [130.5, 160. ],\n",
       "       [130.6, 170. ],\n",
       "       [130.2, 180. ],\n",
       "       [130.3, 190. ],\n",
       "       [130.5, 200. ],\n",
       "       [140.6,  10. ],\n",
       "       [140.7,  20. ],\n",
       "       [140.5,  30. ],\n",
       "       [140.5,  40. ],\n",
       "       [140.4,  50. ],\n",
       "       [140.5,  60. ],\n",
       "       [140.5,  70. ],\n",
       "       [140.5,  80. ],\n",
       "       [140.4,  90. ],\n",
       "       [140.2, 100. ],\n",
       "       [140.6, 110. ],\n",
       "       [140.6, 120. ],\n",
       "       [140.6, 130. ],\n",
       "       [140.4, 140. ],\n",
       "       [140.6, 150. ],\n",
       "       [140.6, 160. ],\n",
       "       [140.6, 170. ],\n",
       "       [140.5, 180. ],\n",
       "       [140.6, 190. ],\n",
       "       [140.6, 200. ],\n",
       "       [150.4,  10. ],\n",
       "       [150.7,  20. ],\n",
       "       [148.9,  30. ],\n",
       "       [149. ,  40. ],\n",
       "       [150.2,  50. ],\n",
       "       [150.1,  60. ],\n",
       "       [150.5,  70. ],\n",
       "       [150.4,  80. ],\n",
       "       [150.6,  90. ],\n",
       "       [150.4, 100. ],\n",
       "       [150.7, 110. ],\n",
       "       [150.1, 120. ],\n",
       "       [150.4, 130. ],\n",
       "       [150.7, 140. ],\n",
       "       [150.5, 150. ],\n",
       "       [150.7, 160. ],\n",
       "       [150.2, 170. ],\n",
       "       [150.6, 180. ],\n",
       "       [150.7, 190. ],\n",
       "       [150.2, 200. ],\n",
       "       [160.6,  10. ],\n",
       "       [160.6,  20. ],\n",
       "       [160.6,  30. ],\n",
       "       [160.6,  40. ],\n",
       "       [160.6,  50. ],\n",
       "       [160.5,  60. ],\n",
       "       [160.7,  70. ],\n",
       "       [160.1,  80. ],\n",
       "       [160.8,  90. ],\n",
       "       [160.2, 100. ],\n",
       "       [160.6, 110. ],\n",
       "       [160.5, 120. ],\n",
       "       [160.6, 130. ],\n",
       "       [160.1, 140. ],\n",
       "       [160.3, 150. ],\n",
       "       [159.8, 160. ],\n",
       "       [160.5, 170. ],\n",
       "       [160.6, 180. ],\n",
       "       [160.5, 190. ],\n",
       "       [160.6, 200. ],\n",
       "       [162.6,  10. ],\n",
       "       [167.2,  20. ],\n",
       "       [170.6,  30. ],\n",
       "       [170.4,  40. ],\n",
       "       [170.5,  50. ],\n",
       "       [170.5,  60. ],\n",
       "       [170.2,  70. ],\n",
       "       [170.9,  80. ],\n",
       "       [170.2,  90. ],\n",
       "       [170.3, 100. ],\n",
       "       [170.6, 110. ],\n",
       "       [170.6, 120. ],\n",
       "       [169.8, 130. ],\n",
       "       [170.4, 140. ],\n",
       "       [170.4, 150. ],\n",
       "       [170.8, 160. ],\n",
       "       [170.6, 170. ],\n",
       "       [170.5, 180. ],\n",
       "       [170.3, 190. ],\n",
       "       [170.3, 200. ],\n",
       "       [135.2,  10. ],\n",
       "       [175.9,  20. ],\n",
       "       [179. ,  30. ],\n",
       "       [157.2,  40. ],\n",
       "       [180.9,  50. ],\n",
       "       [180.8,  60. ],\n",
       "       [180.7,  70. ],\n",
       "       [180. ,  80. ],\n",
       "       [180.1,  90. ],\n",
       "       [180.7, 100. ],\n",
       "       [180. , 110. ],\n",
       "       [180.3, 120. ],\n",
       "       [180.1, 130. ],\n",
       "       [180.7, 140. ],\n",
       "       [175.4, 150. ],\n",
       "       [181. , 160. ],\n",
       "       [180.2, 170. ],\n",
       "       [181. , 180. ],\n",
       "       [180.3, 190. ],\n",
       "       [180.1, 200. ],\n",
       "       [178.6,  10. ],\n",
       "       [187.7,  20. ],\n",
       "       [179.1,  30. ],\n",
       "       [185. ,  40. ],\n",
       "       [185.5,  50. ],\n",
       "       [190.7,  60. ],\n",
       "       [190.3,  70. ],\n",
       "       [190.5,  80. ],\n",
       "       [188.8,  90. ],\n",
       "       [187.3, 100. ],\n",
       "       [189.8, 110. ],\n",
       "       [189.3, 120. ],\n",
       "       [190.5, 130. ],\n",
       "       [169.6, 140. ],\n",
       "       [146. , 150. ],\n",
       "       [189.3, 160. ],\n",
       "       [189.9, 170. ],\n",
       "       [190.4, 180. ],\n",
       "       [190.6, 190. ],\n",
       "       [189.6, 200. ],\n",
       "       [183.9,  10. ],\n",
       "       [185. ,  20. ],\n",
       "       [191.5,  30. ],\n",
       "       [175. ,  40. ],\n",
       "       [200.3,  50. ],\n",
       "       [200. ,  60. ],\n",
       "       [200.7,  70. ],\n",
       "       [200.2,  80. ],\n",
       "       [197.5,  90. ],\n",
       "       [193.6, 100. ],\n",
       "       [197.8, 110. ],\n",
       "       [197.6, 120. ],\n",
       "       [196.6, 130. ],\n",
       "       [200. , 140. ],\n",
       "       [190.2, 150. ],\n",
       "       [200.5, 160. ],\n",
       "       [187.5, 170. ],\n",
       "       [198.9, 180. ],\n",
       "       [197. , 190. ],\n",
       "       [198.3, 200. ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "650810a9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33],\n",
       "       [0.85],\n",
       "       [1.19],\n",
       "       [1.22],\n",
       "       [1.18],\n",
       "       [1.19],\n",
       "       [1.17],\n",
       "       [1.13],\n",
       "       [1.17],\n",
       "       [1.17],\n",
       "       [1.18],\n",
       "       [1.18],\n",
       "       [1.15],\n",
       "       [1.18],\n",
       "       [1.17],\n",
       "       [1.17],\n",
       "       [1.14],\n",
       "       [1.16],\n",
       "       [1.13],\n",
       "       [1.12],\n",
       "       [0.19],\n",
       "       [0.46],\n",
       "       [0.74],\n",
       "       [0.99],\n",
       "       [1.2 ],\n",
       "       [1.16],\n",
       "       [1.16],\n",
       "       [1.16],\n",
       "       [1.15],\n",
       "       [1.18],\n",
       "       [1.18],\n",
       "       [1.16],\n",
       "       [1.18],\n",
       "       [1.16],\n",
       "       [1.14],\n",
       "       [1.18],\n",
       "       [1.16],\n",
       "       [1.17],\n",
       "       [1.17],\n",
       "       [1.16],\n",
       "       [0.13],\n",
       "       [0.31],\n",
       "       [0.51],\n",
       "       [0.71],\n",
       "       [0.85],\n",
       "       [1.04],\n",
       "       [1.16],\n",
       "       [1.16],\n",
       "       [1.15],\n",
       "       [1.14],\n",
       "       [1.16],\n",
       "       [1.14],\n",
       "       [1.16],\n",
       "       [1.16],\n",
       "       [1.16],\n",
       "       [1.14],\n",
       "       [1.16],\n",
       "       [1.17],\n",
       "       [1.16],\n",
       "       [1.15],\n",
       "       [0.11],\n",
       "       [0.24],\n",
       "       [0.41],\n",
       "       [0.67],\n",
       "       [0.65],\n",
       "       [0.81],\n",
       "       [0.93],\n",
       "       [1.08],\n",
       "       [1.14],\n",
       "       [1.14],\n",
       "       [1.13],\n",
       "       [1.15],\n",
       "       [1.16],\n",
       "       [1.14],\n",
       "       [1.14],\n",
       "       [1.16],\n",
       "       [1.15],\n",
       "       [1.13],\n",
       "       [1.16],\n",
       "       [1.13],\n",
       "       [0.09],\n",
       "       [0.21],\n",
       "       [0.33],\n",
       "       [0.44],\n",
       "       [0.54],\n",
       "       [0.68],\n",
       "       [0.78],\n",
       "       [0.9 ],\n",
       "       [0.99],\n",
       "       [1.09],\n",
       "       [1.18],\n",
       "       [1.17],\n",
       "       [1.23],\n",
       "       [1.19],\n",
       "       [1.2 ],\n",
       "       [1.19],\n",
       "       [1.18],\n",
       "       [1.2 ],\n",
       "       [1.16],\n",
       "       [1.16],\n",
       "       [0.08],\n",
       "       [0.18],\n",
       "       [0.29],\n",
       "       [0.38],\n",
       "       [0.51],\n",
       "       [0.6 ],\n",
       "       [0.67],\n",
       "       [0.79],\n",
       "       [0.86],\n",
       "       [0.94],\n",
       "       [1.04],\n",
       "       [1.18],\n",
       "       [1.23],\n",
       "       [1.19],\n",
       "       [1.22],\n",
       "       [1.2 ],\n",
       "       [1.26],\n",
       "       [1.19],\n",
       "       [1.2 ],\n",
       "       [1.2 ],\n",
       "       [0.14],\n",
       "       [0.18],\n",
       "       [0.29],\n",
       "       [0.44],\n",
       "       [0.55],\n",
       "       [0.56],\n",
       "       [0.61],\n",
       "       [0.71],\n",
       "       [0.77],\n",
       "       [0.84],\n",
       "       [0.93],\n",
       "       [1.06],\n",
       "       [1.08],\n",
       "       [1.05],\n",
       "       [1.07],\n",
       "       [1.05],\n",
       "       [1.04],\n",
       "       [1.06],\n",
       "       [1.04],\n",
       "       [1.02],\n",
       "       [0.08],\n",
       "       [0.25],\n",
       "       [0.27],\n",
       "       [0.34],\n",
       "       [0.5 ],\n",
       "       [0.5 ],\n",
       "       [0.56],\n",
       "       [0.66],\n",
       "       [0.7 ],\n",
       "       [0.89],\n",
       "       [0.85],\n",
       "       [0.98],\n",
       "       [0.88],\n",
       "       [0.88],\n",
       "       [0.88],\n",
       "       [0.92],\n",
       "       [0.92],\n",
       "       [0.89],\n",
       "       [0.9 ],\n",
       "       [0.9 ],\n",
       "       [0.11],\n",
       "       [0.23],\n",
       "       [0.29],\n",
       "       [0.41],\n",
       "       [0.39],\n",
       "       [0.47],\n",
       "       [0.55],\n",
       "       [0.62],\n",
       "       [0.65],\n",
       "       [0.83],\n",
       "       [0.79],\n",
       "       [0.95],\n",
       "       [0.9 ],\n",
       "       [0.86],\n",
       "       [0.83],\n",
       "       [0.9 ],\n",
       "       [0.9 ],\n",
       "       [0.84],\n",
       "       [0.86],\n",
       "       [0.88],\n",
       "       [0.11],\n",
       "       [0.19],\n",
       "       [0.3 ],\n",
       "       [0.61],\n",
       "       [0.45],\n",
       "       [0.47],\n",
       "       [0.51],\n",
       "       [0.58],\n",
       "       [0.6 ],\n",
       "       [0.79],\n",
       "       [0.76],\n",
       "       [0.86],\n",
       "       [0.78],\n",
       "       [0.78],\n",
       "       [0.77],\n",
       "       [0.78],\n",
       "       [0.78],\n",
       "       [0.76],\n",
       "       [0.74],\n",
       "       [0.75],\n",
       "       [0.11],\n",
       "       [0.35],\n",
       "       [0.26],\n",
       "       [0.45],\n",
       "       [0.5 ],\n",
       "       [0.47],\n",
       "       [0.48],\n",
       "       [0.58],\n",
       "       [0.57],\n",
       "       [0.76],\n",
       "       [0.73],\n",
       "       [0.86],\n",
       "       [0.84],\n",
       "       [0.88],\n",
       "       [0.85],\n",
       "       [0.88],\n",
       "       [0.85],\n",
       "       [0.83],\n",
       "       [0.85],\n",
       "       [0.85],\n",
       "       [0.17],\n",
       "       [1.01],\n",
       "       [0.29],\n",
       "       [0.39],\n",
       "       [0.44],\n",
       "       [0.44],\n",
       "       [0.46],\n",
       "       [0.57],\n",
       "       [0.58],\n",
       "       [0.79],\n",
       "       [0.73],\n",
       "       [0.83],\n",
       "       [0.94],\n",
       "       [0.85],\n",
       "       [0.82],\n",
       "       [0.83],\n",
       "       [0.8 ],\n",
       "       [0.76],\n",
       "       [0.8 ],\n",
       "       [0.81],\n",
       "       [0.28],\n",
       "       [0.58],\n",
       "       [0.59],\n",
       "       [0.43],\n",
       "       [0.57],\n",
       "       [0.44],\n",
       "       [0.44],\n",
       "       [0.56],\n",
       "       [0.57],\n",
       "       [0.74],\n",
       "       [0.67],\n",
       "       [0.8 ],\n",
       "       [1.01],\n",
       "       [0.8 ],\n",
       "       [0.82],\n",
       "       [0.84],\n",
       "       [0.79],\n",
       "       [0.84],\n",
       "       [0.83],\n",
       "       [0.82],\n",
       "       [0.36],\n",
       "       [0.55],\n",
       "       [0.35],\n",
       "       [1.09],\n",
       "       [0.46],\n",
       "       [0.44],\n",
       "       [0.45],\n",
       "       [0.53],\n",
       "       [0.55],\n",
       "       [0.76],\n",
       "       [0.72],\n",
       "       [0.88],\n",
       "       [0.75],\n",
       "       [0.84],\n",
       "       [0.75],\n",
       "       [0.79],\n",
       "       [0.76],\n",
       "       [0.78],\n",
       "       [0.8 ],\n",
       "       [0.79],\n",
       "       [0.72],\n",
       "       [1.75],\n",
       "       [0.86],\n",
       "       [2.15],\n",
       "       [0.81],\n",
       "       [0.43],\n",
       "       [0.43],\n",
       "       [0.55],\n",
       "       [0.55],\n",
       "       [0.77],\n",
       "       [0.74],\n",
       "       [0.81],\n",
       "       [0.82],\n",
       "       [0.87],\n",
       "       [0.82],\n",
       "       [0.91],\n",
       "       [0.9 ],\n",
       "       [0.82],\n",
       "       [0.86],\n",
       "       [0.85],\n",
       "       [0.47],\n",
       "       [1.52],\n",
       "       [0.56],\n",
       "       [1.08],\n",
       "       [1.03],\n",
       "       [0.47],\n",
       "       [0.45],\n",
       "       [0.6 ],\n",
       "       [0.58],\n",
       "       [0.89],\n",
       "       [0.76],\n",
       "       [0.96],\n",
       "       [1.2 ],\n",
       "       [1.16],\n",
       "       [0.96],\n",
       "       [1.07],\n",
       "       [0.9 ],\n",
       "       [0.72],\n",
       "       [0.85],\n",
       "       [0.91],\n",
       "       [2.2 ],\n",
       "       [2.37],\n",
       "       [1.26],\n",
       "       [0.9 ],\n",
       "       [1.65],\n",
       "       [0.52],\n",
       "       [0.49],\n",
       "       [0.59],\n",
       "       [1.21],\n",
       "       [0.95],\n",
       "       [0.75],\n",
       "       [0.88],\n",
       "       [0.94],\n",
       "       [0.91],\n",
       "       [0.85],\n",
       "       [1.07],\n",
       "       [0.92],\n",
       "       [0.77],\n",
       "       [0.91],\n",
       "       [0.92],\n",
       "       [2.21],\n",
       "       [2.03],\n",
       "       [1.68],\n",
       "       [2.73],\n",
       "       [1.77],\n",
       "       [0.68],\n",
       "       [0.62],\n",
       "       [0.87],\n",
       "       [1.03],\n",
       "       [0.97],\n",
       "       [1.01],\n",
       "       [1.58],\n",
       "       [1.25],\n",
       "       [1.05],\n",
       "       [1.49],\n",
       "       [1.23],\n",
       "       [0.97],\n",
       "       [0.96],\n",
       "       [1.19],\n",
       "       [1.06],\n",
       "       [1.64],\n",
       "       [1.91],\n",
       "       [1.76],\n",
       "       [2.23],\n",
       "       [2.09],\n",
       "       [0.85],\n",
       "       [1.01],\n",
       "       [1.05],\n",
       "       [1.05],\n",
       "       [1.4 ],\n",
       "       [1.52],\n",
       "       [1.43],\n",
       "       [1.69],\n",
       "       [2.04],\n",
       "       [1.45],\n",
       "       [1.46],\n",
       "       [1.06],\n",
       "       [1.28],\n",
       "       [1.33],\n",
       "       [1.35],\n",
       "       [2.17],\n",
       "       [1.38],\n",
       "       [1.85],\n",
       "       [2.49],\n",
       "       [2.11],\n",
       "       [1.11],\n",
       "       [1.03],\n",
       "       [1.48],\n",
       "       [1.09],\n",
       "       [1.57],\n",
       "       [1.62],\n",
       "       [1.65],\n",
       "       [1.7 ],\n",
       "       [1.8 ],\n",
       "       [1.7 ],\n",
       "       [1.35],\n",
       "       [2.17],\n",
       "       [1.31],\n",
       "       [1.65],\n",
       "       [1.63]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d85c76d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10. ],\n",
       "       [ 10. ],\n",
       "       [ 10. ],\n",
       "       [  9.8],\n",
       "       [ 10. ],\n",
       "       [ 10. ],\n",
       "       [  9.9],\n",
       "       [  9.9],\n",
       "       [ 10. ],\n",
       "       [ 10. ],\n",
       "       [ 10. ],\n",
       "       [ 10. ],\n",
       "       [  9.9],\n",
       "       [  9.9],\n",
       "       [ 10. ],\n",
       "       [  9.8],\n",
       "       [  9.8],\n",
       "       [ 10. ],\n",
       "       [ 10. ],\n",
       "       [ 10. ],\n",
       "       [ 20.1],\n",
       "       [ 20.1],\n",
       "       [ 19.4],\n",
       "       [ 20. ],\n",
       "       [ 19.9],\n",
       "       [ 20. ],\n",
       "       [ 19.3],\n",
       "       [ 19.9],\n",
       "       [ 19.6],\n",
       "       [ 19.9],\n",
       "       [ 19.8],\n",
       "       [ 20.1],\n",
       "       [ 19.9],\n",
       "       [ 19.3],\n",
       "       [ 19.4],\n",
       "       [ 19.8],\n",
       "       [ 20. ],\n",
       "       [ 19.4],\n",
       "       [ 19.9],\n",
       "       [ 19.4],\n",
       "       [ 30.1],\n",
       "       [ 30.1],\n",
       "       [ 28.5],\n",
       "       [ 30.1],\n",
       "       [ 30.1],\n",
       "       [ 29.3],\n",
       "       [ 28.8],\n",
       "       [ 28.6],\n",
       "       [ 28.6],\n",
       "       [ 28.7],\n",
       "       [ 28.5],\n",
       "       [ 28.6],\n",
       "       [ 28.5],\n",
       "       [ 28.6],\n",
       "       [ 28.4],\n",
       "       [ 28.5],\n",
       "       [ 28.6],\n",
       "       [ 28.6],\n",
       "       [ 28.4],\n",
       "       [ 28.8],\n",
       "       [ 40.1],\n",
       "       [ 40.1],\n",
       "       [ 37.3],\n",
       "       [ 38.2],\n",
       "       [ 40.1],\n",
       "       [ 38.3],\n",
       "       [ 37.6],\n",
       "       [ 38.3],\n",
       "       [ 37.8],\n",
       "       [ 37.6],\n",
       "       [ 37.6],\n",
       "       [ 37.8],\n",
       "       [ 37.8],\n",
       "       [ 37.6],\n",
       "       [ 37.6],\n",
       "       [ 37.6],\n",
       "       [ 37.3],\n",
       "       [ 37.6],\n",
       "       [ 37.7],\n",
       "       [ 37.5],\n",
       "       [ 50.1],\n",
       "       [ 50.1],\n",
       "       [ 45.7],\n",
       "       [ 50. ],\n",
       "       [ 50. ],\n",
       "       [ 46.9],\n",
       "       [ 46.2],\n",
       "       [ 46.9],\n",
       "       [ 45.7],\n",
       "       [ 49.9],\n",
       "       [ 48.4],\n",
       "       [ 48.7],\n",
       "       [ 47.8],\n",
       "       [ 48. ],\n",
       "       [ 48. ],\n",
       "       [ 48.2],\n",
       "       [ 48.6],\n",
       "       [ 48.6],\n",
       "       [ 48.4],\n",
       "       [ 48.6],\n",
       "       [ 60.2],\n",
       "       [ 60.1],\n",
       "       [ 53.9],\n",
       "       [ 60.1],\n",
       "       [ 59.9],\n",
       "       [ 55.3],\n",
       "       [ 54.3],\n",
       "       [ 55.2],\n",
       "       [ 53.8],\n",
       "       [ 59.8],\n",
       "       [ 53.8],\n",
       "       [ 55.2],\n",
       "       [ 54. ],\n",
       "       [ 59.8],\n",
       "       [ 54.3],\n",
       "       [ 54.1],\n",
       "       [ 53.7],\n",
       "       [ 59.5],\n",
       "       [ 53.6],\n",
       "       [ 53.8],\n",
       "       [ 61.8],\n",
       "       [ 70. ],\n",
       "       [ 61.7],\n",
       "       [ 62.8],\n",
       "       [ 63.6],\n",
       "       [ 63.2],\n",
       "       [ 62.2],\n",
       "       [ 63.2],\n",
       "       [ 61.6],\n",
       "       [ 69.7],\n",
       "       [ 61.8],\n",
       "       [ 63.3],\n",
       "       [ 61.6],\n",
       "       [ 61.7],\n",
       "       [ 69.8],\n",
       "       [ 69.3],\n",
       "       [ 69.9],\n",
       "       [ 61.8],\n",
       "       [ 61.6],\n",
       "       [ 69.8],\n",
       "       [ 80.2],\n",
       "       [ 69.7],\n",
       "       [ 69.2],\n",
       "       [ 79.9],\n",
       "       [ 71.5],\n",
       "       [ 70.8],\n",
       "       [ 69.7],\n",
       "       [ 70.8],\n",
       "       [ 69.2],\n",
       "       [ 74.3],\n",
       "       [ 69.2],\n",
       "       [ 70.9],\n",
       "       [ 69.4],\n",
       "       [ 69.4],\n",
       "       [ 70.3],\n",
       "       [ 70.3],\n",
       "       [ 69.7],\n",
       "       [ 70.1],\n",
       "       [ 70.1],\n",
       "       [ 69.8],\n",
       "       [ 76.6],\n",
       "       [ 77. ],\n",
       "       [ 76.5],\n",
       "       [ 78.2],\n",
       "       [ 89.5],\n",
       "       [ 78.3],\n",
       "       [ 77.1],\n",
       "       [ 78.3],\n",
       "       [ 76.4],\n",
       "       [ 82. ],\n",
       "       [ 76.3],\n",
       "       [ 78.4],\n",
       "       [ 80.6],\n",
       "       [ 81.2],\n",
       "       [ 81.3],\n",
       "       [ 81.1],\n",
       "       [ 80.7],\n",
       "       [ 81.2],\n",
       "       [ 80.9],\n",
       "       [ 81.8],\n",
       "       [ 83.7],\n",
       "       [ 84. ],\n",
       "       [ 83.5],\n",
       "       [ 83.1],\n",
       "       [ 85.7],\n",
       "       [ 85.3],\n",
       "       [ 84.3],\n",
       "       [ 85.3],\n",
       "       [ 83.3],\n",
       "       [ 89.6],\n",
       "       [ 83.1],\n",
       "       [ 85.4],\n",
       "       [ 97. ],\n",
       "       [ 96.2],\n",
       "       [ 96.2],\n",
       "       [ 96.5],\n",
       "       [ 97.3],\n",
       "       [ 98.6],\n",
       "       [ 96.5],\n",
       "       [ 96.8],\n",
       "       [ 90.3],\n",
       "       [ 90.9],\n",
       "       [ 90.3],\n",
       "       [ 92.5],\n",
       "       [ 92.7],\n",
       "       [ 91.9],\n",
       "       [ 90.8],\n",
       "       [ 92.3],\n",
       "       [ 90.3],\n",
       "       [ 96.3],\n",
       "       [ 90.6],\n",
       "       [ 92.4],\n",
       "       [ 97. ],\n",
       "       [ 96.6],\n",
       "       [ 96.7],\n",
       "       [ 95.8],\n",
       "       [ 96.4],\n",
       "       [ 96.5],\n",
       "       [ 96.2],\n",
       "       [ 96.8],\n",
       "       [ 97. ],\n",
       "       [ 96.7],\n",
       "       [ 96.5],\n",
       "       [119.3],\n",
       "       [ 99.2],\n",
       "       [ 98.9],\n",
       "       [ 97.6],\n",
       "       [ 99.1],\n",
       "       [ 97. ],\n",
       "       [103.3],\n",
       "       [ 96.7],\n",
       "       [ 99. ],\n",
       "       [ 97. ],\n",
       "       [ 98.5],\n",
       "       [ 97.2],\n",
       "       [ 97.6],\n",
       "       [ 97.2],\n",
       "       [ 96.9],\n",
       "       [ 97.4],\n",
       "       [ 97.9],\n",
       "       [129.6],\n",
       "       [104. ],\n",
       "       [103.5],\n",
       "       [106. ],\n",
       "       [105.5],\n",
       "       [105.4],\n",
       "       [103.9],\n",
       "       [105.5],\n",
       "       [103.4],\n",
       "       [110.1],\n",
       "       [103.4],\n",
       "       [105.4],\n",
       "       [119.8],\n",
       "       [120.3],\n",
       "       [121.9],\n",
       "       [121.3],\n",
       "       [120.6],\n",
       "       [121.7],\n",
       "       [121.9],\n",
       "       [120.9],\n",
       "       [109. ],\n",
       "       [110.1],\n",
       "       [138.1],\n",
       "       [111.6],\n",
       "       [111.8],\n",
       "       [111.6],\n",
       "       [110.2],\n",
       "       [111.4],\n",
       "       [109.1],\n",
       "       [116.3],\n",
       "       [109.4],\n",
       "       [111.5],\n",
       "       [121.4],\n",
       "       [121.6],\n",
       "       [121.5],\n",
       "       [121.5],\n",
       "       [121. ],\n",
       "       [121.4],\n",
       "       [121.4],\n",
       "       [121.6],\n",
       "       [115.1],\n",
       "       [114.3],\n",
       "       [110.5],\n",
       "       [111.8],\n",
       "       [118. ],\n",
       "       [117.9],\n",
       "       [116. ],\n",
       "       [118. ],\n",
       "       [115.5],\n",
       "       [122.6],\n",
       "       [115.3],\n",
       "       [117.4],\n",
       "       [119.9],\n",
       "       [120.9],\n",
       "       [120.1],\n",
       "       [119.9],\n",
       "       [120.7],\n",
       "       [120.9],\n",
       "       [121.4],\n",
       "       [121.3],\n",
       "       [120.3],\n",
       "       [119.1],\n",
       "       [120.1],\n",
       "       [121.4],\n",
       "       [123.3],\n",
       "       [123.6],\n",
       "       [121. ],\n",
       "       [123.1],\n",
       "       [121.2],\n",
       "       [127.7],\n",
       "       [120.9],\n",
       "       [123.2],\n",
       "       [121.8],\n",
       "       [121.3],\n",
       "       [121.6],\n",
       "       [121.2],\n",
       "       [120.4],\n",
       "       [122.7],\n",
       "       [121.6],\n",
       "       [121.8],\n",
       "       [118.8],\n",
       "       [122.6],\n",
       "       [124.5],\n",
       "       [125.2],\n",
       "       [125.4],\n",
       "       [128.8],\n",
       "       [127.2],\n",
       "       [128.5],\n",
       "       [128.5],\n",
       "       [131.6],\n",
       "       [126.4],\n",
       "       [129. ],\n",
       "       [161.2],\n",
       "       [160.3],\n",
       "       [161. ],\n",
       "       [159.7],\n",
       "       [160.5],\n",
       "       [160.3],\n",
       "       [159.9],\n",
       "       [159.6],\n",
       "       [105.4],\n",
       "       [126.4],\n",
       "       [129.1],\n",
       "       [115.7],\n",
       "       [129.5],\n",
       "       [132.1],\n",
       "       [132.4],\n",
       "       [132.7],\n",
       "       [130.7],\n",
       "       [138.6],\n",
       "       [130. ],\n",
       "       [129.8],\n",
       "       [160.5],\n",
       "       [161.8],\n",
       "       [157.9],\n",
       "       [159.5],\n",
       "       [159.8],\n",
       "       [160.7],\n",
       "       [159.5],\n",
       "       [162.2],\n",
       "       [126.8],\n",
       "       [133.5],\n",
       "       [127.1],\n",
       "       [129.3],\n",
       "       [130.3],\n",
       "       [135.1],\n",
       "       [134.9],\n",
       "       [135.3],\n",
       "       [134.6],\n",
       "       [137.6],\n",
       "       [130.7],\n",
       "       [134.4],\n",
       "       [159.4],\n",
       "       [122.3],\n",
       "       [118.5],\n",
       "       [161.6],\n",
       "       [163.5],\n",
       "       [158.5],\n",
       "       [163.1],\n",
       "       [161. ],\n",
       "       [131. ],\n",
       "       [130.2],\n",
       "       [134.1],\n",
       "       [121.3],\n",
       "       [135.9],\n",
       "       [139.4],\n",
       "       [139.1],\n",
       "       [138.2],\n",
       "       [137. ],\n",
       "       [138.7],\n",
       "       [177.2],\n",
       "       [137.6],\n",
       "       [159.7],\n",
       "       [158.7],\n",
       "       [160.6],\n",
       "       [160.8],\n",
       "       [158.4],\n",
       "       [163.5],\n",
       "       [163. ],\n",
       "       [161.6]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28a82a8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# MLP1(send rates, block size) = latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0458870",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Split training set and test set\n",
    "Xtrain1, Xtest1, Ytrain1, Ytest1 = train_test_split(X, Y1, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bdee55f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[197. , 190. ],\n",
       "       [ 70.2,  60. ],\n",
       "       [170.2,  90. ],\n",
       "       [170.3, 200. ],\n",
       "       [ 90.5, 130. ],\n",
       "       [179. ,  30. ],\n",
       "       [100.4, 180. ],\n",
       "       [150.1, 120. ],\n",
       "       [ 20.1, 100. ],\n",
       "       [150.2,  50. ],\n",
       "       [ 90.4, 150. ],\n",
       "       [190.5, 130. ],\n",
       "       [100.3,  90. ],\n",
       "       [170.5,  50. ],\n",
       "       [167.2,  20. ],\n",
       "       [120.5,  80. ],\n",
       "       [189.3, 120. ],\n",
       "       [ 10. ,  60. ],\n",
       "       [ 40.2, 190. ],\n",
       "       [120.4,  40. ],\n",
       "       [ 70.3,  30. ],\n",
       "       [130.4,  30. ],\n",
       "       [191.5,  30. ],\n",
       "       [110.3, 150. ],\n",
       "       [ 10. , 180. ],\n",
       "       [ 50.3, 130. ],\n",
       "       [190.3,  70. ],\n",
       "       [110.2,  20. ],\n",
       "       [187.7,  20. ],\n",
       "       [110.6,  80. ],\n",
       "       [ 50.2,  20. ],\n",
       "       [ 10. ,  50. ],\n",
       "       [ 90.4,  60. ],\n",
       "       [140.6, 160. ],\n",
       "       [ 10. ,  70. ],\n",
       "       [ 50.2,  10. ],\n",
       "       [ 30.1, 190. ],\n",
       "       [ 60.3,  30. ],\n",
       "       [198.9, 180. ],\n",
       "       [ 70.3, 200. ],\n",
       "       [140.4,  90. ],\n",
       "       [110.5,  50. ],\n",
       "       [ 90.4, 120. ],\n",
       "       [ 40.2,  30. ],\n",
       "       [200. ,  60. ],\n",
       "       [ 50.2,  60. ],\n",
       "       [193.6, 100. ],\n",
       "       [160.1,  80. ],\n",
       "       [160.3, 150. ],\n",
       "       [140.6, 190. ],\n",
       "       [ 40.2,  60. ],\n",
       "       [120.6,  60. ],\n",
       "       [120.4, 100. ],\n",
       "       [ 10. , 190. ],\n",
       "       [150.2, 170. ],\n",
       "       [150.5,  70. ],\n",
       "       [140.6, 130. ],\n",
       "       [ 60.3, 180. ],\n",
       "       [130.3, 190. ],\n",
       "       [178.6,  10. ],\n",
       "       [ 60.3,  80. ],\n",
       "       [ 40.2,  80. ],\n",
       "       [120.5, 150. ],\n",
       "       [130.6,  70. ],\n",
       "       [175.4, 150. ],\n",
       "       [120.4,  30. ],\n",
       "       [ 60.3,  70. ],\n",
       "       [160.6, 110. ],\n",
       "       [140.6, 110. ],\n",
       "       [160.6, 130. ],\n",
       "       [110.4, 190. ],\n",
       "       [ 50.2, 160. ],\n",
       "       [180. , 110. ],\n",
       "       [200.2,  80. ],\n",
       "       [ 10. , 120. ],\n",
       "       [180. ,  80. ],\n",
       "       [ 30.1,  20. ],\n",
       "       [100.3,  10. ],\n",
       "       [ 70.2, 130. ],\n",
       "       [120.4,  50. ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set\n",
    "Xtest1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec3253d7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.99],\n",
       "       [1.18],\n",
       "       [0.33],\n",
       "       [1.16],\n",
       "       [1.15],\n",
       "       [1.55],\n",
       "       [0.9 ],\n",
       "       [0.81],\n",
       "       [1.2 ],\n",
       "       [1.22],\n",
       "       [1.23],\n",
       "       [1.28],\n",
       "       [0.92],\n",
       "       [1.18],\n",
       "       [0.91],\n",
       "       [0.26],\n",
       "       [1.18],\n",
       "       [1.26],\n",
       "       [1.17],\n",
       "       [0.87],\n",
       "       [1.18],\n",
       "       [0.92],\n",
       "       [0.94],\n",
       "       [1.24],\n",
       "       [0.88],\n",
       "       [1.19],\n",
       "       [2.32],\n",
       "       [1.01],\n",
       "       [1.66],\n",
       "       [0.76],\n",
       "       [0.77],\n",
       "       [1.34],\n",
       "       [0.89],\n",
       "       [1.19],\n",
       "       [0.65],\n",
       "       [0.83],\n",
       "       [1.13],\n",
       "       [2.57],\n",
       "       [0.92],\n",
       "       [1.2 ],\n",
       "       [0.97],\n",
       "       [0.89],\n",
       "       [0.88],\n",
       "       [1.16],\n",
       "       [2.29],\n",
       "       [0.47],\n",
       "       [1.15],\n",
       "       [0.93],\n",
       "       [0.85],\n",
       "       [0.8 ],\n",
       "       [1.19],\n",
       "       [2.56],\n",
       "       [1.18],\n",
       "       [1.73],\n",
       "       [1.23],\n",
       "       [1.45],\n",
       "       [2.1 ],\n",
       "       [1.27],\n",
       "       [1.52],\n",
       "       [0.85],\n",
       "       [1.17],\n",
       "       [0.95],\n",
       "       [0.86],\n",
       "       [0.25],\n",
       "       [0.84],\n",
       "       [0.9 ],\n",
       "       [1.09],\n",
       "       [0.84],\n",
       "       [1.24],\n",
       "       [0.91],\n",
       "       [1.2 ],\n",
       "       [1.25],\n",
       "       [1.58],\n",
       "       [2.9 ],\n",
       "       [1.59],\n",
       "       [1.1 ],\n",
       "       [2.33],\n",
       "       [1.21],\n",
       "       [1.25],\n",
       "       [0.87],\n",
       "       [2.18],\n",
       "       [1.25],\n",
       "       [0.86],\n",
       "       [1.38],\n",
       "       [2.14],\n",
       "       [1.48],\n",
       "       [1.26],\n",
       "       [1.18],\n",
       "       [0.93],\n",
       "       [1.  ],\n",
       "       [1.11],\n",
       "       [1.21],\n",
       "       [1.03],\n",
       "       [0.81],\n",
       "       [1.17],\n",
       "       [1.24],\n",
       "       [1.17],\n",
       "       [1.24],\n",
       "       [0.45],\n",
       "       [1.31],\n",
       "       [1.15],\n",
       "       [1.3 ],\n",
       "       [2.17],\n",
       "       [0.9 ],\n",
       "       [1.07],\n",
       "       [2.36],\n",
       "       [1.17],\n",
       "       [1.77],\n",
       "       [1.25],\n",
       "       [1.68],\n",
       "       [1.89],\n",
       "       [0.89],\n",
       "       [0.43],\n",
       "       [0.92],\n",
       "       [0.59],\n",
       "       [1.16],\n",
       "       [1.6 ],\n",
       "       [0.67],\n",
       "       [0.94],\n",
       "       [0.96],\n",
       "       [1.04],\n",
       "       [0.95],\n",
       "       [0.97],\n",
       "       [0.87],\n",
       "       [0.88],\n",
       "       [1.16],\n",
       "       [0.8 ],\n",
       "       [0.92],\n",
       "       [1.17],\n",
       "       [0.84],\n",
       "       [1.16],\n",
       "       [0.86],\n",
       "       [1.66],\n",
       "       [0.95],\n",
       "       [1.88],\n",
       "       [0.87],\n",
       "       [1.12],\n",
       "       [1.17],\n",
       "       [1.18],\n",
       "       [1.87],\n",
       "       [1.75],\n",
       "       [3.07],\n",
       "       [0.94],\n",
       "       [0.93],\n",
       "       [0.87],\n",
       "       [1.27],\n",
       "       [0.8 ],\n",
       "       [1.24],\n",
       "       [1.18],\n",
       "       [1.02],\n",
       "       [0.95],\n",
       "       [0.85],\n",
       "       [1.16],\n",
       "       [0.64],\n",
       "       [1.2 ],\n",
       "       [1.57],\n",
       "       [0.58],\n",
       "       [1.18],\n",
       "       [1.16],\n",
       "       [1.23],\n",
       "       [1.3 ],\n",
       "       [1.27],\n",
       "       [1.19],\n",
       "       [0.88],\n",
       "       [1.12],\n",
       "       [0.47],\n",
       "       [0.84],\n",
       "       [1.2 ],\n",
       "       [1.08],\n",
       "       [1.66],\n",
       "       [1.16],\n",
       "       [1.45],\n",
       "       [1.14],\n",
       "       [1.08],\n",
       "       [1.16],\n",
       "       [0.89],\n",
       "       [0.92],\n",
       "       [2.21],\n",
       "       [0.83],\n",
       "       [0.81],\n",
       "       [1.18],\n",
       "       [0.94],\n",
       "       [2.  ],\n",
       "       [0.92],\n",
       "       [1.21],\n",
       "       [1.62],\n",
       "       [0.84],\n",
       "       [0.93],\n",
       "       [0.16],\n",
       "       [2.18],\n",
       "       [1.18],\n",
       "       [2.24],\n",
       "       [1.27],\n",
       "       [1.32],\n",
       "       [1.04],\n",
       "       [0.88],\n",
       "       [0.92],\n",
       "       [1.23],\n",
       "       [1.17],\n",
       "       [1.36],\n",
       "       [0.93],\n",
       "       [2.08],\n",
       "       [0.91],\n",
       "       [1.28],\n",
       "       [0.85],\n",
       "       [0.88],\n",
       "       [0.31],\n",
       "       [2.14],\n",
       "       [1.24],\n",
       "       [1.18],\n",
       "       [0.94],\n",
       "       [1.16],\n",
       "       [1.07],\n",
       "       [0.95],\n",
       "       [0.94],\n",
       "       [2.3 ],\n",
       "       [1.08],\n",
       "       [0.96],\n",
       "       [1.93],\n",
       "       [1.25],\n",
       "       [0.93],\n",
       "       [0.88],\n",
       "       [1.25],\n",
       "       [2.52],\n",
       "       [2.07],\n",
       "       [1.17],\n",
       "       [0.89],\n",
       "       [2.19],\n",
       "       [1.11],\n",
       "       [1.23],\n",
       "       [1.22],\n",
       "       [1.19],\n",
       "       [1.17],\n",
       "       [0.8 ],\n",
       "       [0.9 ],\n",
       "       [1.26],\n",
       "       [0.29],\n",
       "       [1.46],\n",
       "       [2.59],\n",
       "       [0.47],\n",
       "       [1.25],\n",
       "       [1.17],\n",
       "       [0.95],\n",
       "       [1.91],\n",
       "       [0.51],\n",
       "       [1.07],\n",
       "       [1.75],\n",
       "       [0.92],\n",
       "       [2.55],\n",
       "       [0.87],\n",
       "       [2.03],\n",
       "       [1.99],\n",
       "       [0.93],\n",
       "       [1.03],\n",
       "       [0.92],\n",
       "       [2.1 ],\n",
       "       [0.54],\n",
       "       [1.68],\n",
       "       [1.03],\n",
       "       [1.18],\n",
       "       [0.87],\n",
       "       [0.89],\n",
       "       [2.23],\n",
       "       [1.17],\n",
       "       [0.68],\n",
       "       [0.92],\n",
       "       [0.9 ],\n",
       "       [1.47],\n",
       "       [1.45],\n",
       "       [0.97],\n",
       "       [1.18],\n",
       "       [1.15],\n",
       "       [0.86],\n",
       "       [1.19],\n",
       "       [1.15],\n",
       "       [1.17],\n",
       "       [0.89],\n",
       "       [1.64],\n",
       "       [0.49],\n",
       "       [1.2 ],\n",
       "       [1.22],\n",
       "       [0.5 ],\n",
       "       [0.94],\n",
       "       [1.02],\n",
       "       [2.13],\n",
       "       [1.23],\n",
       "       [1.24],\n",
       "       [1.15],\n",
       "       [0.82],\n",
       "       [0.82],\n",
       "       [2.32],\n",
       "       [1.21],\n",
       "       [1.82],\n",
       "       [1.87],\n",
       "       [0.64],\n",
       "       [1.17],\n",
       "       [1.25],\n",
       "       [0.88],\n",
       "       [0.85],\n",
       "       [0.9 ],\n",
       "       [1.02],\n",
       "       [0.91],\n",
       "       [0.94],\n",
       "       [1.09],\n",
       "       [1.24],\n",
       "       [1.24],\n",
       "       [0.9 ],\n",
       "       [0.67],\n",
       "       [0.89],\n",
       "       [2.73],\n",
       "       [0.91],\n",
       "       [1.18],\n",
       "       [1.23],\n",
       "       [2.38],\n",
       "       [1.83],\n",
       "       [1.28],\n",
       "       [0.82],\n",
       "       [1.07],\n",
       "       [2.16],\n",
       "       [1.2 ],\n",
       "       [1.99],\n",
       "       [0.9 ],\n",
       "       [2.57],\n",
       "       [1.17],\n",
       "       [1.17],\n",
       "       [1.97],\n",
       "       [1.18],\n",
       "       [0.88],\n",
       "       [0.92],\n",
       "       [1.21],\n",
       "       [1.76],\n",
       "       [1.15],\n",
       "       [2.19],\n",
       "       [0.93],\n",
       "       [1.16],\n",
       "       [2.13],\n",
       "       [0.92],\n",
       "       [0.93],\n",
       "       [0.93],\n",
       "       [0.89],\n",
       "       [1.17],\n",
       "       [1.17],\n",
       "       [1.4 ],\n",
       "       [1.16],\n",
       "       [1.32],\n",
       "       [2.22],\n",
       "       [1.15],\n",
       "       [0.99],\n",
       "       [2.5 ],\n",
       "       [1.15],\n",
       "       [0.91],\n",
       "       [1.21],\n",
       "       [1.17],\n",
       "       [1.2 ],\n",
       "       [1.66],\n",
       "       [0.97],\n",
       "       [0.85],\n",
       "       [1.21],\n",
       "       [2.06],\n",
       "       [0.94],\n",
       "       [1.99],\n",
       "       [1.76],\n",
       "       [1.04],\n",
       "       [1.05],\n",
       "       [2.71],\n",
       "       [0.97],\n",
       "       [0.88],\n",
       "       [0.91],\n",
       "       [2.45],\n",
       "       [0.95],\n",
       "       [1.13],\n",
       "       [1.25],\n",
       "       [0.94],\n",
       "       [0.94],\n",
       "       [0.92],\n",
       "       [1.19],\n",
       "       [1.2 ],\n",
       "       [0.88],\n",
       "       [2.05],\n",
       "       [0.99],\n",
       "       [1.19],\n",
       "       [0.7 ],\n",
       "       [1.11],\n",
       "       [2.12],\n",
       "       [0.88],\n",
       "       [0.85],\n",
       "       [0.81],\n",
       "       [1.19],\n",
       "       [2.04],\n",
       "       [1.2 ],\n",
       "       [0.91],\n",
       "       [2.5 ],\n",
       "       [1.18],\n",
       "       [1.17],\n",
       "       [1.01],\n",
       "       [1.17],\n",
       "       [1.18],\n",
       "       [1.28],\n",
       "       [1.27],\n",
       "       [0.96],\n",
       "       [1.53],\n",
       "       [1.11],\n",
       "       [0.91],\n",
       "       [0.93],\n",
       "       [1.18],\n",
       "       [0.88],\n",
       "       [2.35],\n",
       "       [0.91],\n",
       "       [0.95],\n",
       "       [1.2 ],\n",
       "       [1.84],\n",
       "       [1.16],\n",
       "       [1.27],\n",
       "       [1.02],\n",
       "       [2.25],\n",
       "       [1.19],\n",
       "       [1.16],\n",
       "       [0.97],\n",
       "       [1.16],\n",
       "       [2.35],\n",
       "       [1.96],\n",
       "       [1.31],\n",
       "       [1.82],\n",
       "       [0.97],\n",
       "       [1.26],\n",
       "       [0.91],\n",
       "       [1.1 ],\n",
       "       [0.83],\n",
       "       [0.92],\n",
       "       [0.98],\n",
       "       [1.1 ],\n",
       "       [0.83],\n",
       "       [1.82],\n",
       "       [0.95],\n",
       "       [0.45],\n",
       "       [0.87],\n",
       "       [1.24],\n",
       "       [0.93],\n",
       "       [2.17],\n",
       "       [1.17],\n",
       "       [1.16],\n",
       "       [2.11],\n",
       "       [0.93],\n",
       "       [2.57],\n",
       "       [1.82],\n",
       "       [2.21],\n",
       "       [1.15],\n",
       "       [1.03],\n",
       "       [0.48],\n",
       "       [1.31],\n",
       "       [1.23],\n",
       "       [1.18],\n",
       "       [1.25],\n",
       "       [0.51],\n",
       "       [0.96],\n",
       "       [0.9 ],\n",
       "       [2.45],\n",
       "       [1.21],\n",
       "       [1.02],\n",
       "       [0.99],\n",
       "       [1.24],\n",
       "       [1.1 ],\n",
       "       [1.27],\n",
       "       [2.12],\n",
       "       [1.83],\n",
       "       [1.33],\n",
       "       [0.84],\n",
       "       [2.2 ],\n",
       "       [0.9 ],\n",
       "       [1.23],\n",
       "       [0.51],\n",
       "       [1.66],\n",
       "       [0.83],\n",
       "       [1.17],\n",
       "       [0.94],\n",
       "       [1.02],\n",
       "       [2.45],\n",
       "       [0.89],\n",
       "       [1.17],\n",
       "       [1.  ],\n",
       "       [1.8 ],\n",
       "       [2.19],\n",
       "       [0.58],\n",
       "       [1.19],\n",
       "       [1.84],\n",
       "       [1.19],\n",
       "       [0.84],\n",
       "       [1.74],\n",
       "       [1.17],\n",
       "       [1.05],\n",
       "       [1.64],\n",
       "       [1.3 ],\n",
       "       [1.14],\n",
       "       [0.94],\n",
       "       [1.93],\n",
       "       [0.84],\n",
       "       [2.48],\n",
       "       [0.89],\n",
       "       [1.17],\n",
       "       [0.86],\n",
       "       [1.06],\n",
       "       [1.16],\n",
       "       [0.93],\n",
       "       [1.03],\n",
       "       [1.02],\n",
       "       [0.92],\n",
       "       [0.83],\n",
       "       [1.18],\n",
       "       [0.87],\n",
       "       [1.2 ],\n",
       "       [0.91],\n",
       "       [0.9 ],\n",
       "       [0.78],\n",
       "       [2.08],\n",
       "       [0.5 ],\n",
       "       [1.18],\n",
       "       [1.03],\n",
       "       [0.86],\n",
       "       [0.88],\n",
       "       [1.21],\n",
       "       [0.88],\n",
       "       [1.01],\n",
       "       [0.86],\n",
       "       [0.26],\n",
       "       [0.96],\n",
       "       [2.75],\n",
       "       [0.08],\n",
       "       [1.26],\n",
       "       [2.41],\n",
       "       [0.85],\n",
       "       [0.95],\n",
       "       [1.98],\n",
       "       [1.2 ],\n",
       "       [2.22],\n",
       "       [1.17],\n",
       "       [0.97],\n",
       "       [2.41],\n",
       "       [1.23],\n",
       "       [1.24],\n",
       "       [1.21],\n",
       "       [1.17],\n",
       "       [1.16],\n",
       "       [1.2 ],\n",
       "       [1.26],\n",
       "       [0.1 ],\n",
       "       [1.61],\n",
       "       [2.4 ],\n",
       "       [0.88],\n",
       "       [0.83],\n",
       "       [1.16],\n",
       "       [2.32],\n",
       "       [1.03],\n",
       "       [1.02],\n",
       "       [1.23],\n",
       "       [1.16],\n",
       "       [0.89],\n",
       "       [0.94],\n",
       "       [1.02],\n",
       "       [1.51],\n",
       "       [0.88],\n",
       "       [2.54],\n",
       "       [1.06],\n",
       "       [1.17],\n",
       "       [0.89],\n",
       "       [1.24],\n",
       "       [0.94],\n",
       "       [1.14],\n",
       "       [1.17],\n",
       "       [0.88],\n",
       "       [1.7 ],\n",
       "       [1.24],\n",
       "       [1.1 ],\n",
       "       [0.93],\n",
       "       [0.5 ],\n",
       "       [1.18],\n",
       "       [1.54],\n",
       "       [1.23],\n",
       "       [1.19],\n",
       "       [1.66],\n",
       "       [1.26],\n",
       "       [1.18],\n",
       "       [0.9 ],\n",
       "       [1.08],\n",
       "       [1.71],\n",
       "       [0.9 ],\n",
       "       [1.02],\n",
       "       [0.87],\n",
       "       [0.9 ],\n",
       "       [1.63],\n",
       "       [0.92],\n",
       "       [1.17],\n",
       "       [0.89],\n",
       "       [0.62],\n",
       "       [0.93],\n",
       "       [0.84],\n",
       "       [0.87],\n",
       "       [0.98],\n",
       "       [2.13],\n",
       "       [0.82],\n",
       "       [1.25],\n",
       "       [1.04],\n",
       "       [0.91],\n",
       "       [1.18],\n",
       "       [0.92],\n",
       "       [1.25],\n",
       "       [1.17],\n",
       "       [0.88],\n",
       "       [1.16],\n",
       "       [1.19],\n",
       "       [1.33],\n",
       "       [2.49],\n",
       "       [1.16],\n",
       "       [1.34],\n",
       "       [0.92],\n",
       "       [1.27],\n",
       "       [1.18],\n",
       "       [1.06],\n",
       "       [0.95],\n",
       "       [1.08],\n",
       "       [2.36],\n",
       "       [0.88],\n",
       "       [0.87],\n",
       "       [0.65],\n",
       "       [0.2 ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytest1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cec710d5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# property scaling\n",
    "min_max_scaler1 = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f6ca873",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8427673 , 0.51898734],\n",
       "       [0.39412998, 0.92405063],\n",
       "       [0.52568134, 0.46835443],\n",
       "       ...,\n",
       "       [0.34224319, 0.70886076],\n",
       "       [0.05293501, 0.94936709],\n",
       "       [0.34224319, 0.26582278]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling training set data\n",
    "Xtrain1_minmax = min_max_scaler1.fit_transform(Xtrain1)\n",
    "Xtrain1_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d632a673",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94444444, 0.89873418],\n",
       "       [0.02672956, 0.37974684],\n",
       "       [0.34224319, 0.03797468],\n",
       "       ...,\n",
       "       [0.5       , 0.5443038 ],\n",
       "       [0.47222222, 0.08860759],\n",
       "       [0.52672956, 0.01265823]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the same scaling to the test set data\n",
    "Xtest1_minmax = min_max_scaler1.transform(Xtest1)\n",
    "Xtest1_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa52ed0a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Xtest1_tensor = torch.from_numpy(Xtest1_minmax).type(torch.float32)\n",
    "Ytest1_tensor = torch.from_numpy(Ytest1).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5b318ea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9444, 0.8987],\n",
       "        [0.0267, 0.3797],\n",
       "        [0.3422, 0.0380],\n",
       "        ...,\n",
       "        [0.5000, 0.5443],\n",
       "        [0.4722, 0.0886],\n",
       "        [0.5267, 0.0127]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest1_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "832155d9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# batch the training dataset\n",
    "# prepare dataset\n",
    "class BlockChainDataset(Dataset):\n",
    "    def __init__(self, data, label):\n",
    "        self.len = data.shape[0]\n",
    "        self.x_data = torch.from_numpy(data).type(torch.float32)\n",
    "        self.y_data = torch.from_numpy(label).type(torch.float32)\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a69f3f89",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = BlockChainDataset(Xtrain1_minmax, Ytrain1)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14cf2abc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af6478ab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# design model using class\n",
    "class Lat(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Lat, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 64)\n",
    "        self.fc2 = nn.Linear(64, 8)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(8, 1)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "model = Lat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6f533b5c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# net = nn.Sequential(\n",
    "#     nn.Linear(2, 64), nn.BatchNorm1d(64), nn.Dropout(p=0.5), nn.ReLU(),\n",
    "#     nn.Linear(64, 64), nn.BatchNorm1d(64), nn.Dropout(p=0.5), nn.ReLU(),\n",
    "#     nn.Linear(64, 1))\n",
    "\n",
    "\n",
    "# model = net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1044383",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# construct loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f46b24ba",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# traning cycle forward, backward, update\n",
    "def train(epoch):\n",
    "    train_loss = 0.0\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader, 0):\n",
    "        y_pred = model(inputs)\n",
    "        loss = criterion(y_pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * labels.shape[0]\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print('epoch:', epoch + 1, 'train_loss:', train_loss / len(Xtrain1))\n",
    "        \n",
    "\n",
    "def test():\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(Xtest1_tensor)\n",
    "        loss = criterion(y_pred, Ytest1_tensor)\n",
    "        print('test_loss:', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f8827317",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 train_loss: 0.052233589068055156\n",
      "test_loss: tensor(0.0300)\n",
      "epoch: 20 train_loss: 0.05219027679413557\n",
      "test_loss: tensor(0.0300)\n",
      "epoch: 30 train_loss: 0.0521331487223506\n",
      "test_loss: tensor(0.0300)\n",
      "epoch: 40 train_loss: 0.05210463274270296\n",
      "test_loss: tensor(0.0300)\n",
      "epoch: 50 train_loss: 0.052052390016615394\n",
      "test_loss: tensor(0.0300)\n",
      "epoch: 60 train_loss: 0.05200352035462856\n",
      "test_loss: tensor(0.0300)\n",
      "epoch: 70 train_loss: 0.05197533424943686\n",
      "test_loss: tensor(0.0299)\n",
      "epoch: 80 train_loss: 0.05186860896646976\n",
      "test_loss: tensor(0.0300)\n",
      "epoch: 90 train_loss: 0.05173366386443377\n",
      "test_loss: tensor(0.0296)\n",
      "epoch: 100 train_loss: 0.05158418510109186\n",
      "test_loss: tensor(0.0295)\n",
      "epoch: 110 train_loss: 0.051470202207565305\n",
      "test_loss: tensor(0.0293)\n",
      "epoch: 120 train_loss: 0.051355143822729585\n",
      "test_loss: tensor(0.0294)\n",
      "epoch: 130 train_loss: 0.05126049015671015\n",
      "test_loss: tensor(0.0293)\n",
      "epoch: 140 train_loss: 0.051125096157193184\n",
      "test_loss: tensor(0.0293)\n",
      "epoch: 150 train_loss: 0.05101311337202787\n",
      "test_loss: tensor(0.0294)\n",
      "epoch: 160 train_loss: 0.05096117276698351\n",
      "test_loss: tensor(0.0293)\n",
      "epoch: 170 train_loss: 0.05083553455770016\n",
      "test_loss: tensor(0.0293)\n",
      "epoch: 180 train_loss: 0.050761089846491816\n",
      "test_loss: tensor(0.0292)\n",
      "epoch: 190 train_loss: 0.05067995954304934\n",
      "test_loss: tensor(0.0291)\n",
      "epoch: 200 train_loss: 0.05063448902219534\n",
      "test_loss: tensor(0.0291)\n",
      "epoch: 210 train_loss: 0.05052093025296926\n",
      "test_loss: tensor(0.0292)\n",
      "epoch: 220 train_loss: 0.050466019101440905\n",
      "test_loss: tensor(0.0291)\n",
      "epoch: 230 train_loss: 0.050402816571295264\n",
      "test_loss: tensor(0.0291)\n",
      "epoch: 240 train_loss: 0.05033987518399954\n",
      "test_loss: tensor(0.0290)\n",
      "epoch: 250 train_loss: 0.05027086567133665\n",
      "test_loss: tensor(0.0290)\n",
      "epoch: 260 train_loss: 0.050196276791393754\n",
      "test_loss: tensor(0.0290)\n",
      "epoch: 270 train_loss: 0.050128060206770894\n",
      "test_loss: tensor(0.0290)\n",
      "epoch: 280 train_loss: 0.0500606507062912\n",
      "test_loss: tensor(0.0290)\n",
      "epoch: 290 train_loss: 0.05001372154802084\n",
      "test_loss: tensor(0.0290)\n",
      "epoch: 300 train_loss: 0.049944783374667165\n",
      "test_loss: tensor(0.0289)\n",
      "epoch: 310 train_loss: 0.04984585251659155\n",
      "test_loss: tensor(0.0290)\n",
      "epoch: 320 train_loss: 0.04976984616369009\n",
      "test_loss: tensor(0.0289)\n",
      "epoch: 330 train_loss: 0.049720606207847594\n",
      "test_loss: tensor(0.0289)\n",
      "epoch: 340 train_loss: 0.04967683851718903\n",
      "test_loss: tensor(0.0289)\n",
      "epoch: 350 train_loss: 0.04960587657988071\n",
      "test_loss: tensor(0.0289)\n",
      "epoch: 360 train_loss: 0.04951446410268545\n",
      "test_loss: tensor(0.0289)\n",
      "epoch: 370 train_loss: 0.04947999939322471\n",
      "test_loss: tensor(0.0288)\n",
      "epoch: 380 train_loss: 0.04944410137832165\n",
      "test_loss: tensor(0.0287)\n",
      "epoch: 390 train_loss: 0.04937248956412077\n",
      "test_loss: tensor(0.0287)\n",
      "epoch: 400 train_loss: 0.049285407178103924\n",
      "test_loss: tensor(0.0287)\n",
      "epoch: 410 train_loss: 0.04924636799842119\n",
      "test_loss: tensor(0.0288)\n",
      "epoch: 420 train_loss: 0.04918697066605091\n",
      "test_loss: tensor(0.0287)\n",
      "epoch: 430 train_loss: 0.04912851862609387\n",
      "test_loss: tensor(0.0287)\n",
      "epoch: 440 train_loss: 0.04905689638108015\n",
      "test_loss: tensor(0.0287)\n",
      "epoch: 450 train_loss: 0.04897989314049482\n",
      "test_loss: tensor(0.0287)\n",
      "epoch: 460 train_loss: 0.04891898911446333\n",
      "test_loss: tensor(0.0287)\n",
      "epoch: 470 train_loss: 0.048822507821023466\n",
      "test_loss: tensor(0.0288)\n",
      "epoch: 480 train_loss: 0.04876113254576921\n",
      "test_loss: tensor(0.0288)\n",
      "epoch: 490 train_loss: 0.0487046655267477\n",
      "test_loss: tensor(0.0287)\n",
      "epoch: 500 train_loss: 0.048668266646564005\n",
      "test_loss: tensor(0.0286)\n",
      "epoch: 510 train_loss: 0.04859138708561659\n",
      "test_loss: tensor(0.0286)\n",
      "epoch: 520 train_loss: 0.04853126220405102\n",
      "test_loss: tensor(0.0285)\n",
      "epoch: 530 train_loss: 0.048452583700418474\n",
      "test_loss: tensor(0.0286)\n",
      "epoch: 540 train_loss: 0.04842930398881436\n",
      "test_loss: tensor(0.0285)\n",
      "epoch: 550 train_loss: 0.04836247209459543\n",
      "test_loss: tensor(0.0284)\n",
      "epoch: 560 train_loss: 0.048274966143071654\n",
      "test_loss: tensor(0.0285)\n",
      "epoch: 570 train_loss: 0.04820651207119227\n",
      "test_loss: tensor(0.0284)\n",
      "epoch: 580 train_loss: 0.04815631341189146\n",
      "test_loss: tensor(0.0283)\n",
      "epoch: 590 train_loss: 0.048132617957890034\n",
      "test_loss: tensor(0.0283)\n",
      "epoch: 600 train_loss: 0.048063458502292634\n",
      "test_loss: tensor(0.0283)\n",
      "epoch: 610 train_loss: 0.048009775765240195\n",
      "test_loss: tensor(0.0282)\n",
      "epoch: 620 train_loss: 0.04793699253350496\n",
      "test_loss: tensor(0.0282)\n",
      "epoch: 630 train_loss: 0.0478500721976161\n",
      "test_loss: tensor(0.0281)\n",
      "epoch: 640 train_loss: 0.04776755105704069\n",
      "test_loss: tensor(0.0282)\n",
      "epoch: 650 train_loss: 0.0477584395557642\n",
      "test_loss: tensor(0.0281)\n",
      "epoch: 660 train_loss: 0.047685954719781876\n",
      "test_loss: tensor(0.0280)\n",
      "epoch: 670 train_loss: 0.04765084814280272\n",
      "test_loss: tensor(0.0280)\n",
      "epoch: 680 train_loss: 0.0475748598575592\n",
      "test_loss: tensor(0.0281)\n",
      "epoch: 690 train_loss: 0.04749040380120277\n",
      "test_loss: tensor(0.0280)\n",
      "epoch: 700 train_loss: 0.047444268316030505\n",
      "test_loss: tensor(0.0280)\n",
      "epoch: 710 train_loss: 0.04740757178515196\n",
      "test_loss: tensor(0.0279)\n",
      "epoch: 720 train_loss: 0.047327290289103985\n",
      "test_loss: tensor(0.0279)\n",
      "epoch: 730 train_loss: 0.04730559065937996\n",
      "test_loss: tensor(0.0278)\n",
      "epoch: 740 train_loss: 0.04721515104174614\n",
      "test_loss: tensor(0.0279)\n",
      "epoch: 750 train_loss: 0.04720209315419197\n",
      "test_loss: tensor(0.0278)\n",
      "epoch: 760 train_loss: 0.04712336473166943\n",
      "test_loss: tensor(0.0277)\n",
      "epoch: 770 train_loss: 0.0470579918473959\n",
      "test_loss: tensor(0.0278)\n",
      "epoch: 780 train_loss: 0.04700143411755562\n",
      "test_loss: tensor(0.0277)\n",
      "epoch: 790 train_loss: 0.04694016724824905\n",
      "test_loss: tensor(0.0277)\n",
      "epoch: 800 train_loss: 0.046920040622353554\n",
      "test_loss: tensor(0.0276)\n",
      "epoch: 810 train_loss: 0.046826372109353545\n",
      "test_loss: tensor(0.0277)\n",
      "epoch: 820 train_loss: 0.046777686662971975\n",
      "test_loss: tensor(0.0276)\n",
      "epoch: 830 train_loss: 0.0467553585767746\n",
      "test_loss: tensor(0.0276)\n",
      "epoch: 840 train_loss: 0.04671349599957466\n",
      "test_loss: tensor(0.0276)\n",
      "epoch: 850 train_loss: 0.04664166886359453\n",
      "test_loss: tensor(0.0276)\n",
      "epoch: 860 train_loss: 0.046592542342841624\n",
      "test_loss: tensor(0.0276)\n",
      "epoch: 870 train_loss: 0.04657991975545883\n",
      "test_loss: tensor(0.0275)\n",
      "epoch: 880 train_loss: 0.04653749968856573\n",
      "test_loss: tensor(0.0274)\n",
      "epoch: 890 train_loss: 0.04645224381238222\n",
      "test_loss: tensor(0.0276)\n",
      "epoch: 900 train_loss: 0.04639640748500824\n",
      "test_loss: tensor(0.0275)\n",
      "epoch: 910 train_loss: 0.04638173040002584\n",
      "test_loss: tensor(0.0275)\n",
      "epoch: 920 train_loss: 0.04633430205285549\n",
      "test_loss: tensor(0.0275)\n",
      "epoch: 930 train_loss: 0.04626336432993412\n",
      "test_loss: tensor(0.0275)\n",
      "epoch: 940 train_loss: 0.046202227286994454\n",
      "test_loss: tensor(0.0275)\n",
      "epoch: 950 train_loss: 0.04621634390205145\n",
      "test_loss: tensor(0.0274)\n",
      "epoch: 960 train_loss: 0.04616192802786827\n",
      "test_loss: tensor(0.0274)\n",
      "epoch: 970 train_loss: 0.04608750138431787\n",
      "test_loss: tensor(0.0274)\n",
      "epoch: 980 train_loss: 0.046056225709617135\n",
      "test_loss: tensor(0.0273)\n",
      "epoch: 990 train_loss: 0.046007685363292694\n",
      "test_loss: tensor(0.0274)\n",
      "epoch: 1000 train_loss: 0.045960959233343604\n",
      "test_loss: tensor(0.0273)\n",
      "epoch: 1010 train_loss: 0.0459060775116086\n",
      "test_loss: tensor(0.0274)\n",
      "epoch: 1020 train_loss: 0.04584939926862717\n",
      "test_loss: tensor(0.0274)\n",
      "epoch: 1030 train_loss: 0.04581367708742619\n",
      "test_loss: tensor(0.0274)\n",
      "epoch: 1040 train_loss: 0.045774138905107974\n",
      "test_loss: tensor(0.0274)\n",
      "epoch: 1050 train_loss: 0.045719041116535665\n",
      "test_loss: tensor(0.0274)\n",
      "epoch: 1060 train_loss: 0.045683898776769635\n",
      "test_loss: tensor(0.0273)\n",
      "epoch: 1070 train_loss: 0.04567887652665377\n",
      "test_loss: tensor(0.0272)\n",
      "epoch: 1080 train_loss: 0.04559304751455784\n",
      "test_loss: tensor(0.0273)\n",
      "epoch: 1090 train_loss: 0.04554853532463312\n",
      "test_loss: tensor(0.0272)\n",
      "epoch: 1100 train_loss: 0.04550969451665878\n",
      "test_loss: tensor(0.0272)\n",
      "epoch: 1110 train_loss: 0.04546235334128142\n",
      "test_loss: tensor(0.0273)\n",
      "epoch: 1120 train_loss: 0.04540536683052778\n",
      "test_loss: tensor(0.0272)\n",
      "epoch: 1130 train_loss: 0.04537451080977917\n",
      "test_loss: tensor(0.0272)\n",
      "epoch: 1140 train_loss: 0.04532783757895231\n",
      "test_loss: tensor(0.0272)\n",
      "epoch: 1150 train_loss: 0.04522760231047869\n",
      "test_loss: tensor(0.0273)\n",
      "epoch: 1160 train_loss: 0.0452012063935399\n",
      "test_loss: tensor(0.0272)\n",
      "epoch: 1170 train_loss: 0.04512429889291525\n",
      "test_loss: tensor(0.0272)\n",
      "epoch: 1180 train_loss: 0.04507763665169477\n",
      "test_loss: tensor(0.0272)\n",
      "epoch: 1190 train_loss: 0.04506685752421617\n",
      "test_loss: tensor(0.0270)\n",
      "epoch: 1200 train_loss: 0.04495807588100433\n",
      "test_loss: tensor(0.0269)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1210 train_loss: 0.04490919839590788\n",
      "test_loss: tensor(0.0269)\n",
      "epoch: 1220 train_loss: 0.044886069186031816\n",
      "test_loss: tensor(0.0267)\n",
      "epoch: 1230 train_loss: 0.044877889566123486\n",
      "test_loss: tensor(0.0267)\n",
      "epoch: 1240 train_loss: 0.04477553674951196\n",
      "test_loss: tensor(0.0268)\n",
      "epoch: 1250 train_loss: 0.044747271295636895\n",
      "test_loss: tensor(0.0268)\n",
      "epoch: 1260 train_loss: 0.044730660133063795\n",
      "test_loss: tensor(0.0267)\n",
      "epoch: 1270 train_loss: 0.044691288471221925\n",
      "test_loss: tensor(0.0267)\n",
      "epoch: 1280 train_loss: 0.04461910193786025\n",
      "test_loss: tensor(0.0269)\n",
      "epoch: 1290 train_loss: 0.044587109610438345\n",
      "test_loss: tensor(0.0267)\n",
      "epoch: 1300 train_loss: 0.044579712115228175\n",
      "test_loss: tensor(0.0267)\n",
      "epoch: 1310 train_loss: 0.04455103762447834\n",
      "test_loss: tensor(0.0267)\n",
      "epoch: 1320 train_loss: 0.04446751531213522\n",
      "test_loss: tensor(0.0268)\n",
      "epoch: 1330 train_loss: 0.04445881461724639\n",
      "test_loss: tensor(0.0267)\n",
      "epoch: 1340 train_loss: 0.044440907519310714\n",
      "test_loss: tensor(0.0267)\n",
      "epoch: 1350 train_loss: 0.04440101776272058\n",
      "test_loss: tensor(0.0267)\n",
      "epoch: 1360 train_loss: 0.044367026537656784\n",
      "test_loss: tensor(0.0267)\n",
      "epoch: 1370 train_loss: 0.04431986566632986\n",
      "test_loss: tensor(0.0268)\n",
      "epoch: 1380 train_loss: 0.044284163415431975\n",
      "test_loss: tensor(0.0267)\n",
      "epoch: 1390 train_loss: 0.04424663763493299\n",
      "test_loss: tensor(0.0268)\n",
      "epoch: 1400 train_loss: 0.04421721175312996\n",
      "test_loss: tensor(0.0267)\n",
      "epoch: 1410 train_loss: 0.04419048437848687\n",
      "test_loss: tensor(0.0266)\n",
      "epoch: 1420 train_loss: 0.04415487637743354\n",
      "test_loss: tensor(0.0267)\n",
      "epoch: 1430 train_loss: 0.04405869655311108\n",
      "test_loss: tensor(0.0268)\n",
      "epoch: 1440 train_loss: 0.04403065051883459\n",
      "test_loss: tensor(0.0268)\n",
      "epoch: 1450 train_loss: 0.04398849569261074\n",
      "test_loss: tensor(0.0268)\n",
      "epoch: 1460 train_loss: 0.04397569866850972\n",
      "test_loss: tensor(0.0267)\n",
      "epoch: 1470 train_loss: 0.043937748018652203\n",
      "test_loss: tensor(0.0267)\n",
      "epoch: 1480 train_loss: 0.04390501175075769\n",
      "test_loss: tensor(0.0266)\n",
      "epoch: 1490 train_loss: 0.04392232540994882\n",
      "test_loss: tensor(0.0266)\n",
      "epoch: 1500 train_loss: 0.043879874795675275\n",
      "test_loss: tensor(0.0266)\n",
      "epoch: 1510 train_loss: 0.043865214101970196\n",
      "test_loss: tensor(0.0265)\n",
      "epoch: 1520 train_loss: 0.0438366019167006\n",
      "test_loss: tensor(0.0264)\n",
      "epoch: 1530 train_loss: 0.04376429757103324\n",
      "test_loss: tensor(0.0265)\n",
      "epoch: 1540 train_loss: 0.043744065798819065\n",
      "test_loss: tensor(0.0265)\n",
      "epoch: 1550 train_loss: 0.04369839699938893\n",
      "test_loss: tensor(0.0266)\n",
      "epoch: 1560 train_loss: 0.043654698971658946\n",
      "test_loss: tensor(0.0266)\n",
      "epoch: 1570 train_loss: 0.04363356083631516\n",
      "test_loss: tensor(0.0266)\n",
      "epoch: 1580 train_loss: 0.043616801220923665\n",
      "test_loss: tensor(0.0266)\n",
      "epoch: 1590 train_loss: 0.04357645846903324\n",
      "test_loss: tensor(0.0265)\n",
      "epoch: 1600 train_loss: 0.043561904598027466\n",
      "test_loss: tensor(0.0265)\n",
      "epoch: 1610 train_loss: 0.04352310784161091\n",
      "test_loss: tensor(0.0265)\n",
      "epoch: 1620 train_loss: 0.04345338400453329\n",
      "test_loss: tensor(0.0265)\n",
      "epoch: 1630 train_loss: 0.04341728957369924\n",
      "test_loss: tensor(0.0265)\n",
      "epoch: 1640 train_loss: 0.043384366668760777\n",
      "test_loss: tensor(0.0264)\n",
      "epoch: 1650 train_loss: 0.043366363272070885\n",
      "test_loss: tensor(0.0263)\n",
      "epoch: 1660 train_loss: 0.04331708867102861\n",
      "test_loss: tensor(0.0264)\n",
      "epoch: 1670 train_loss: 0.04329548589885235\n",
      "test_loss: tensor(0.0263)\n",
      "epoch: 1680 train_loss: 0.043246311135590076\n",
      "test_loss: tensor(0.0263)\n",
      "epoch: 1690 train_loss: 0.043237799778580666\n",
      "test_loss: tensor(0.0262)\n",
      "epoch: 1700 train_loss: 0.04318959917873144\n",
      "test_loss: tensor(0.0262)\n",
      "epoch: 1710 train_loss: 0.043202588055282834\n",
      "test_loss: tensor(0.0261)\n",
      "epoch: 1720 train_loss: 0.04317807462066412\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 1730 train_loss: 0.04317515166476369\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 1740 train_loss: 0.04308982044458389\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 1750 train_loss: 0.04307999461889267\n",
      "test_loss: tensor(0.0258)\n",
      "epoch: 1760 train_loss: 0.04309875061735511\n",
      "test_loss: tensor(0.0259)\n",
      "epoch: 1770 train_loss: 0.04301098054274917\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 1780 train_loss: 0.043042843136936425\n",
      "test_loss: tensor(0.0259)\n",
      "epoch: 1790 train_loss: 0.04294988522306085\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 1800 train_loss: 0.04298926619812846\n",
      "test_loss: tensor(0.0259)\n",
      "epoch: 1810 train_loss: 0.042906572483479975\n",
      "test_loss: tensor(0.0258)\n",
      "epoch: 1820 train_loss: 0.042872908245772126\n",
      "test_loss: tensor(0.0259)\n",
      "epoch: 1830 train_loss: 0.04290072247385979\n",
      "test_loss: tensor(0.0258)\n",
      "epoch: 1840 train_loss: 0.042832175455987456\n",
      "test_loss: tensor(0.0258)\n",
      "epoch: 1850 train_loss: 0.04279017820954323\n",
      "test_loss: tensor(0.0259)\n",
      "epoch: 1860 train_loss: 0.042822431121021506\n",
      "test_loss: tensor(0.0258)\n",
      "epoch: 1870 train_loss: 0.0427472454495728\n",
      "test_loss: tensor(0.0258)\n",
      "epoch: 1880 train_loss: 0.04270806862041354\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 1890 train_loss: 0.042755851056426764\n",
      "test_loss: tensor(0.0258)\n",
      "epoch: 1900 train_loss: 0.042681252025067805\n",
      "test_loss: tensor(0.0258)\n",
      "epoch: 1910 train_loss: 0.04265487277880311\n",
      "test_loss: tensor(0.0259)\n",
      "epoch: 1920 train_loss: 0.04261080706492067\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 1930 train_loss: 0.04259432200342417\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 1940 train_loss: 0.0425889253616333\n",
      "test_loss: tensor(0.0259)\n",
      "epoch: 1950 train_loss: 0.042555836401879786\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 1960 train_loss: 0.04258396262302995\n",
      "test_loss: tensor(0.0259)\n",
      "epoch: 1970 train_loss: 0.04256188590079546\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 1980 train_loss: 0.04254139270633459\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 1990 train_loss: 0.04251819895580411\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2000 train_loss: 0.04249272858723998\n",
      "test_loss: tensor(0.0259)\n",
      "epoch: 2010 train_loss: 0.042472070828080175\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2020 train_loss: 0.042448205314576624\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2030 train_loss: 0.0424424359574914\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2040 train_loss: 0.04243258461356163\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2050 train_loss: 0.04235542509704828\n",
      "test_loss: tensor(0.0261)\n",
      "epoch: 2060 train_loss: 0.042340127378702165\n",
      "test_loss: tensor(0.0261)\n",
      "epoch: 2070 train_loss: 0.042307743802666664\n",
      "test_loss: tensor(0.0261)\n",
      "epoch: 2080 train_loss: 0.042306060809642075\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2090 train_loss: 0.042275357991456985\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2100 train_loss: 0.04227369651198387\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2110 train_loss: 0.042273478023707865\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2120 train_loss: 0.042263761069625615\n",
      "test_loss: tensor(0.0261)\n",
      "epoch: 2130 train_loss: 0.042236121464520694\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2140 train_loss: 0.04217347530648112\n",
      "test_loss: tensor(0.0261)\n",
      "epoch: 2150 train_loss: 0.04214355424046516\n",
      "test_loss: tensor(0.0261)\n",
      "epoch: 2160 train_loss: 0.04214693708345294\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2170 train_loss: 0.04212814532220364\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2180 train_loss: 0.04213096089661121\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2190 train_loss: 0.04211524510756135\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2200 train_loss: 0.04205462327226996\n",
      "test_loss: tensor(0.0261)\n",
      "epoch: 2210 train_loss: 0.042038137651979925\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2220 train_loss: 0.042062221001833676\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2230 train_loss: 0.04199752304702997\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2240 train_loss: 0.04198972741141915\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2250 train_loss: 0.042004726454615594\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2260 train_loss: 0.04196295998990536\n",
      "test_loss: tensor(0.0259)\n",
      "epoch: 2270 train_loss: 0.04195911204442382\n",
      "test_loss: tensor(0.0259)\n",
      "epoch: 2280 train_loss: 0.04191387183964253\n",
      "test_loss: tensor(0.0259)\n",
      "epoch: 2290 train_loss: 0.04191097989678383\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2300 train_loss: 0.04187512258067727\n",
      "test_loss: tensor(0.0259)\n",
      "epoch: 2310 train_loss: 0.041888292878866196\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2320 train_loss: 0.04185623219236732\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2330 train_loss: 0.04183250330388546\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2340 train_loss: 0.04181788433343172\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2350 train_loss: 0.0417975751683116\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2360 train_loss: 0.04181341929361224\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2370 train_loss: 0.041773412656039\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2380 train_loss: 0.041773566231131556\n",
      "test_loss: tensor(0.0259)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2390 train_loss: 0.041733233630657195\n",
      "test_loss: tensor(0.0259)\n",
      "epoch: 2400 train_loss: 0.04171702554449439\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2410 train_loss: 0.041728274524211885\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2420 train_loss: 0.041691673919558525\n",
      "test_loss: tensor(0.0259)\n",
      "epoch: 2430 train_loss: 0.041673250030726194\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2440 train_loss: 0.041664407774806025\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2450 train_loss: 0.04165559923276305\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2460 train_loss: 0.0416522653773427\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2470 train_loss: 0.04160564299672842\n",
      "test_loss: tensor(0.0261)\n",
      "epoch: 2480 train_loss: 0.04157986268401146\n",
      "test_loss: tensor(0.0261)\n",
      "epoch: 2490 train_loss: 0.04157840646803379\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2500 train_loss: 0.041568286903202536\n",
      "test_loss: tensor(0.0261)\n",
      "epoch: 2510 train_loss: 0.041552466060966256\n",
      "test_loss: tensor(0.0261)\n",
      "epoch: 2520 train_loss: 0.04153741719201207\n",
      "test_loss: tensor(0.0261)\n",
      "epoch: 2530 train_loss: 0.041534722223877905\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2540 train_loss: 0.041509007569402456\n",
      "test_loss: tensor(0.0260)\n",
      "epoch: 2550 train_loss: 0.041505268588662145\n",
      "test_loss: tensor(0.0261)\n",
      "epoch: 2560 train_loss: 0.04151863781735301\n",
      "test_loss: tensor(0.0261)\n",
      "epoch: 2570 train_loss: 0.04149999963119626\n",
      "test_loss: tensor(0.0262)\n",
      "epoch: 2580 train_loss: 0.0414491998963058\n",
      "test_loss: tensor(0.0262)\n",
      "epoch: 2590 train_loss: 0.04145907433703542\n",
      "test_loss: tensor(0.0262)\n",
      "epoch: 2600 train_loss: 0.041432980075478555\n",
      "test_loss: tensor(0.0263)\n",
      "epoch: 2610 train_loss: 0.041410704143345356\n",
      "test_loss: tensor(0.0263)\n",
      "epoch: 2620 train_loss: 0.041416273918002844\n",
      "test_loss: tensor(0.0264)\n",
      "epoch: 2630 train_loss: 0.04142311653122306\n",
      "test_loss: tensor(0.0263)\n",
      "epoch: 2640 train_loss: 0.04137544771656394\n",
      "test_loss: tensor(0.0264)\n",
      "epoch: 2650 train_loss: 0.04135944042354822\n",
      "test_loss: tensor(0.0263)\n",
      "epoch: 2660 train_loss: 0.041345851961523294\n",
      "test_loss: tensor(0.0263)\n",
      "epoch: 2670 train_loss: 0.0413346485234797\n",
      "test_loss: tensor(0.0263)\n",
      "epoch: 2680 train_loss: 0.04133234154433012\n",
      "test_loss: tensor(0.0262)\n",
      "epoch: 2690 train_loss: 0.041319791693240404\n",
      "test_loss: tensor(0.0262)\n",
      "epoch: 2700 train_loss: 0.0413038918748498\n",
      "test_loss: tensor(0.0262)\n",
      "epoch: 2710 train_loss: 0.041293648071587086\n",
      "test_loss: tensor(0.0263)\n",
      "epoch: 2720 train_loss: 0.04130947981029749\n",
      "test_loss: tensor(0.0263)\n",
      "epoch: 2730 train_loss: 0.041291515342891216\n",
      "test_loss: tensor(0.0264)\n",
      "epoch: 2740 train_loss: 0.04127921853214502\n",
      "test_loss: tensor(0.0263)\n",
      "epoch: 2750 train_loss: 0.0412745887413621\n",
      "test_loss: tensor(0.0264)\n",
      "epoch: 2760 train_loss: 0.04123181449249387\n",
      "test_loss: tensor(0.0263)\n",
      "epoch: 2770 train_loss: 0.04122598217800259\n",
      "test_loss: tensor(0.0264)\n",
      "epoch: 2780 train_loss: 0.04122965820133686\n",
      "test_loss: tensor(0.0264)\n",
      "epoch: 2790 train_loss: 0.041229845583438875\n",
      "test_loss: tensor(0.0264)\n",
      "epoch: 2800 train_loss: 0.04123206352815032\n",
      "test_loss: tensor(0.0263)\n",
      "epoch: 2810 train_loss: 0.041173689160496\n",
      "test_loss: tensor(0.0264)\n",
      "epoch: 2820 train_loss: 0.041194220818579194\n",
      "test_loss: tensor(0.0264)\n",
      "epoch: 2830 train_loss: 0.04120318880304694\n",
      "test_loss: tensor(0.0264)\n",
      "epoch: 2840 train_loss: 0.04118944779038429\n",
      "test_loss: tensor(0.0264)\n",
      "epoch: 2850 train_loss: 0.04115935750305653\n",
      "test_loss: tensor(0.0265)\n",
      "epoch: 2860 train_loss: 0.04115353850647807\n",
      "test_loss: tensor(0.0264)\n",
      "epoch: 2870 train_loss: 0.041155855357646945\n",
      "test_loss: tensor(0.0265)\n",
      "epoch: 2880 train_loss: 0.041168298479169606\n",
      "test_loss: tensor(0.0265)\n",
      "epoch: 2890 train_loss: 0.04113698471337557\n",
      "test_loss: tensor(0.0265)\n",
      "epoch: 2900 train_loss: 0.04112776927649975\n",
      "test_loss: tensor(0.0265)\n",
      "epoch: 2910 train_loss: 0.041141977161169054\n",
      "test_loss: tensor(0.0266)\n",
      "epoch: 2920 train_loss: 0.041112329531461\n",
      "test_loss: tensor(0.0265)\n",
      "epoch: 2930 train_loss: 0.041104592476040126\n",
      "test_loss: tensor(0.0264)\n",
      "epoch: 2940 train_loss: 0.041138661466538905\n",
      "test_loss: tensor(0.0267)\n",
      "epoch: 2950 train_loss: 0.0410864251665771\n",
      "test_loss: tensor(0.0265)\n",
      "epoch: 2960 train_loss: 0.04107208140194416\n",
      "test_loss: tensor(0.0265)\n",
      "epoch: 2970 train_loss: 0.041102582681924106\n",
      "test_loss: tensor(0.0267)\n",
      "epoch: 2980 train_loss: 0.041076624672859906\n",
      "test_loss: tensor(0.0266)\n",
      "epoch: 2990 train_loss: 0.041085847094655036\n",
      "test_loss: tensor(0.0267)\n",
      "epoch: 3000 train_loss: 0.04105629166588187\n",
      "test_loss: tensor(0.0266)\n",
      "epoch: 3010 train_loss: 0.041058930289000276\n",
      "test_loss: tensor(0.0266)\n",
      "epoch: 3020 train_loss: 0.04104440584778786\n",
      "test_loss: tensor(0.0268)\n",
      "epoch: 3030 train_loss: 0.041035154927521945\n",
      "test_loss: tensor(0.0267)\n",
      "epoch: 3040 train_loss: 0.04102943083271384\n",
      "test_loss: tensor(0.0267)\n",
      "epoch: 3050 train_loss: 0.04101970214396715\n",
      "test_loss: tensor(0.0267)\n",
      "epoch: 3060 train_loss: 0.04100806256756186\n",
      "test_loss: tensor(0.0267)\n",
      "epoch: 3070 train_loss: 0.04100155448541045\n",
      "test_loss: tensor(0.0267)\n",
      "epoch: 3080 train_loss: 0.040993493888527154\n",
      "test_loss: tensor(0.0268)\n",
      "epoch: 3090 train_loss: 0.040991169027984144\n",
      "test_loss: tensor(0.0269)\n",
      "epoch: 3100 train_loss: 0.040988716017454865\n",
      "test_loss: tensor(0.0267)\n",
      "epoch: 3110 train_loss: 0.04099902398884296\n",
      "test_loss: tensor(0.0269)\n",
      "epoch: 3120 train_loss: 0.0409968257881701\n",
      "test_loss: tensor(0.0269)\n",
      "epoch: 3130 train_loss: 0.0409964638762176\n",
      "test_loss: tensor(0.0269)\n",
      "epoch: 3140 train_loss: 0.040967599395662545\n",
      "test_loss: tensor(0.0269)\n",
      "epoch: 3150 train_loss: 0.040974977798759936\n",
      "test_loss: tensor(0.0269)\n",
      "epoch: 3160 train_loss: 0.04096193052828312\n",
      "test_loss: tensor(0.0269)\n",
      "epoch: 3170 train_loss: 0.04097465323284268\n",
      "test_loss: tensor(0.0270)\n",
      "epoch: 3180 train_loss: 0.040965876448899506\n",
      "test_loss: tensor(0.0270)\n",
      "epoch: 3190 train_loss: 0.04093686165288091\n",
      "test_loss: tensor(0.0270)\n",
      "epoch: 3200 train_loss: 0.04095778539776802\n",
      "test_loss: tensor(0.0270)\n",
      "epoch: 3210 train_loss: 0.04093650383874774\n",
      "test_loss: tensor(0.0270)\n",
      "epoch: 3220 train_loss: 0.040955633576959374\n",
      "test_loss: tensor(0.0271)\n",
      "epoch: 3230 train_loss: 0.04091196153312922\n",
      "test_loss: tensor(0.0270)\n",
      "epoch: 3240 train_loss: 0.040897511318325995\n",
      "test_loss: tensor(0.0270)\n",
      "epoch: 3250 train_loss: 0.040906406659632924\n",
      "test_loss: tensor(0.0270)\n",
      "epoch: 3260 train_loss: 0.04089998584240675\n",
      "test_loss: tensor(0.0271)\n",
      "epoch: 3270 train_loss: 0.040925250854343176\n",
      "test_loss: tensor(0.0271)\n",
      "epoch: 3280 train_loss: 0.04090235186740756\n",
      "test_loss: tensor(0.0271)\n",
      "epoch: 3290 train_loss: 0.04091250086203217\n",
      "test_loss: tensor(0.0271)\n",
      "epoch: 3300 train_loss: 0.04091067304834724\n",
      "test_loss: tensor(0.0271)\n",
      "epoch: 3310 train_loss: 0.0408779488876462\n",
      "test_loss: tensor(0.0269)\n",
      "epoch: 3320 train_loss: 0.040859575383365154\n",
      "test_loss: tensor(0.0272)\n",
      "epoch: 3330 train_loss: 0.04084592582657933\n",
      "test_loss: tensor(0.0271)\n",
      "epoch: 3340 train_loss: 0.04088841713964939\n",
      "test_loss: tensor(0.0272)\n",
      "epoch: 3350 train_loss: 0.040874111093580724\n",
      "test_loss: tensor(0.0271)\n",
      "epoch: 3360 train_loss: 0.04085300303995609\n",
      "test_loss: tensor(0.0272)\n",
      "epoch: 3370 train_loss: 0.04088406385853886\n",
      "test_loss: tensor(0.0273)\n",
      "epoch: 3380 train_loss: 0.04084584303200245\n",
      "test_loss: tensor(0.0272)\n",
      "epoch: 3390 train_loss: 0.04084967393428087\n",
      "test_loss: tensor(0.0273)\n",
      "epoch: 3400 train_loss: 0.04084229143336415\n",
      "test_loss: tensor(0.0272)\n",
      "epoch: 3410 train_loss: 0.04086508024483919\n",
      "test_loss: tensor(0.0273)\n",
      "epoch: 3420 train_loss: 0.040840549487620594\n",
      "test_loss: tensor(0.0272)\n",
      "epoch: 3430 train_loss: 0.04081248566508293\n",
      "test_loss: tensor(0.0273)\n",
      "epoch: 3440 train_loss: 0.04082184098660946\n",
      "test_loss: tensor(0.0272)\n",
      "epoch: 3450 train_loss: 0.040836159233003856\n",
      "test_loss: tensor(0.0273)\n",
      "epoch: 3460 train_loss: 0.04080541264265776\n",
      "test_loss: tensor(0.0272)\n",
      "epoch: 3470 train_loss: 0.04080503024160862\n",
      "test_loss: tensor(0.0273)\n",
      "epoch: 3480 train_loss: 0.04080438744276762\n",
      "test_loss: tensor(0.0273)\n",
      "epoch: 3490 train_loss: 0.04083715034648776\n",
      "test_loss: tensor(0.0275)\n",
      "epoch: 3500 train_loss: 0.04079910116270184\n",
      "test_loss: tensor(0.0275)\n",
      "epoch: 3510 train_loss: 0.04078076565638185\n",
      "test_loss: tensor(0.0273)\n",
      "epoch: 3520 train_loss: 0.04077992150560021\n",
      "test_loss: tensor(0.0275)\n",
      "epoch: 3530 train_loss: 0.04078638823702931\n",
      "test_loss: tensor(0.0274)\n",
      "epoch: 3540 train_loss: 0.04076272901147604\n",
      "test_loss: tensor(0.0275)\n",
      "epoch: 3550 train_loss: 0.04078884990885854\n",
      "test_loss: tensor(0.0275)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3560 train_loss: 0.04075597831979394\n",
      "test_loss: tensor(0.0275)\n",
      "epoch: 3570 train_loss: 0.04074216037988663\n",
      "test_loss: tensor(0.0274)\n",
      "epoch: 3580 train_loss: 0.04075707821175456\n",
      "test_loss: tensor(0.0274)\n",
      "epoch: 3590 train_loss: 0.04073150521144271\n",
      "test_loss: tensor(0.0276)\n",
      "epoch: 3600 train_loss: 0.040778305102139714\n",
      "test_loss: tensor(0.0276)\n",
      "epoch: 3610 train_loss: 0.04074556352570653\n",
      "test_loss: tensor(0.0275)\n",
      "epoch: 3620 train_loss: 0.04074637740850449\n",
      "test_loss: tensor(0.0274)\n",
      "epoch: 3630 train_loss: 0.040740808844566344\n",
      "test_loss: tensor(0.0275)\n",
      "epoch: 3640 train_loss: 0.040728802978992465\n",
      "test_loss: tensor(0.0274)\n",
      "epoch: 3650 train_loss: 0.04071098323911428\n",
      "test_loss: tensor(0.0274)\n",
      "epoch: 3660 train_loss: 0.04070665091276169\n",
      "test_loss: tensor(0.0276)\n",
      "epoch: 3670 train_loss: 0.040751616656780246\n",
      "test_loss: tensor(0.0276)\n",
      "epoch: 3680 train_loss: 0.04072785498574376\n",
      "test_loss: tensor(0.0276)\n",
      "epoch: 3690 train_loss: 0.04072588579729199\n",
      "test_loss: tensor(0.0274)\n",
      "epoch: 3700 train_loss: 0.04069987311959267\n",
      "test_loss: tensor(0.0276)\n",
      "epoch: 3710 train_loss: 0.040716209821403025\n",
      "test_loss: tensor(0.0274)\n",
      "epoch: 3720 train_loss: 0.040700759179890154\n",
      "test_loss: tensor(0.0275)\n",
      "epoch: 3730 train_loss: 0.04068583594635129\n",
      "test_loss: tensor(0.0277)\n",
      "epoch: 3740 train_loss: 0.040692965034395456\n",
      "test_loss: tensor(0.0276)\n",
      "epoch: 3750 train_loss: 0.04069307502359152\n",
      "test_loss: tensor(0.0276)\n",
      "epoch: 3760 train_loss: 0.04067041333764791\n",
      "test_loss: tensor(0.0274)\n",
      "epoch: 3770 train_loss: 0.04067768109962344\n",
      "test_loss: tensor(0.0279)\n",
      "epoch: 3780 train_loss: 0.040678652189671996\n",
      "test_loss: tensor(0.0277)\n",
      "epoch: 3790 train_loss: 0.04071129458025098\n",
      "test_loss: tensor(0.0277)\n",
      "epoch: 3800 train_loss: 0.04067520815879107\n",
      "test_loss: tensor(0.0276)\n",
      "epoch: 3810 train_loss: 0.04068734850734472\n",
      "test_loss: tensor(0.0277)\n",
      "epoch: 3820 train_loss: 0.04065836006775499\n",
      "test_loss: tensor(0.0274)\n",
      "epoch: 3830 train_loss: 0.040660303086042404\n",
      "test_loss: tensor(0.0277)\n",
      "epoch: 3840 train_loss: 0.0406555512920022\n",
      "test_loss: tensor(0.0278)\n",
      "epoch: 3850 train_loss: 0.040664727240800856\n",
      "test_loss: tensor(0.0277)\n",
      "epoch: 3860 train_loss: 0.040669399220496415\n",
      "test_loss: tensor(0.0278)\n",
      "epoch: 3870 train_loss: 0.04063833765685558\n",
      "test_loss: tensor(0.0278)\n",
      "epoch: 3880 train_loss: 0.04065002668648958\n",
      "test_loss: tensor(0.0278)\n",
      "epoch: 3890 train_loss: 0.04067551270127297\n",
      "test_loss: tensor(0.0278)\n",
      "epoch: 3900 train_loss: 0.04064075844362378\n",
      "test_loss: tensor(0.0278)\n",
      "epoch: 3910 train_loss: 0.0406281691044569\n",
      "test_loss: tensor(0.0277)\n",
      "epoch: 3920 train_loss: 0.0406394743360579\n",
      "test_loss: tensor(0.0276)\n",
      "epoch: 3930 train_loss: 0.040631492529064415\n",
      "test_loss: tensor(0.0277)\n",
      "epoch: 3940 train_loss: 0.04063841933384538\n",
      "test_loss: tensor(0.0279)\n",
      "epoch: 3950 train_loss: 0.04062813911587\n",
      "test_loss: tensor(0.0278)\n",
      "epoch: 3960 train_loss: 0.04060456994920969\n",
      "test_loss: tensor(0.0278)\n",
      "epoch: 3970 train_loss: 0.040589593909680845\n",
      "test_loss: tensor(0.0279)\n",
      "epoch: 3980 train_loss: 0.04061394426971674\n",
      "test_loss: tensor(0.0279)\n",
      "epoch: 3990 train_loss: 0.04061589865013957\n",
      "test_loss: tensor(0.0277)\n",
      "epoch: 4000 train_loss: 0.04062065854668617\n",
      "test_loss: tensor(0.0278)\n",
      "epoch: 4010 train_loss: 0.04060030533000827\n",
      "test_loss: tensor(0.0279)\n",
      "epoch: 4020 train_loss: 0.040590866841375826\n",
      "test_loss: tensor(0.0280)\n",
      "epoch: 4030 train_loss: 0.04058524155989289\n",
      "test_loss: tensor(0.0280)\n",
      "epoch: 4040 train_loss: 0.040599558316171167\n",
      "test_loss: tensor(0.0279)\n",
      "epoch: 4050 train_loss: 0.040592423360794785\n",
      "test_loss: tensor(0.0278)\n",
      "epoch: 4060 train_loss: 0.04059033021330834\n",
      "test_loss: tensor(0.0279)\n",
      "epoch: 4070 train_loss: 0.040579477697610854\n",
      "test_loss: tensor(0.0278)\n",
      "epoch: 4080 train_loss: 0.04055745005607605\n",
      "test_loss: tensor(0.0279)\n",
      "epoch: 4090 train_loss: 0.04057983485981822\n",
      "test_loss: tensor(0.0280)\n",
      "epoch: 4100 train_loss: 0.0406070196069777\n",
      "test_loss: tensor(0.0277)\n",
      "epoch: 4110 train_loss: 0.04060878688469529\n",
      "test_loss: tensor(0.0278)\n",
      "epoch: 4120 train_loss: 0.04058783240616322\n",
      "test_loss: tensor(0.0279)\n",
      "epoch: 4130 train_loss: 0.0405822491273284\n",
      "test_loss: tensor(0.0281)\n",
      "epoch: 4140 train_loss: 0.040567748993635175\n",
      "test_loss: tensor(0.0279)\n",
      "epoch: 4150 train_loss: 0.04055774183943868\n",
      "test_loss: tensor(0.0279)\n",
      "epoch: 4160 train_loss: 0.04056968502700329\n",
      "test_loss: tensor(0.0280)\n",
      "epoch: 4170 train_loss: 0.04055338483303785\n",
      "test_loss: tensor(0.0279)\n",
      "epoch: 4180 train_loss: 0.040548875275999305\n",
      "test_loss: tensor(0.0280)\n",
      "epoch: 4190 train_loss: 0.040534055605530736\n",
      "test_loss: tensor(0.0279)\n",
      "epoch: 4200 train_loss: 0.04058158835396171\n",
      "test_loss: tensor(0.0281)\n",
      "epoch: 4210 train_loss: 0.040549443755298856\n",
      "test_loss: tensor(0.0281)\n",
      "epoch: 4220 train_loss: 0.0405518407933414\n",
      "test_loss: tensor(0.0280)\n",
      "epoch: 4230 train_loss: 0.04055695552378893\n",
      "test_loss: tensor(0.0280)\n",
      "epoch: 4240 train_loss: 0.04055382953956723\n",
      "test_loss: tensor(0.0278)\n",
      "epoch: 4250 train_loss: 0.04053223766386509\n",
      "test_loss: tensor(0.0278)\n",
      "epoch: 4260 train_loss: 0.04054567599669099\n",
      "test_loss: tensor(0.0278)\n",
      "epoch: 4270 train_loss: 0.04053445616737008\n",
      "test_loss: tensor(0.0279)\n",
      "epoch: 4280 train_loss: 0.040541084948927164\n",
      "test_loss: tensor(0.0280)\n",
      "epoch: 4290 train_loss: 0.04052846422418952\n",
      "test_loss: tensor(0.0278)\n",
      "epoch: 4300 train_loss: 0.04054798977449536\n",
      "test_loss: tensor(0.0280)\n",
      "epoch: 4310 train_loss: 0.04051796710118651\n",
      "test_loss: tensor(0.0280)\n",
      "epoch: 4320 train_loss: 0.04049163842573762\n",
      "test_loss: tensor(0.0280)\n",
      "epoch: 4330 train_loss: 0.040535281784832476\n",
      "test_loss: tensor(0.0280)\n",
      "epoch: 4340 train_loss: 0.040539604146033525\n",
      "test_loss: tensor(0.0281)\n",
      "epoch: 4350 train_loss: 0.04052577959373593\n",
      "test_loss: tensor(0.0280)\n",
      "epoch: 4360 train_loss: 0.040511269401758906\n",
      "test_loss: tensor(0.0278)\n",
      "epoch: 4370 train_loss: 0.04049245398491621\n",
      "test_loss: tensor(0.0278)\n",
      "epoch: 4380 train_loss: 0.04049736242741346\n",
      "test_loss: tensor(0.0280)\n",
      "epoch: 4390 train_loss: 0.04052372053265572\n",
      "test_loss: tensor(0.0281)\n",
      "epoch: 4400 train_loss: 0.04049769202247262\n",
      "test_loss: tensor(0.0281)\n",
      "epoch: 4410 train_loss: 0.040490074455738066\n",
      "test_loss: tensor(0.0281)\n",
      "epoch: 4420 train_loss: 0.04051045933738351\n",
      "test_loss: tensor(0.0281)\n",
      "epoch: 4430 train_loss: 0.04051918452605605\n",
      "test_loss: tensor(0.0281)\n",
      "epoch: 4440 train_loss: 0.04052159795537591\n",
      "test_loss: tensor(0.0281)\n",
      "epoch: 4450 train_loss: 0.040509738586843015\n",
      "test_loss: tensor(0.0280)\n",
      "epoch: 4460 train_loss: 0.04049127381294966\n",
      "test_loss: tensor(0.0281)\n",
      "epoch: 4470 train_loss: 0.0404911101795733\n",
      "test_loss: tensor(0.0280)\n",
      "epoch: 4480 train_loss: 0.04047748548910022\n",
      "test_loss: tensor(0.0281)\n",
      "epoch: 4490 train_loss: 0.040493058040738106\n",
      "test_loss: tensor(0.0282)\n",
      "epoch: 4500 train_loss: 0.04046187177300453\n",
      "test_loss: tensor(0.0281)\n",
      "epoch: 4510 train_loss: 0.04048079205676913\n",
      "test_loss: tensor(0.0281)\n",
      "epoch: 4520 train_loss: 0.040464045479893684\n",
      "test_loss: tensor(0.0281)\n",
      "epoch: 4530 train_loss: 0.04045580811798573\n",
      "test_loss: tensor(0.0282)\n",
      "epoch: 4540 train_loss: 0.04046563012525439\n",
      "test_loss: tensor(0.0282)\n",
      "epoch: 4550 train_loss: 0.04044922906905413\n",
      "test_loss: tensor(0.0281)\n",
      "epoch: 4560 train_loss: 0.0404996694996953\n",
      "test_loss: tensor(0.0281)\n",
      "epoch: 4570 train_loss: 0.04045308930799365\n",
      "test_loss: tensor(0.0281)\n",
      "epoch: 4580 train_loss: 0.0404335149563849\n",
      "test_loss: tensor(0.0281)\n",
      "epoch: 4590 train_loss: 0.04045222494751215\n",
      "test_loss: tensor(0.0281)\n",
      "epoch: 4600 train_loss: 0.04045547991991043\n",
      "test_loss: tensor(0.0282)\n",
      "epoch: 4610 train_loss: 0.04045257549732924\n",
      "test_loss: tensor(0.0279)\n",
      "epoch: 4620 train_loss: 0.040458768419921395\n",
      "test_loss: tensor(0.0280)\n",
      "epoch: 4630 train_loss: 0.04044214906170964\n",
      "test_loss: tensor(0.0281)\n",
      "epoch: 4640 train_loss: 0.04042491819709539\n",
      "test_loss: tensor(0.0282)\n",
      "epoch: 4650 train_loss: 0.04042854439467192\n",
      "test_loss: tensor(0.0280)\n",
      "epoch: 4660 train_loss: 0.04041005223989487\n",
      "test_loss: tensor(0.0282)\n",
      "epoch: 4670 train_loss: 0.04043739233165979\n",
      "test_loss: tensor(0.0282)\n",
      "epoch: 4680 train_loss: 0.0404308682307601\n",
      "test_loss: tensor(0.0282)\n",
      "epoch: 4690 train_loss: 0.04042919296771288\n",
      "test_loss: tensor(0.0281)\n",
      "epoch: 4700 train_loss: 0.040428356546908614\n",
      "test_loss: tensor(0.0281)\n",
      "epoch: 4710 train_loss: 0.040407631732523444\n",
      "test_loss: tensor(0.0281)\n",
      "epoch: 4720 train_loss: 0.040419927425682546\n",
      "test_loss: tensor(0.0279)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4730 train_loss: 0.04040937945246696\n",
      "test_loss: tensor(0.0282)\n",
      "epoch: 4740 train_loss: 0.040391347277909516\n",
      "test_loss: tensor(0.0282)\n",
      "epoch: 4750 train_loss: 0.040411506127566096\n",
      "test_loss: tensor(0.0281)\n",
      "epoch: 4760 train_loss: 0.040400182269513606\n",
      "test_loss: tensor(0.0279)\n",
      "epoch: 4770 train_loss: 0.040404736343771216\n",
      "test_loss: tensor(0.0282)\n",
      "epoch: 4780 train_loss: 0.04041217658668757\n",
      "test_loss: tensor(0.0283)\n",
      "epoch: 4790 train_loss: 0.040405870601534846\n",
      "test_loss: tensor(0.0282)\n",
      "epoch: 4800 train_loss: 0.04039819771423936\n",
      "test_loss: tensor(0.0281)\n",
      "epoch: 4810 train_loss: 0.04038372738286853\n",
      "test_loss: tensor(0.0279)\n",
      "epoch: 4820 train_loss: 0.04038691986352205\n",
      "test_loss: tensor(0.0283)\n",
      "epoch: 4830 train_loss: 0.04036543676629663\n",
      "test_loss: tensor(0.0281)\n",
      "epoch: 4840 train_loss: 0.040365563612431286\n",
      "test_loss: tensor(0.0281)\n",
      "epoch: 4850 train_loss: 0.040371925383806226\n",
      "test_loss: tensor(0.0282)\n",
      "epoch: 4860 train_loss: 0.04037431087344885\n",
      "test_loss: tensor(0.0281)\n",
      "epoch: 4870 train_loss: 0.040363422222435476\n",
      "test_loss: tensor(0.0282)\n",
      "epoch: 4880 train_loss: 0.040387319214642045\n",
      "test_loss: tensor(0.0282)\n",
      "epoch: 4890 train_loss: 0.04035233855247498\n",
      "test_loss: tensor(0.0279)\n",
      "epoch: 4900 train_loss: 0.040386168472468856\n",
      "test_loss: tensor(0.0283)\n",
      "epoch: 4910 train_loss: 0.04034630851820111\n",
      "test_loss: tensor(0.0280)\n",
      "epoch: 4920 train_loss: 0.04036445086821914\n",
      "test_loss: tensor(0.0280)\n",
      "epoch: 4930 train_loss: 0.04036254705861211\n",
      "test_loss: tensor(0.0283)\n",
      "epoch: 4940 train_loss: 0.040328392013907435\n",
      "test_loss: tensor(0.0279)\n",
      "epoch: 4950 train_loss: 0.04032776588574052\n",
      "test_loss: tensor(0.0279)\n",
      "epoch: 4960 train_loss: 0.040345939435064794\n",
      "test_loss: tensor(0.0279)\n",
      "epoch: 4970 train_loss: 0.04034607987850904\n",
      "test_loss: tensor(0.0282)\n",
      "epoch: 4980 train_loss: 0.040339548606425524\n",
      "test_loss: tensor(0.0281)\n",
      "epoch: 4990 train_loss: 0.04033665172755718\n",
      "test_loss: tensor(0.0280)\n",
      "epoch: 5000 train_loss: 0.04036162327975035\n",
      "test_loss: tensor(0.0284)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    for epoch in range(5000):\n",
    "        train(epoch)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            model.eval()\n",
    "            test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "52419a1a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[197. , 190. ],\n",
       "       [ 70.2,  60. ],\n",
       "       [170.2,  90. ],\n",
       "       [170.3, 200. ],\n",
       "       [ 90.5, 130. ],\n",
       "       [179. ,  30. ],\n",
       "       [100.4, 180. ],\n",
       "       [150.1, 120. ],\n",
       "       [ 20.1, 100. ],\n",
       "       [150.2,  50. ],\n",
       "       [ 90.4, 150. ],\n",
       "       [190.5, 130. ],\n",
       "       [100.3,  90. ],\n",
       "       [170.5,  50. ],\n",
       "       [167.2,  20. ],\n",
       "       [120.5,  80. ],\n",
       "       [189.3, 120. ],\n",
       "       [ 10. ,  60. ],\n",
       "       [ 40.2, 190. ],\n",
       "       [120.4,  40. ],\n",
       "       [ 70.3,  30. ],\n",
       "       [130.4,  30. ],\n",
       "       [191.5,  30. ],\n",
       "       [110.3, 150. ],\n",
       "       [ 10. , 180. ],\n",
       "       [ 50.3, 130. ],\n",
       "       [190.3,  70. ],\n",
       "       [110.2,  20. ],\n",
       "       [187.7,  20. ],\n",
       "       [110.6,  80. ],\n",
       "       [ 50.2,  20. ],\n",
       "       [ 10. ,  50. ],\n",
       "       [ 90.4,  60. ],\n",
       "       [140.6, 160. ],\n",
       "       [ 10. ,  70. ],\n",
       "       [ 50.2,  10. ],\n",
       "       [ 30.1, 190. ],\n",
       "       [ 60.3,  30. ],\n",
       "       [198.9, 180. ],\n",
       "       [ 70.3, 200. ],\n",
       "       [140.4,  90. ],\n",
       "       [110.5,  50. ],\n",
       "       [ 90.4, 120. ],\n",
       "       [ 40.2,  30. ],\n",
       "       [200. ,  60. ],\n",
       "       [ 50.2,  60. ],\n",
       "       [193.6, 100. ],\n",
       "       [160.1,  80. ],\n",
       "       [160.3, 150. ],\n",
       "       [140.6, 190. ],\n",
       "       [ 40.2,  60. ],\n",
       "       [120.6,  60. ],\n",
       "       [120.4, 100. ],\n",
       "       [ 10. , 190. ],\n",
       "       [150.2, 170. ],\n",
       "       [150.5,  70. ],\n",
       "       [140.6, 130. ],\n",
       "       [ 60.3, 180. ],\n",
       "       [130.3, 190. ],\n",
       "       [178.6,  10. ],\n",
       "       [ 60.3,  80. ],\n",
       "       [ 40.2,  80. ],\n",
       "       [120.5, 150. ],\n",
       "       [130.6,  70. ],\n",
       "       [175.4, 150. ],\n",
       "       [120.4,  30. ],\n",
       "       [ 60.3,  70. ],\n",
       "       [160.6, 110. ],\n",
       "       [140.6, 110. ],\n",
       "       [160.6, 130. ],\n",
       "       [110.4, 190. ],\n",
       "       [ 50.2, 160. ],\n",
       "       [180. , 110. ],\n",
       "       [200.2,  80. ],\n",
       "       [ 10. , 120. ],\n",
       "       [180. ,  80. ],\n",
       "       [ 30.1,  20. ],\n",
       "       [100.3,  10. ],\n",
       "       [ 70.2, 130. ],\n",
       "       [120.4,  50. ]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "843f3241",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([190.,  60.,  90., 200., 130.,  30., 180., 120., 100.,  50., 150.,\n",
       "       130.,  90.,  50.,  20.,  80., 120.,  60., 190.,  40.,  30.,  30.,\n",
       "        30., 150., 180., 130.,  70.,  20.,  20.,  80.,  20.,  50.,  60.,\n",
       "       160.,  70.,  10., 190.,  30., 180., 200.,  90.,  50., 120.,  30.,\n",
       "        60.,  60., 100.,  80., 150., 190.,  60.,  60., 100., 190., 170.,\n",
       "        70., 130., 180., 190.,  10.,  80.,  80., 150.,  70., 150.,  30.,\n",
       "        70., 110., 110., 130., 190., 160., 110.,  80., 120.,  80.,  20.,\n",
       "        10., 130.,  50.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest1[:, 1].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "34ce44ea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = model(Xtest1_tensor)\n",
    "y = pd.concat([pd.Series(Xtest1[:, 0].reshape(-1), name='send rates'), pd.Series(Xtest1[:, 1].reshape(-1), name='block size'), \n",
    "               pd.Series(Ytest1_tensor.numpy().reshape(-1), name='latency_true'), pd.Series(y_pred.numpy().reshape(-1), name='latency_pred')], \n",
    "              axis=1)\n",
    "y.to_csv('./latency_true_pred_related1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3d7e4365",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>send rates</th>\n",
       "      <th>block size</th>\n",
       "      <th>latency_true</th>\n",
       "      <th>latency_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>197.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1.497848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.2</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.553954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>170.2</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.793090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170.3</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.913903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.5</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.813841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   send rates  block size  latency_true  latency_pred\n",
       "0       197.0       190.0          1.65      1.497848\n",
       "1        70.2        60.0          0.56      0.553954\n",
       "2       170.2        90.0          1.21      0.793090\n",
       "3       170.3       200.0          0.92      0.913903\n",
       "4        90.5       130.0          0.90      0.813841"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute test set MAE RMSE MAPE\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./latency_true_pred_related1.csv')\n",
    "data.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "354b4d47",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.65, 0.56, 1.21, 0.92, 0.9 , 1.68, 0.76, 0.81, 1.18, 0.81, 0.83,\n",
       "       1.69, 0.6 , 1.65, 2.37, 0.57, 1.43, 1.19, 1.16, 0.39, 0.29, 0.59,\n",
       "       1.85, 0.85, 1.16, 1.23, 1.01, 0.35, 1.91, 0.58, 0.21, 1.18, 0.47,\n",
       "       0.79, 1.17, 0.09, 1.16, 0.29, 1.31, 1.02, 0.55, 0.5 , 0.95, 0.41,\n",
       "       1.11, 0.68, 1.57, 0.6 , 0.96, 0.8 , 0.81, 0.44, 0.79, 1.13, 0.9 ,\n",
       "       0.43, 0.75, 1.19, 0.83, 1.64, 0.79, 1.08, 0.82, 0.44, 1.49, 0.29,\n",
       "       0.67, 0.76, 0.72, 1.2 , 0.85, 1.19, 1.01, 1.48, 1.18, 0.87, 0.31,\n",
       "       0.11, 1.08, 0.44])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['latency_true'].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8eb18263",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.4978478 , 0.55395377, 0.7930897 , 0.9139033 , 0.81384116,\n",
       "       1.3864472 , 0.75785774, 0.7757339 , 1.1435018 , 0.6058958 ,\n",
       "       0.82730526, 1.4952234 , 0.66688854, 1.3293817 , 1.5366441 ,\n",
       "       0.52950794, 1.4209621 , 1.3794163 , 1.1534368 , 0.67124176,\n",
       "       0.30876976, 0.32951614, 1.557362  , 0.7915691 , 1.1337626 ,\n",
       "       1.1521361 , 0.80856436, 0.45578927, 1.815589  , 0.540561  ,\n",
       "       0.23321153, 1.4051139 , 0.48424473, 0.82691765, 1.3100386 ,\n",
       "       0.09630895, 1.1488233 , 0.31633332, 1.565887  , 1.0352813 ,\n",
       "       0.599356  , 0.4260105 , 0.8152727 , 0.4051596 , 1.1907303 ,\n",
       "       0.6916644 , 1.3075556 , 0.52727026, 0.9106764 , 0.7943826 ,\n",
       "       0.81004256, 0.43839845, 0.72446626, 1.1396426 , 0.84982854,\n",
       "       0.42835286, 0.91967607, 1.1101464 , 0.7870315 , 1.8667512 ,\n",
       "       0.72078514, 0.9684507 , 0.81682146, 0.45555633, 1.2282456 ,\n",
       "       0.30846006, 0.68124825, 0.8505971 , 0.7438759 , 0.95582306,\n",
       "       0.7785057 , 1.155096  , 1.2005758 , 1.0324607 , 1.1430919 ,\n",
       "       0.804782  , 0.36546168, 0.09312202, 1.0488808 , 0.42218485])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = data['latency_pred'].values\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a18748f3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "818e234b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.104048277425\n",
      "RMSE:  0.1684201009354377\n",
      "MAPE:  0.10662073111580077\n"
     ]
    }
   ],
   "source": [
    "MAE = metrics.mean_absolute_error(y, y_hat)\n",
    "RMSE = metrics.mean_squared_error(y, y_hat) ** 0.5\n",
    "MAPE = metrics.mean_absolute_percentage_error(y, y_hat)\n",
    "print('MAE: ', MAE)\n",
    "print('RMSE: ', RMSE)\n",
    "print('MAPE: ', MAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c0cfe2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# MLP2(send rates, block size) = throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "157b7764",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Split training set and test set\n",
    "Xtrain2, Xtest2, Ytrain2, Ytest2 = train_test_split(X, Y2, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "de8a9bf9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[197. , 190. ],\n",
       "       [ 70.2,  60. ],\n",
       "       [170.2,  90. ],\n",
       "       [170.3, 200. ],\n",
       "       [ 90.5, 130. ],\n",
       "       [179. ,  30. ],\n",
       "       [100.4, 180. ],\n",
       "       [150.1, 120. ],\n",
       "       [ 20.1, 100. ],\n",
       "       [150.2,  50. ],\n",
       "       [ 90.4, 150. ],\n",
       "       [190.5, 130. ],\n",
       "       [100.3,  90. ],\n",
       "       [170.5,  50. ],\n",
       "       [167.2,  20. ],\n",
       "       [120.5,  80. ],\n",
       "       [189.3, 120. ],\n",
       "       [ 10. ,  60. ],\n",
       "       [ 40.2, 190. ],\n",
       "       [120.4,  40. ],\n",
       "       [ 70.3,  30. ],\n",
       "       [130.4,  30. ],\n",
       "       [191.5,  30. ],\n",
       "       [110.3, 150. ],\n",
       "       [ 10. , 180. ],\n",
       "       [ 50.3, 130. ],\n",
       "       [190.3,  70. ],\n",
       "       [110.2,  20. ],\n",
       "       [187.7,  20. ],\n",
       "       [110.6,  80. ],\n",
       "       [ 50.2,  20. ],\n",
       "       [ 10. ,  50. ],\n",
       "       [ 90.4,  60. ],\n",
       "       [140.6, 160. ],\n",
       "       [ 10. ,  70. ],\n",
       "       [ 50.2,  10. ],\n",
       "       [ 30.1, 190. ],\n",
       "       [ 60.3,  30. ],\n",
       "       [198.9, 180. ],\n",
       "       [ 70.3, 200. ],\n",
       "       [140.4,  90. ],\n",
       "       [110.5,  50. ],\n",
       "       [ 90.4, 120. ],\n",
       "       [ 40.2,  30. ],\n",
       "       [200. ,  60. ],\n",
       "       [ 50.2,  60. ],\n",
       "       [193.6, 100. ],\n",
       "       [160.1,  80. ],\n",
       "       [160.3, 150. ],\n",
       "       [140.6, 190. ],\n",
       "       [ 40.2,  60. ],\n",
       "       [120.6,  60. ],\n",
       "       [120.4, 100. ],\n",
       "       [ 10. , 190. ],\n",
       "       [150.2, 170. ],\n",
       "       [150.5,  70. ],\n",
       "       [140.6, 130. ],\n",
       "       [ 60.3, 180. ],\n",
       "       [130.3, 190. ],\n",
       "       [178.6,  10. ],\n",
       "       [ 60.3,  80. ],\n",
       "       [ 40.2,  80. ],\n",
       "       [120.5, 150. ],\n",
       "       [130.6,  70. ],\n",
       "       [175.4, 150. ],\n",
       "       [120.4,  30. ],\n",
       "       [ 60.3,  70. ],\n",
       "       [160.6, 110. ],\n",
       "       [140.6, 110. ],\n",
       "       [160.6, 130. ],\n",
       "       [110.4, 190. ],\n",
       "       [ 50.2, 160. ],\n",
       "       [180. , 110. ],\n",
       "       [200.2,  80. ],\n",
       "       [ 10. , 120. ],\n",
       "       [180. ,  80. ],\n",
       "       [ 30.1,  20. ],\n",
       "       [100.3,  10. ],\n",
       "       [ 70.2, 130. ],\n",
       "       [120.4,  50. ]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f14b9110",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[163. ],\n",
       "       [ 63.2],\n",
       "       [128.5],\n",
       "       [159.6],\n",
       "       [ 80.6],\n",
       "       [129.1],\n",
       "       [ 98.6],\n",
       "       [117.4],\n",
       "       [ 19.9],\n",
       "       [118. ],\n",
       "       [ 81.3],\n",
       "       [159.4],\n",
       "       [ 83.3],\n",
       "       [125.4],\n",
       "       [122.6],\n",
       "       [ 99.1],\n",
       "       [134.4],\n",
       "       [ 10. ],\n",
       "       [ 37.7],\n",
       "       [119.3],\n",
       "       [ 61.7],\n",
       "       [103.5],\n",
       "       [134.1],\n",
       "       [ 96.7],\n",
       "       [ 10. ],\n",
       "       [ 47.8],\n",
       "       [134.9],\n",
       "       [ 90.9],\n",
       "       [133.5],\n",
       "       [ 92.3],\n",
       "       [ 50.1],\n",
       "       [ 10. ],\n",
       "       [ 78.3],\n",
       "       [121.5],\n",
       "       [  9.9],\n",
       "       [ 50.1],\n",
       "       [ 28.4],\n",
       "       [ 53.9],\n",
       "       [163.5],\n",
       "       [ 69.8],\n",
       "       [109.1],\n",
       "       [ 92.7],\n",
       "       [ 78.4],\n",
       "       [ 37.3],\n",
       "       [139.4],\n",
       "       [ 46.9],\n",
       "       [138.7],\n",
       "       [123.1],\n",
       "       [121.6],\n",
       "       [121.4],\n",
       "       [ 38.3],\n",
       "       [ 98.9],\n",
       "       [103.3],\n",
       "       [ 10. ],\n",
       "       [120.7],\n",
       "       [116. ],\n",
       "       [121.4],\n",
       "       [ 59.5],\n",
       "       [121.9],\n",
       "       [126.8],\n",
       "       [ 55.2],\n",
       "       [ 38.3],\n",
       "       [ 97.2],\n",
       "       [103.9],\n",
       "       [157.9],\n",
       "       [ 96.5],\n",
       "       [ 54.3],\n",
       "       [120.9],\n",
       "       [109.4],\n",
       "       [121.8],\n",
       "       [ 96.2],\n",
       "       [ 48.2],\n",
       "       [130. ],\n",
       "       [138.2],\n",
       "       [ 10. ],\n",
       "       [132.7],\n",
       "       [ 30.1],\n",
       "       [ 83.7],\n",
       "       [ 61.6],\n",
       "       [ 99.2]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytest2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6cd3ae3d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# property scaling\n",
    "min_max_scaler2 = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "05f08d18",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.10802307e-01, 6.84210526e-01],\n",
       "       [5.29627687e-02, 1.57894737e-01],\n",
       "       [7.35186156e-01, 1.00000000e+00],\n",
       "       [0.00000000e+00, 6.84210526e-01],\n",
       "       [2.10802307e-01, 5.26315789e-01],\n",
       "       [1.58363922e-01, 5.26315789e-02],\n",
       "       [9.17671736e-01, 5.26315789e-02],\n",
       "       [5.25957001e-01, 6.84210526e-01],\n",
       "       [9.83744101e-01, 5.78947368e-01],\n",
       "       [3.16727845e-01, 3.68421053e-01],\n",
       "       [3.68641846e-01, 1.00000000e+00],\n",
       "       [8.96696382e-01, 7.89473684e-01],\n",
       "       [7.28893550e-01, 1.57894737e-01],\n",
       "       [8.40587310e-01, 9.47368421e-01],\n",
       "       [4.21604615e-01, 5.26315789e-02],\n",
       "       [7.89722077e-01, 0.00000000e+00],\n",
       "       [6.84320923e-01, 8.94736842e-01],\n",
       "       [7.36234924e-01, 4.73684211e-01],\n",
       "       [6.84845307e-01, 0.00000000e+00],\n",
       "       [4.21080231e-01, 6.84210526e-01],\n",
       "       [2.10802307e-01, 1.05263158e-01],\n",
       "       [9.46512847e-01, 3.68421053e-01],\n",
       "       [4.21080231e-01, 1.00000000e+00],\n",
       "       [5.29627687e-02, 3.68421053e-01],\n",
       "       [2.10802307e-01, 4.73684211e-01],\n",
       "       [7.89197693e-01, 5.78947368e-01],\n",
       "       [1.58363922e-01, 6.84210526e-01],\n",
       "       [5.79968537e-01, 6.84210526e-01],\n",
       "       [7.37808076e-01, 9.47368421e-01],\n",
       "       [6.31882538e-01, 5.26315789e-01],\n",
       "       [2.63765076e-01, 1.00000000e+00],\n",
       "       [9.45988464e-01, 8.94736842e-01],\n",
       "       [2.10802307e-01, 9.47368421e-01],\n",
       "       [6.30833770e-01, 2.10526316e-01],\n",
       "       [3.68641846e-01, 3.15789474e-01],\n",
       "       [2.10802307e-01, 5.78947368e-01],\n",
       "       [8.42160461e-01, 1.05263158e-01],\n",
       "       [6.30833770e-01, 4.21052632e-01],\n",
       "       [4.73518616e-01, 3.15789474e-01],\n",
       "       [9.98951232e-01, 7.89473684e-01],\n",
       "       [5.29627687e-02, 1.00000000e+00],\n",
       "       [4.21604615e-01, 3.68421053e-01],\n",
       "       [8.65233351e-01, 1.57894737e-01],\n",
       "       [5.79444153e-01, 5.26315789e-02],\n",
       "       [8.93025695e-01, 5.78947368e-01],\n",
       "       [1.05401154e-01, 1.00000000e+00],\n",
       "       [3.16203461e-01, 0.00000000e+00],\n",
       "       [0.00000000e+00, 6.31578947e-01],\n",
       "       [7.87624541e-01, 4.73684211e-01],\n",
       "       [9.87414788e-01, 1.00000000e+00],\n",
       "       [8.41111694e-01, 6.84210526e-01],\n",
       "       [7.37808076e-01, 6.84210526e-01],\n",
       "       [9.42842160e-01, 5.26315789e-01],\n",
       "       [7.36234924e-01, 3.68421053e-01],\n",
       "       [8.93025695e-01, 9.47368421e-01],\n",
       "       [7.37808076e-01, 7.89473684e-01],\n",
       "       [2.10802307e-01, 4.21052632e-01],\n",
       "       [3.16203461e-01, 5.78947368e-01],\n",
       "       [3.16203461e-01, 2.10526316e-01],\n",
       "       [9.43366544e-01, 8.42105263e-01],\n",
       "       [0.00000000e+00, 7.36842105e-01],\n",
       "       [4.21604615e-01, 1.05263158e-01],\n",
       "       [3.15679077e-01, 1.57894737e-01],\n",
       "       [3.16203461e-01, 9.47368421e-01],\n",
       "       [2.63765076e-01, 5.78947368e-01],\n",
       "       [1.05401154e-01, 5.78947368e-01],\n",
       "       [2.63765076e-01, 6.31578947e-01],\n",
       "       [5.24383849e-04, 4.73684211e-01],\n",
       "       [4.74042999e-01, 2.63157895e-01],\n",
       "       [0.00000000e+00, 8.42105263e-01],\n",
       "       [9.20293655e-01, 2.10526316e-01],\n",
       "       [0.00000000e+00, 0.00000000e+00],\n",
       "       [2.63765076e-01, 2.63157895e-01],\n",
       "       [4.74042999e-01, 4.73684211e-01],\n",
       "       [5.25957001e-01, 5.78947368e-01],\n",
       "       [6.56528579e-01, 0.00000000e+00],\n",
       "       [1.58363922e-01, 5.26315789e-01],\n",
       "       [5.29627687e-02, 9.47368421e-01],\n",
       "       [3.69166230e-01, 5.26315789e-01],\n",
       "       [5.25957001e-01, 4.21052632e-01],\n",
       "       [4.21604615e-01, 1.57894737e-01],\n",
       "       [6.31882538e-01, 3.68421053e-01],\n",
       "       [9.47037231e-01, 9.47368421e-01],\n",
       "       [3.69166230e-01, 2.63157895e-01],\n",
       "       [6.31882538e-01, 5.78947368e-01],\n",
       "       [1.05401154e-01, 1.05263158e-01],\n",
       "       [4.20555847e-01, 0.00000000e+00],\n",
       "       [5.78395385e-01, 5.26315789e-01],\n",
       "       [4.74042999e-01, 5.78947368e-01],\n",
       "       [5.78919769e-01, 9.47368421e-01],\n",
       "       [8.96171998e-01, 2.10526316e-01],\n",
       "       [9.78500262e-01, 6.31578947e-01],\n",
       "       [8.42160461e-01, 5.26315789e-01],\n",
       "       [7.34661772e-01, 2.63157895e-01],\n",
       "       [4.74042999e-01, 6.31578947e-01],\n",
       "       [3.69166230e-01, 3.68421053e-01],\n",
       "       [7.89722077e-01, 2.10526316e-01],\n",
       "       [2.63240692e-01, 0.00000000e+00],\n",
       "       [5.29627687e-02, 7.36842105e-01],\n",
       "       [2.63240692e-01, 5.26315789e-01],\n",
       "       [4.21080231e-01, 7.89473684e-01],\n",
       "       [6.32406922e-01, 2.63157895e-01],\n",
       "       [3.16203461e-01, 7.89473684e-01],\n",
       "       [7.13162035e-01, 7.36842105e-01],\n",
       "       [3.68117462e-01, 7.36842105e-01],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [3.68641846e-01, 1.05263158e-01],\n",
       "       [3.68117462e-01, 9.47368421e-01],\n",
       "       [6.83796539e-01, 6.84210526e-01],\n",
       "       [1.05401154e-01, 2.10526316e-01],\n",
       "       [6.84845307e-01, 5.78947368e-01],\n",
       "       [5.78919769e-01, 8.42105263e-01],\n",
       "       [6.32406922e-01, 4.73684211e-01],\n",
       "       [2.63765076e-01, 4.21052632e-01],\n",
       "       [8.95647614e-01, 2.63157895e-01],\n",
       "       [4.21604615e-01, 4.73684211e-01],\n",
       "       [1.58363922e-01, 1.00000000e+00],\n",
       "       [9.41793393e-01, 1.00000000e+00],\n",
       "       [2.10802307e-01, 2.10526316e-01],\n",
       "       [0.00000000e+00, 4.21052632e-01],\n",
       "       [9.47561615e-01, 2.63157895e-01],\n",
       "       [2.10802307e-01, 1.00000000e+00],\n",
       "       [8.91976927e-01, 4.21052632e-01],\n",
       "       [8.40587310e-01, 4.73684211e-01],\n",
       "       [8.00209754e-01, 0.00000000e+00],\n",
       "       [5.29627687e-02, 4.21052632e-01],\n",
       "       [5.29627687e-02, 5.78947368e-01],\n",
       "       [1.05401154e-01, 7.89473684e-01],\n",
       "       [5.77871002e-01, 4.21052632e-01],\n",
       "       [5.29627687e-02, 6.31578947e-01],\n",
       "       [6.84845307e-01, 7.36842105e-01],\n",
       "       [1.05401154e-01, 4.21052632e-01],\n",
       "       [8.42160461e-01, 5.78947368e-01],\n",
       "       [6.30309386e-01, 8.94736842e-01],\n",
       "       [8.69952805e-01, 5.26315789e-02],\n",
       "       [5.29627687e-02, 6.84210526e-01],\n",
       "       [6.84320923e-01, 3.68421053e-01],\n",
       "       [5.29627687e-02, 7.89473684e-01],\n",
       "       [7.89722077e-01, 1.57894737e-01],\n",
       "       [1.58363922e-01, 1.57894737e-01],\n",
       "       [3.69166230e-01, 8.94736842e-01],\n",
       "       [3.16203461e-01, 4.21052632e-01],\n",
       "       [1.05401154e-01, 3.15789474e-01],\n",
       "       [5.79968537e-01, 6.31578947e-01],\n",
       "       [1.58363922e-01, 3.15789474e-01],\n",
       "       [6.32406922e-01, 8.42105263e-01],\n",
       "       [8.95123230e-01, 4.73684211e-01],\n",
       "       [6.85369691e-01, 5.26315789e-02],\n",
       "       [9.11903513e-01, 0.00000000e+00],\n",
       "       [9.84792868e-01, 5.26315789e-01],\n",
       "       [8.41111694e-01, 1.57894737e-01],\n",
       "       [1.05925537e-01, 2.63157895e-01],\n",
       "       [5.25957001e-01, 3.15789474e-01],\n",
       "       [4.21080231e-01, 4.21052632e-01],\n",
       "       [8.37965391e-01, 6.31578947e-01],\n",
       "       [1.05401154e-01, 3.68421053e-01],\n",
       "       [2.63765076e-01, 6.84210526e-01],\n",
       "       [4.21604615e-01, 8.94736842e-01],\n",
       "       [5.25432617e-01, 1.00000000e+00],\n",
       "       [7.89197693e-01, 2.63157895e-01],\n",
       "       [1.05401154e-01, 0.00000000e+00],\n",
       "       [5.29627687e-02, 5.26315789e-02],\n",
       "       [2.63765076e-01, 5.26315789e-02],\n",
       "       [4.20031463e-01, 2.10526316e-01],\n",
       "       [1.58363922e-01, 4.73684211e-01],\n",
       "       [1.05401154e-01, 6.84210526e-01],\n",
       "       [4.74042999e-01, 1.00000000e+00],\n",
       "       [9.97902465e-01, 2.10526316e-01],\n",
       "       [3.15679077e-01, 8.94736842e-01],\n",
       "       [5.29627687e-02, 2.10526316e-01],\n",
       "       [8.41636078e-01, 2.63157895e-01],\n",
       "       [4.74042999e-01, 3.68421053e-01],\n",
       "       [4.74042999e-01, 2.10526316e-01],\n",
       "       [5.27005768e-01, 2.63157895e-01],\n",
       "       [3.15679077e-01, 7.36842105e-01],\n",
       "       [7.89197693e-01, 9.47368421e-01],\n",
       "       [2.63765076e-01, 8.42105263e-01],\n",
       "       [5.27005768e-01, 6.31578947e-01],\n",
       "       [8.86733089e-01, 1.05263158e-01],\n",
       "       [7.71893026e-01, 1.57894737e-01],\n",
       "       [8.41636078e-01, 8.94736842e-01],\n",
       "       [5.79444153e-01, 5.78947368e-01],\n",
       "       [5.26481384e-01, 8.94736842e-01],\n",
       "       [1.05401154e-01, 8.42105263e-01],\n",
       "       [7.85527006e-01, 7.89473684e-01],\n",
       "       [7.36759308e-01, 7.36842105e-01],\n",
       "       [7.36234924e-01, 6.31578947e-01],\n",
       "       [4.74567383e-01, 5.26315789e-02],\n",
       "       [2.10802307e-01, 8.94736842e-01],\n",
       "       [2.63240692e-01, 7.36842105e-01],\n",
       "       [2.63765076e-01, 9.47368421e-01],\n",
       "       [7.89722077e-01, 5.26315789e-02],\n",
       "       [4.21604615e-01, 5.26315789e-01],\n",
       "       [8.95123230e-01, 3.15789474e-01],\n",
       "       [1.05401154e-01, 7.36842105e-01],\n",
       "       [4.21604615e-01, 8.42105263e-01],\n",
       "       [4.74567383e-01, 7.36842105e-01],\n",
       "       [4.74567383e-01, 9.47368421e-01],\n",
       "       [4.74567383e-01, 1.05263158e-01],\n",
       "       [8.43733613e-01, 3.68421053e-01],\n",
       "       [2.63240692e-01, 1.57894737e-01],\n",
       "       [5.79968537e-01, 0.00000000e+00],\n",
       "       [3.16203461e-01, 5.26315789e-01],\n",
       "       [7.37808076e-01, 5.26315789e-01],\n",
       "       [1.58363922e-01, 0.00000000e+00],\n",
       "       [2.10802307e-01, 7.36842105e-01],\n",
       "       [4.73518616e-01, 6.84210526e-01],\n",
       "       [3.69166230e-01, 0.00000000e+00],\n",
       "       [3.68641846e-01, 4.21052632e-01],\n",
       "       [5.26481384e-01, 1.05263158e-01],\n",
       "       [3.69166230e-01, 6.31578947e-01],\n",
       "       [8.40062926e-01, 3.15789474e-01],\n",
       "       [0.00000000e+00, 5.26315789e-01],\n",
       "       [6.82747771e-01, 4.73684211e-01],\n",
       "       [2.10802307e-01, 8.42105263e-01],\n",
       "       [5.27530152e-01, 5.26315789e-01],\n",
       "       [6.31358154e-01, 0.00000000e+00],\n",
       "       [1.05401154e-01, 8.94736842e-01],\n",
       "       [7.90246460e-01, 3.15789474e-01],\n",
       "       [5.29627687e-02, 8.42105263e-01],\n",
       "       [8.91976927e-01, 1.00000000e+00],\n",
       "       [5.29627687e-02, 0.00000000e+00],\n",
       "       [8.95123230e-01, 6.84210526e-01],\n",
       "       [1.58363922e-01, 7.89473684e-01],\n",
       "       [5.27005768e-01, 0.00000000e+00],\n",
       "       [1.58363922e-01, 8.94736842e-01],\n",
       "       [6.84320923e-01, 1.57894737e-01],\n",
       "       [9.44939696e-01, 7.36842105e-01],\n",
       "       [3.68117462e-01, 4.73684211e-01],\n",
       "       [9.40220241e-01, 7.89473684e-01],\n",
       "       [0.00000000e+00, 1.05263158e-01],\n",
       "       [1.05925537e-01, 6.31578947e-01],\n",
       "       [6.84320923e-01, 1.05263158e-01],\n",
       "       [6.32406922e-01, 6.84210526e-01],\n",
       "       [6.31882538e-01, 1.00000000e+00],\n",
       "       [4.71945464e-01, 1.57894737e-01],\n",
       "       [3.68641846e-01, 5.78947368e-01],\n",
       "       [9.17671736e-01, 1.57894737e-01],\n",
       "       [7.89722077e-01, 1.05263158e-01],\n",
       "       [4.74042999e-01, 5.26315789e-01],\n",
       "       [1.58363922e-01, 7.36842105e-01],\n",
       "       [6.33455690e-01, 1.57894737e-01],\n",
       "       [1.00000000e+00, 3.15789474e-01],\n",
       "       [2.10802307e-01, 3.68421053e-01],\n",
       "       [5.77871002e-01, 1.00000000e+00],\n",
       "       [3.69166230e-01, 1.57894737e-01],\n",
       "       [8.41111694e-01, 7.36842105e-01],\n",
       "       [6.84320923e-01, 3.15789474e-01],\n",
       "       [7.37283692e-01, 4.21052632e-01],\n",
       "       [3.16203461e-01, 8.42105263e-01],\n",
       "       [4.21080231e-01, 3.15789474e-01],\n",
       "       [2.10802307e-01, 1.57894737e-01],\n",
       "       [8.92501311e-01, 8.42105263e-01],\n",
       "       [3.68117462e-01, 7.89473684e-01],\n",
       "       [6.84845307e-01, 1.00000000e+00],\n",
       "       [3.16727845e-01, 3.15789474e-01],\n",
       "       [4.74567383e-01, 7.89473684e-01],\n",
       "       [6.84320923e-01, 2.63157895e-01],\n",
       "       [9.29732564e-01, 4.73684211e-01],\n",
       "       [2.63765076e-01, 2.10526316e-01],\n",
       "       [3.68641846e-01, 6.84210526e-01],\n",
       "       [7.28369166e-01, 1.05263158e-01],\n",
       "       [5.79444153e-01, 3.15789474e-01],\n",
       "       [5.29627687e-02, 2.63157895e-01],\n",
       "       [4.73518616e-01, 8.42105263e-01],\n",
       "       [1.58363922e-01, 2.10526316e-01],\n",
       "       [0.00000000e+00, 7.89473684e-01],\n",
       "       [7.37283692e-01, 8.94736842e-01],\n",
       "       [2.63765076e-01, 4.73684211e-01],\n",
       "       [8.42160461e-01, 8.42105263e-01],\n",
       "       [7.90770844e-01, 4.21052632e-01],\n",
       "       [5.29627687e-02, 3.15789474e-01],\n",
       "       [1.58363922e-01, 8.42105263e-01],\n",
       "       [1.05925537e-01, 1.57894737e-01],\n",
       "       [7.36234924e-01, 0.00000000e+00],\n",
       "       [0.00000000e+00, 1.57894737e-01],\n",
       "       [9.37598322e-01, 4.21052632e-01],\n",
       "       [1.05401154e-01, 4.73684211e-01],\n",
       "       [9.83219717e-01, 4.21052632e-01],\n",
       "       [5.29627687e-02, 5.26315789e-01],\n",
       "       [3.16203461e-01, 5.26315789e-02],\n",
       "       [2.63765076e-01, 7.89473684e-01],\n",
       "       [8.36916623e-01, 6.84210526e-01],\n",
       "       [5.26481384e-01, 8.42105263e-01],\n",
       "       [6.83796539e-01, 2.10526316e-01],\n",
       "       [5.26481384e-01, 4.73684211e-01],\n",
       "       [7.89197693e-01, 8.42105263e-01],\n",
       "       [0.00000000e+00, 5.26315789e-02],\n",
       "       [7.87100157e-01, 6.84210526e-01],\n",
       "       [5.29627687e-02, 1.05263158e-01],\n",
       "       [7.89722077e-01, 8.94736842e-01],\n",
       "       [7.89722077e-01, 1.00000000e+00],\n",
       "       [0.00000000e+00, 3.68421053e-01],\n",
       "       [3.69690614e-01, 5.26315789e-02],\n",
       "       [2.10802307e-01, 3.15789474e-01],\n",
       "       [8.91976927e-01, 6.31578947e-01],\n",
       "       [6.29785003e-01, 5.26315789e-02],\n",
       "       [5.27530152e-01, 7.89473684e-01],\n",
       "       [1.58363922e-01, 4.21052632e-01],\n",
       "       [1.05925537e-01, 5.26315789e-01],\n",
       "       [3.68641846e-01, 8.42105263e-01],\n",
       "       [6.31358154e-01, 6.31578947e-01],\n",
       "       [8.96696382e-01, 8.94736842e-01],\n",
       "       [6.30309386e-01, 7.36842105e-01],\n",
       "       [6.84845307e-01, 8.42105263e-01],\n",
       "       [4.21080231e-01, 9.47368421e-01],\n",
       "       [7.37808076e-01, 5.26315789e-02],\n",
       "       [5.79444153e-01, 8.94736842e-01],\n",
       "       [1.58363922e-01, 5.78947368e-01],\n",
       "       [3.16203461e-01, 4.73684211e-01],\n",
       "       [3.69166230e-01, 2.10526316e-01],\n",
       "       [8.43209229e-01, 7.89473684e-01],\n",
       "       [3.16203461e-01, 6.84210526e-01],\n",
       "       [5.27530152e-01, 1.57894737e-01],\n",
       "       [9.96329313e-01, 6.84210526e-01],\n",
       "       [6.31882538e-01, 7.89473684e-01],\n",
       "       [1.58363922e-01, 6.31578947e-01],\n",
       "       [9.30781332e-01, 8.42105263e-01],\n",
       "       [5.78919769e-01, 7.89473684e-01],\n",
       "       [5.29627687e-02, 8.94736842e-01]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling training set data\n",
    "Xtrain2_minmax = min_max_scaler2.fit_transform(Xtrain2)\n",
    "Xtrain2_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "461721dd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9805978 , 0.94736842],\n",
       "       [0.31567908, 0.26315789],\n",
       "       [0.84006293, 0.42105263],\n",
       "       [0.84058731, 1.        ],\n",
       "       [0.422129  , 0.63157895],\n",
       "       [0.8862087 , 0.10526316],\n",
       "       [0.474043  , 0.89473684],\n",
       "       [0.73466177, 0.57894737],\n",
       "       [0.05296277, 0.47368421],\n",
       "       [0.73518616, 0.21052632],\n",
       "       [0.42160461, 0.73684211],\n",
       "       [0.94651285, 0.63157895],\n",
       "       [0.47351862, 0.42105263],\n",
       "       [0.84163608, 0.21052632],\n",
       "       [0.82433141, 0.05263158],\n",
       "       [0.57944415, 0.36842105],\n",
       "       [0.94022024, 0.57894737],\n",
       "       [0.        , 0.26315789],\n",
       "       [0.15836392, 0.94736842],\n",
       "       [0.57891977, 0.15789474],\n",
       "       [0.31620346, 0.10526316],\n",
       "       [0.63135815, 0.10526316],\n",
       "       [0.95175669, 0.10526316],\n",
       "       [0.525957  , 0.73684211],\n",
       "       [0.        , 0.89473684],\n",
       "       [0.21132669, 0.63157895],\n",
       "       [0.94546408, 0.31578947],\n",
       "       [0.52543262, 0.05263158],\n",
       "       [0.9318301 , 0.05263158],\n",
       "       [0.52753015, 0.36842105],\n",
       "       [0.21080231, 0.05263158],\n",
       "       [0.        , 0.21052632],\n",
       "       [0.42160461, 0.26315789],\n",
       "       [0.68484531, 0.78947368],\n",
       "       [0.        , 0.31578947],\n",
       "       [0.21080231, 0.        ],\n",
       "       [0.10540115, 0.94736842],\n",
       "       [0.26376508, 0.10526316],\n",
       "       [0.99056109, 0.89473684],\n",
       "       [0.31620346, 1.        ],\n",
       "       [0.68379654, 0.42105263],\n",
       "       [0.52700577, 0.21052632],\n",
       "       [0.42160461, 0.57894737],\n",
       "       [0.15836392, 0.10526316],\n",
       "       [0.99632931, 0.26315789],\n",
       "       [0.21080231, 0.26315789],\n",
       "       [0.96276875, 0.47368421],\n",
       "       [0.78710016, 0.36842105],\n",
       "       [0.78814893, 0.73684211],\n",
       "       [0.68484531, 0.94736842],\n",
       "       [0.15836392, 0.26315789],\n",
       "       [0.57996854, 0.26315789],\n",
       "       [0.57891977, 0.47368421],\n",
       "       [0.        , 0.94736842],\n",
       "       [0.73518616, 0.84210526],\n",
       "       [0.73675931, 0.31578947],\n",
       "       [0.68484531, 0.63157895],\n",
       "       [0.26376508, 0.89473684],\n",
       "       [0.63083377, 0.94736842],\n",
       "       [0.88411117, 0.        ],\n",
       "       [0.26376508, 0.36842105],\n",
       "       [0.15836392, 0.36842105],\n",
       "       [0.57944415, 0.73684211],\n",
       "       [0.63240692, 0.31578947],\n",
       "       [0.86733089, 0.73684211],\n",
       "       [0.57891977, 0.10526316],\n",
       "       [0.26376508, 0.31578947],\n",
       "       [0.78972208, 0.52631579],\n",
       "       [0.68484531, 0.52631579],\n",
       "       [0.78972208, 0.63157895],\n",
       "       [0.52648138, 0.94736842],\n",
       "       [0.21080231, 0.78947368],\n",
       "       [0.89145254, 0.52631579],\n",
       "       [0.99737808, 0.36842105],\n",
       "       [0.        , 0.57894737],\n",
       "       [0.89145254, 0.36842105],\n",
       "       [0.10540115, 0.05263158],\n",
       "       [0.47351862, 0.        ],\n",
       "       [0.31567908, 0.63157895],\n",
       "       [0.57891977, 0.21052632]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the same scaling to the test set data\n",
    "Xtest2_minmax = min_max_scaler2.transform(Xtest2)\n",
    "Xtest2_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f07479a2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Xtest2_tensor = torch.from_numpy(Xtest2_minmax).type(torch.float32)\n",
    "Ytest2_tensor = torch.from_numpy(Ytest2).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "badda5a4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = BlockChainDataset(Xtrain2_minmax, Ytrain2)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e3238dff",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# design model using class\n",
    "class Thr(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Thr, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 64)\n",
    "        self.fc2 = nn.Linear(64, 8)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(8, 1)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "model1 = Thr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cab7f50f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# construct loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model1.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68714a7d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# traning cycle forward, backward, update\n",
    "def train1(epoch):\n",
    "    train_loss = 0.0\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader, 0):\n",
    "        y_pred = model1(inputs)\n",
    "        loss = criterion(y_pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * labels.shape[0]\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print('epoch:', epoch + 1, 'train_loss:', train_loss / len(Xtrain2))\n",
    "        \n",
    "\n",
    "def test1():\n",
    "    with torch.no_grad():\n",
    "        y_pred = model1(Xtest2_tensor)\n",
    "        loss = criterion(y_pred, Ytest2_tensor)\n",
    "        print('test_loss:', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "380e16d2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 train_loss: 40.42617921829223\n",
      "test_loss: tensor(35.9523)\n",
      "epoch: 20 train_loss: 40.424303722381595\n",
      "test_loss: tensor(35.9711)\n",
      "epoch: 30 train_loss: 40.42428321838379\n",
      "test_loss: tensor(35.9714)\n",
      "epoch: 40 train_loss: 40.42399415969849\n",
      "test_loss: tensor(35.9743)\n",
      "epoch: 50 train_loss: 40.424316787719725\n",
      "test_loss: tensor(35.9721)\n",
      "epoch: 60 train_loss: 40.42429962158203\n",
      "test_loss: tensor(35.9750)\n",
      "epoch: 70 train_loss: 40.424763679504395\n",
      "test_loss: tensor(35.9729)\n",
      "epoch: 80 train_loss: 40.42577991485596\n",
      "test_loss: tensor(35.9808)\n",
      "epoch: 90 train_loss: 40.42421588897705\n",
      "test_loss: tensor(35.9773)\n",
      "epoch: 100 train_loss: 40.42426528930664\n",
      "test_loss: tensor(35.9746)\n",
      "epoch: 110 train_loss: 40.42396202087402\n",
      "test_loss: tensor(35.9761)\n",
      "epoch: 120 train_loss: 40.42429389953613\n",
      "test_loss: tensor(35.9733)\n",
      "epoch: 130 train_loss: 40.42428035736084\n",
      "test_loss: tensor(35.9759)\n",
      "epoch: 140 train_loss: 40.42439336776734\n",
      "test_loss: tensor(35.9761)\n",
      "epoch: 150 train_loss: 40.42055187225342\n",
      "test_loss: tensor(35.9914)\n",
      "epoch: 160 train_loss: 40.42420635223389\n",
      "test_loss: tensor(35.9772)\n",
      "epoch: 170 train_loss: 40.424736213684085\n",
      "test_loss: tensor(35.9745)\n",
      "epoch: 180 train_loss: 40.42574043273926\n",
      "test_loss: tensor(35.9819)\n",
      "epoch: 190 train_loss: 40.42419700622558\n",
      "test_loss: tensor(35.9781)\n",
      "epoch: 200 train_loss: 40.42432498931885\n",
      "test_loss: tensor(35.9750)\n",
      "epoch: 210 train_loss: 40.42573280334473\n",
      "test_loss: tensor(35.9751)\n",
      "epoch: 220 train_loss: 40.42418775558472\n",
      "test_loss: tensor(35.9790)\n",
      "epoch: 230 train_loss: 40.42423229217529\n",
      "test_loss: tensor(35.9758)\n",
      "epoch: 240 train_loss: 40.42571449279785\n",
      "test_loss: tensor(35.9759)\n",
      "epoch: 250 train_loss: 40.42416315078735\n",
      "test_loss: tensor(35.9795)\n",
      "epoch: 260 train_loss: 40.42421178817749\n",
      "test_loss: tensor(35.9761)\n",
      "epoch: 270 train_loss: 40.4239182472229\n",
      "test_loss: tensor(35.9772)\n",
      "epoch: 280 train_loss: 40.42422189712524\n",
      "test_loss: tensor(35.9687)\n",
      "epoch: 290 train_loss: 40.424304485321045\n",
      "test_loss: tensor(35.9763)\n",
      "epoch: 300 train_loss: 40.423915767669676\n",
      "test_loss: tensor(35.9777)\n",
      "epoch: 310 train_loss: 40.424249267578126\n",
      "test_loss: tensor(35.9689)\n",
      "epoch: 320 train_loss: 40.42428760528564\n",
      "test_loss: tensor(35.9765)\n",
      "epoch: 330 train_loss: 40.42390308380127\n",
      "test_loss: tensor(35.9778)\n",
      "epoch: 340 train_loss: 40.42425584793091\n",
      "test_loss: tensor(35.9690)\n",
      "epoch: 350 train_loss: 40.424284076690675\n",
      "test_loss: tensor(35.9765)\n",
      "epoch: 360 train_loss: 40.42389335632324\n",
      "test_loss: tensor(35.9778)\n",
      "epoch: 370 train_loss: 40.424236106872556\n",
      "test_loss: tensor(35.9690)\n",
      "epoch: 380 train_loss: 40.42428102493286\n",
      "test_loss: tensor(35.9765)\n",
      "epoch: 390 train_loss: 40.42389049530029\n",
      "test_loss: tensor(35.9778)\n",
      "epoch: 400 train_loss: 40.42422580718994\n",
      "test_loss: tensor(35.9689)\n",
      "epoch: 410 train_loss: 40.42428913116455\n",
      "test_loss: tensor(35.9764)\n",
      "epoch: 420 train_loss: 40.4238956451416\n",
      "test_loss: tensor(35.9777)\n",
      "epoch: 430 train_loss: 40.424203395843506\n",
      "test_loss: tensor(35.9689)\n",
      "epoch: 440 train_loss: 40.424292755126956\n",
      "test_loss: tensor(35.9764)\n",
      "epoch: 450 train_loss: 40.423888969421384\n",
      "test_loss: tensor(35.9777)\n",
      "epoch: 460 train_loss: 40.42419443130493\n",
      "test_loss: tensor(35.9688)\n",
      "epoch: 470 train_loss: 40.42427682876587\n",
      "test_loss: tensor(35.9763)\n",
      "epoch: 480 train_loss: 40.42388782501221\n",
      "test_loss: tensor(35.9776)\n",
      "epoch: 490 train_loss: 40.424181175231936\n",
      "test_loss: tensor(35.9688)\n",
      "epoch: 500 train_loss: 40.42427558898926\n",
      "test_loss: tensor(35.9763)\n",
      "epoch: 510 train_loss: 40.42388381958008\n",
      "test_loss: tensor(35.9776)\n",
      "epoch: 520 train_loss: 40.42416343688965\n",
      "test_loss: tensor(35.9687)\n",
      "epoch: 530 train_loss: 40.42428073883057\n",
      "test_loss: tensor(35.9762)\n",
      "epoch: 540 train_loss: 40.42387580871582\n",
      "test_loss: tensor(35.9776)\n",
      "epoch: 550 train_loss: 40.424151706695554\n",
      "test_loss: tensor(35.9687)\n",
      "epoch: 560 train_loss: 40.424270439147946\n",
      "test_loss: tensor(35.9762)\n",
      "epoch: 570 train_loss: 40.42388229370117\n",
      "test_loss: tensor(35.9775)\n",
      "epoch: 580 train_loss: 40.42414436340332\n",
      "test_loss: tensor(35.9686)\n",
      "epoch: 590 train_loss: 40.424249458312985\n",
      "test_loss: tensor(35.9761)\n",
      "epoch: 600 train_loss: 40.42386703491211\n",
      "test_loss: tensor(35.9774)\n",
      "epoch: 610 train_loss: 40.42412328720093\n",
      "test_loss: tensor(35.9686)\n",
      "epoch: 620 train_loss: 40.424261283874515\n",
      "test_loss: tensor(35.9761)\n",
      "epoch: 630 train_loss: 40.42386636734009\n",
      "test_loss: tensor(35.9774)\n",
      "epoch: 640 train_loss: 40.424124813079835\n",
      "test_loss: tensor(35.9685)\n",
      "epoch: 650 train_loss: 40.42425203323364\n",
      "test_loss: tensor(35.9760)\n",
      "epoch: 660 train_loss: 40.423866271972656\n",
      "test_loss: tensor(35.9773)\n",
      "epoch: 670 train_loss: 40.424112510681155\n",
      "test_loss: tensor(35.9685)\n",
      "epoch: 680 train_loss: 40.42425880432129\n",
      "test_loss: tensor(35.9760)\n",
      "epoch: 690 train_loss: 40.4238621711731\n",
      "test_loss: tensor(35.9773)\n",
      "epoch: 700 train_loss: 40.42411470413208\n",
      "test_loss: tensor(35.9684)\n",
      "epoch: 710 train_loss: 40.4242506980896\n",
      "test_loss: tensor(35.9759)\n",
      "epoch: 720 train_loss: 40.42386589050293\n",
      "test_loss: tensor(35.9772)\n",
      "epoch: 730 train_loss: 40.42408924102783\n",
      "test_loss: tensor(35.9683)\n",
      "epoch: 740 train_loss: 40.424247360229494\n",
      "test_loss: tensor(35.9758)\n",
      "epoch: 750 train_loss: 40.4238561630249\n",
      "test_loss: tensor(35.9772)\n",
      "epoch: 760 train_loss: 40.42408170700073\n",
      "test_loss: tensor(35.9683)\n",
      "epoch: 770 train_loss: 40.424231719970706\n",
      "test_loss: tensor(35.9758)\n",
      "epoch: 780 train_loss: 40.423859691619874\n",
      "test_loss: tensor(35.9771)\n",
      "epoch: 790 train_loss: 40.42406816482544\n",
      "test_loss: tensor(35.9682)\n",
      "epoch: 800 train_loss: 40.42423496246338\n",
      "test_loss: tensor(35.9758)\n",
      "epoch: 810 train_loss: 40.42385406494141\n",
      "test_loss: tensor(35.9771)\n",
      "epoch: 820 train_loss: 40.424068450927734\n",
      "test_loss: tensor(35.9682)\n",
      "epoch: 830 train_loss: 40.424236583709714\n",
      "test_loss: tensor(35.9757)\n",
      "epoch: 840 train_loss: 40.423849487304686\n",
      "test_loss: tensor(35.9770)\n",
      "epoch: 850 train_loss: 40.424079990386964\n",
      "test_loss: tensor(35.9795)\n",
      "epoch: 860 train_loss: 40.42413387298584\n",
      "test_loss: tensor(35.9758)\n",
      "epoch: 870 train_loss: 40.42562370300293\n",
      "test_loss: tensor(35.9755)\n",
      "epoch: 880 train_loss: 40.42409162521362\n",
      "test_loss: tensor(35.9789)\n",
      "epoch: 890 train_loss: 40.424153327941895\n",
      "test_loss: tensor(35.9753)\n",
      "epoch: 900 train_loss: 40.42563238143921\n",
      "test_loss: tensor(35.9752)\n",
      "epoch: 910 train_loss: 40.4240948677063\n",
      "test_loss: tensor(35.9786)\n",
      "epoch: 920 train_loss: 40.42414026260376\n",
      "test_loss: tensor(35.9752)\n",
      "epoch: 930 train_loss: 40.42561597824097\n",
      "test_loss: tensor(35.9826)\n",
      "epoch: 940 train_loss: 40.42409133911133\n",
      "test_loss: tensor(35.9782)\n",
      "epoch: 950 train_loss: 40.42422389984131\n",
      "test_loss: tensor(35.9746)\n",
      "epoch: 960 train_loss: 40.425612449645996\n",
      "test_loss: tensor(35.9820)\n",
      "epoch: 970 train_loss: 40.42410268783569\n",
      "test_loss: tensor(35.9778)\n",
      "epoch: 980 train_loss: 40.42423210144043\n",
      "test_loss: tensor(35.9744)\n",
      "epoch: 990 train_loss: 40.425619506835936\n",
      "test_loss: tensor(35.9819)\n",
      "epoch: 1000 train_loss: 40.42409772872925\n",
      "test_loss: tensor(35.9777)\n",
      "epoch: 1010 train_loss: 40.424607276916504\n",
      "test_loss: tensor(35.9744)\n",
      "epoch: 1020 train_loss: 40.42042903900146\n",
      "test_loss: tensor(35.9917)\n",
      "epoch: 1030 train_loss: 40.42408275604248\n",
      "test_loss: tensor(35.9771)\n",
      "epoch: 1040 train_loss: 40.424621963500975\n",
      "test_loss: tensor(35.9740)\n",
      "epoch: 1050 train_loss: 40.42043342590332\n",
      "test_loss: tensor(35.9914)\n",
      "epoch: 1060 train_loss: 40.42406883239746\n",
      "test_loss: tensor(35.9768)\n",
      "epoch: 1070 train_loss: 40.42424821853638\n",
      "test_loss: tensor(35.9763)\n",
      "epoch: 1080 train_loss: 40.42414035797119\n",
      "test_loss: tensor(35.9743)\n",
      "epoch: 1090 train_loss: 40.42413463592529\n",
      "test_loss: tensor(35.9761)\n",
      "epoch: 1100 train_loss: 40.42425003051758\n",
      "test_loss: tensor(35.9758)\n",
      "epoch: 1110 train_loss: 40.4241455078125\n",
      "test_loss: tensor(35.9739)\n",
      "epoch: 1120 train_loss: 40.42414035797119\n",
      "test_loss: tensor(35.9758)\n",
      "epoch: 1130 train_loss: 40.42379102706909\n",
      "test_loss: tensor(35.9771)\n",
      "epoch: 1140 train_loss: 40.424075508117674\n",
      "test_loss: tensor(35.9680)\n",
      "epoch: 1150 train_loss: 40.42419033050537\n",
      "test_loss: tensor(35.9753)\n",
      "epoch: 1160 train_loss: 40.42380247116089\n",
      "test_loss: tensor(35.9766)\n",
      "epoch: 1170 train_loss: 40.424030494689944\n",
      "test_loss: tensor(35.9790)\n",
      "epoch: 1180 train_loss: 40.424081039428714\n",
      "test_loss: tensor(35.9752)\n",
      "epoch: 1190 train_loss: 40.425593566894534\n",
      "test_loss: tensor(35.9749)\n",
      "epoch: 1200 train_loss: 40.42405080795288\n",
      "test_loss: tensor(35.9783)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1210 train_loss: 40.42410001754761\n",
      "test_loss: tensor(35.9748)\n",
      "epoch: 1220 train_loss: 40.42556638717652\n",
      "test_loss: tensor(35.9822)\n",
      "epoch: 1230 train_loss: 40.42404956817627\n",
      "test_loss: tensor(35.9777)\n",
      "epoch: 1240 train_loss: 40.424192905426025\n",
      "test_loss: tensor(35.9741)\n",
      "epoch: 1250 train_loss: 40.425584983825686\n",
      "test_loss: tensor(35.9816)\n",
      "epoch: 1260 train_loss: 40.42406005859375\n",
      "test_loss: tensor(35.9773)\n",
      "epoch: 1270 train_loss: 40.42456741333008\n",
      "test_loss: tensor(35.9741)\n",
      "epoch: 1280 train_loss: 40.42039709091186\n",
      "test_loss: tensor(35.9913)\n",
      "epoch: 1290 train_loss: 40.42406234741211\n",
      "test_loss: tensor(35.9766)\n",
      "epoch: 1300 train_loss: 40.42457237243652\n",
      "test_loss: tensor(35.9735)\n",
      "epoch: 1310 train_loss: 40.42410650253296\n",
      "test_loss: tensor(35.9743)\n",
      "epoch: 1320 train_loss: 40.42411241531372\n",
      "test_loss: tensor(35.9760)\n",
      "epoch: 1330 train_loss: 40.424224853515625\n",
      "test_loss: tensor(35.9756)\n",
      "epoch: 1340 train_loss: 40.42411603927612\n",
      "test_loss: tensor(35.9737)\n",
      "epoch: 1350 train_loss: 40.424112224578856\n",
      "test_loss: tensor(35.9756)\n",
      "epoch: 1360 train_loss: 40.42377233505249\n",
      "test_loss: tensor(35.9768)\n",
      "epoch: 1370 train_loss: 40.42403154373169\n",
      "test_loss: tensor(35.9677)\n",
      "epoch: 1380 train_loss: 40.42416820526123\n",
      "test_loss: tensor(35.9750)\n",
      "epoch: 1390 train_loss: 40.42377681732178\n",
      "test_loss: tensor(35.9762)\n",
      "epoch: 1400 train_loss: 40.42399940490723\n",
      "test_loss: tensor(35.9787)\n",
      "epoch: 1410 train_loss: 40.424060916900636\n",
      "test_loss: tensor(35.9749)\n",
      "epoch: 1420 train_loss: 40.425569725036624\n",
      "test_loss: tensor(35.9746)\n",
      "epoch: 1430 train_loss: 40.42402172088623\n",
      "test_loss: tensor(35.9780)\n",
      "epoch: 1440 train_loss: 40.424067211151126\n",
      "test_loss: tensor(35.9745)\n",
      "epoch: 1450 train_loss: 40.425532054901126\n",
      "test_loss: tensor(35.9819)\n",
      "epoch: 1460 train_loss: 40.42403678894043\n",
      "test_loss: tensor(35.9774)\n",
      "epoch: 1470 train_loss: 40.42417163848877\n",
      "test_loss: tensor(35.9738)\n",
      "epoch: 1480 train_loss: 40.42555150985718\n",
      "test_loss: tensor(35.9813)\n",
      "epoch: 1490 train_loss: 40.424034881591794\n",
      "test_loss: tensor(35.9770)\n",
      "epoch: 1500 train_loss: 40.424549388885495\n",
      "test_loss: tensor(35.9738)\n",
      "epoch: 1510 train_loss: 40.42037410736084\n",
      "test_loss: tensor(35.9910)\n",
      "epoch: 1520 train_loss: 40.424026298522946\n",
      "test_loss: tensor(35.9763)\n",
      "epoch: 1530 train_loss: 40.42454833984375\n",
      "test_loss: tensor(35.9733)\n",
      "epoch: 1540 train_loss: 40.4240797996521\n",
      "test_loss: tensor(35.9740)\n",
      "epoch: 1550 train_loss: 40.42407341003418\n",
      "test_loss: tensor(35.9757)\n",
      "epoch: 1560 train_loss: 40.42420072555542\n",
      "test_loss: tensor(35.9753)\n",
      "epoch: 1570 train_loss: 40.42407932281494\n",
      "test_loss: tensor(35.9734)\n",
      "epoch: 1580 train_loss: 40.42408752441406\n",
      "test_loss: tensor(35.9753)\n",
      "epoch: 1590 train_loss: 40.42374477386475\n",
      "test_loss: tensor(35.9765)\n",
      "epoch: 1600 train_loss: 40.423991203308105\n",
      "test_loss: tensor(35.9674)\n",
      "epoch: 1610 train_loss: 40.424134254455566\n",
      "test_loss: tensor(35.9747)\n",
      "epoch: 1620 train_loss: 40.42374067306518\n",
      "test_loss: tensor(35.9760)\n",
      "epoch: 1630 train_loss: 40.42399024963379\n",
      "test_loss: tensor(35.9784)\n",
      "epoch: 1640 train_loss: 40.42404088973999\n",
      "test_loss: tensor(35.9746)\n",
      "epoch: 1650 train_loss: 40.425536918640134\n",
      "test_loss: tensor(35.9743)\n",
      "epoch: 1660 train_loss: 40.42399673461914\n",
      "test_loss: tensor(35.9777)\n",
      "epoch: 1670 train_loss: 40.424135780334474\n",
      "test_loss: tensor(35.9740)\n",
      "epoch: 1680 train_loss: 40.42552604675293\n",
      "test_loss: tensor(35.9813)\n",
      "epoch: 1690 train_loss: 40.42400970458984\n",
      "test_loss: tensor(35.9770)\n",
      "epoch: 1700 train_loss: 40.424146461486814\n",
      "test_loss: tensor(35.9734)\n",
      "epoch: 1710 train_loss: 40.420329856872556\n",
      "test_loss: tensor(35.9912)\n",
      "epoch: 1720 train_loss: 40.42398548126221\n",
      "test_loss: tensor(35.9764)\n",
      "epoch: 1730 train_loss: 40.424524021148684\n",
      "test_loss: tensor(35.9732)\n",
      "epoch: 1740 train_loss: 40.424061107635495\n",
      "test_loss: tensor(35.9739)\n",
      "epoch: 1750 train_loss: 40.424042510986325\n",
      "test_loss: tensor(35.9755)\n",
      "epoch: 1760 train_loss: 40.42417211532593\n",
      "test_loss: tensor(35.9752)\n",
      "epoch: 1770 train_loss: 40.4240683555603\n",
      "test_loss: tensor(35.9732)\n",
      "epoch: 1780 train_loss: 40.4240608215332\n",
      "test_loss: tensor(35.9751)\n",
      "epoch: 1790 train_loss: 40.4237138748169\n",
      "test_loss: tensor(35.9763)\n",
      "epoch: 1800 train_loss: 40.42396869659424\n",
      "test_loss: tensor(35.9672)\n",
      "epoch: 1810 train_loss: 40.424095916748044\n",
      "test_loss: tensor(35.9745)\n",
      "epoch: 1820 train_loss: 40.42550430297852\n",
      "test_loss: tensor(35.9746)\n",
      "epoch: 1830 train_loss: 40.42396984100342\n",
      "test_loss: tensor(35.9778)\n",
      "epoch: 1840 train_loss: 40.42400989532471\n",
      "test_loss: tensor(35.9742)\n",
      "epoch: 1850 train_loss: 40.42548828125\n",
      "test_loss: tensor(35.9816)\n",
      "epoch: 1860 train_loss: 40.42398300170898\n",
      "test_loss: tensor(35.9771)\n",
      "epoch: 1870 train_loss: 40.42411479949951\n",
      "test_loss: tensor(35.9734)\n",
      "epoch: 1880 train_loss: 40.420315742492676\n",
      "test_loss: tensor(35.9911)\n",
      "epoch: 1890 train_loss: 40.42395782470703\n",
      "test_loss: tensor(35.9763)\n",
      "epoch: 1900 train_loss: 40.4245023727417\n",
      "test_loss: tensor(35.9731)\n",
      "epoch: 1910 train_loss: 40.42402610778809\n",
      "test_loss: tensor(35.9737)\n",
      "epoch: 1920 train_loss: 40.42403135299683\n",
      "test_loss: tensor(35.9754)\n",
      "epoch: 1930 train_loss: 40.424154663085936\n",
      "test_loss: tensor(35.9750)\n",
      "epoch: 1940 train_loss: 40.42404432296753\n",
      "test_loss: tensor(35.9676)\n",
      "epoch: 1950 train_loss: 40.42408151626587\n",
      "test_loss: tensor(35.9747)\n",
      "epoch: 1960 train_loss: 40.42369661331177\n",
      "test_loss: tensor(35.9758)\n",
      "epoch: 1970 train_loss: 40.42392807006836\n",
      "test_loss: tensor(35.9782)\n",
      "epoch: 1980 train_loss: 40.42399711608887\n",
      "test_loss: tensor(35.9744)\n",
      "epoch: 1990 train_loss: 40.425497913360594\n",
      "test_loss: tensor(35.9740)\n",
      "epoch: 2000 train_loss: 40.42395811080932\n",
      "test_loss: tensor(35.9774)\n",
      "epoch: 2010 train_loss: 40.424091815948486\n",
      "test_loss: tensor(35.9736)\n",
      "epoch: 2020 train_loss: 40.42548789978027\n",
      "test_loss: tensor(35.9810)\n",
      "epoch: 2030 train_loss: 40.42395782470703\n",
      "test_loss: tensor(35.9766)\n",
      "epoch: 2040 train_loss: 40.42447147369385\n",
      "test_loss: tensor(35.9733)\n",
      "epoch: 2050 train_loss: 40.420301246643064\n",
      "test_loss: tensor(35.9905)\n",
      "epoch: 2060 train_loss: 40.423946952819826\n",
      "test_loss: tensor(35.9759)\n",
      "epoch: 2070 train_loss: 40.4241247177124\n",
      "test_loss: tensor(35.9752)\n",
      "epoch: 2080 train_loss: 40.42401914596557\n",
      "test_loss: tensor(35.9732)\n",
      "epoch: 2090 train_loss: 40.424014472961424\n",
      "test_loss: tensor(35.9750)\n",
      "epoch: 2100 train_loss: 40.42366333007813\n",
      "test_loss: tensor(35.9761)\n",
      "epoch: 2110 train_loss: 40.42393560409546\n",
      "test_loss: tensor(35.9669)\n",
      "epoch: 2120 train_loss: 40.424064254760744\n",
      "test_loss: tensor(35.9743)\n",
      "epoch: 2130 train_loss: 40.4254714012146\n",
      "test_loss: tensor(35.9743)\n",
      "epoch: 2140 train_loss: 40.42393579483032\n",
      "test_loss: tensor(35.9776)\n",
      "epoch: 2150 train_loss: 40.42397327423096\n",
      "test_loss: tensor(35.9739)\n",
      "epoch: 2160 train_loss: 40.42544260025024\n",
      "test_loss: tensor(35.9813)\n",
      "epoch: 2170 train_loss: 40.42393913269043\n",
      "test_loss: tensor(35.9768)\n",
      "epoch: 2180 train_loss: 40.424079704284665\n",
      "test_loss: tensor(35.9732)\n",
      "epoch: 2190 train_loss: 40.420280838012694\n",
      "test_loss: tensor(35.9909)\n",
      "epoch: 2200 train_loss: 40.42393255233765\n",
      "test_loss: tensor(35.9760)\n",
      "epoch: 2210 train_loss: 40.42445449829101\n",
      "test_loss: tensor(35.9728)\n",
      "epoch: 2220 train_loss: 40.424002742767335\n",
      "test_loss: tensor(35.9735)\n",
      "epoch: 2230 train_loss: 40.42399730682373\n",
      "test_loss: tensor(35.9751)\n",
      "epoch: 2240 train_loss: 40.424105930328366\n",
      "test_loss: tensor(35.9747)\n",
      "epoch: 2250 train_loss: 40.424014282226565\n",
      "test_loss: tensor(35.9674)\n",
      "epoch: 2260 train_loss: 40.424052238464355\n",
      "test_loss: tensor(35.9745)\n",
      "epoch: 2270 train_loss: 40.42366304397583\n",
      "test_loss: tensor(35.9756)\n",
      "epoch: 2280 train_loss: 40.42389392852783\n",
      "test_loss: tensor(35.9780)\n",
      "epoch: 2290 train_loss: 40.42396087646485\n",
      "test_loss: tensor(35.9741)\n",
      "epoch: 2300 train_loss: 40.425454235076906\n",
      "test_loss: tensor(35.9738)\n",
      "epoch: 2310 train_loss: 40.42391557693482\n",
      "test_loss: tensor(35.9772)\n",
      "epoch: 2320 train_loss: 40.42405242919922\n",
      "test_loss: tensor(35.9734)\n",
      "epoch: 2330 train_loss: 40.4254433631897\n",
      "test_loss: tensor(35.9808)\n",
      "epoch: 2340 train_loss: 40.42392587661743\n",
      "test_loss: tensor(35.9764)\n",
      "epoch: 2350 train_loss: 40.42442560195923\n",
      "test_loss: tensor(35.9731)\n",
      "epoch: 2360 train_loss: 40.420273303985596\n",
      "test_loss: tensor(35.9903)\n",
      "epoch: 2370 train_loss: 40.423916816711426\n",
      "test_loss: tensor(35.9756)\n",
      "epoch: 2380 train_loss: 40.42408504486084\n",
      "test_loss: tensor(35.9750)\n",
      "epoch: 2390 train_loss: 40.42398633956909\n",
      "test_loss: tensor(35.9729)\n",
      "epoch: 2400 train_loss: 40.42397899627686\n",
      "test_loss: tensor(35.9748)\n",
      "epoch: 2410 train_loss: 40.423640441894534\n",
      "test_loss: tensor(35.9759)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2420 train_loss: 40.423879337310794\n",
      "test_loss: tensor(35.9668)\n",
      "epoch: 2430 train_loss: 40.424035263061526\n",
      "test_loss: tensor(35.9741)\n",
      "epoch: 2440 train_loss: 40.425429344177246\n",
      "test_loss: tensor(35.9741)\n",
      "epoch: 2450 train_loss: 40.42389812469482\n",
      "test_loss: tensor(35.9774)\n",
      "epoch: 2460 train_loss: 40.423936462402345\n",
      "test_loss: tensor(35.9738)\n",
      "epoch: 2470 train_loss: 40.42541351318359\n",
      "test_loss: tensor(35.9811)\n",
      "epoch: 2480 train_loss: 40.423900508880614\n",
      "test_loss: tensor(35.9766)\n",
      "epoch: 2490 train_loss: 40.42403087615967\n",
      "test_loss: tensor(35.9730)\n",
      "epoch: 2500 train_loss: 40.42023525238037\n",
      "test_loss: tensor(35.9907)\n",
      "epoch: 2510 train_loss: 40.423886966705325\n",
      "test_loss: tensor(35.9759)\n",
      "epoch: 2520 train_loss: 40.42444000244141\n",
      "test_loss: tensor(35.9727)\n",
      "epoch: 2530 train_loss: 40.423952293396\n",
      "test_loss: tensor(35.9733)\n",
      "epoch: 2540 train_loss: 40.42395839691162\n",
      "test_loss: tensor(35.9750)\n",
      "epoch: 2550 train_loss: 40.4240647315979\n",
      "test_loss: tensor(35.9745)\n",
      "epoch: 2560 train_loss: 40.42397012710571\n",
      "test_loss: tensor(35.9672)\n",
      "epoch: 2570 train_loss: 40.4240062713623\n",
      "test_loss: tensor(35.9743)\n",
      "epoch: 2580 train_loss: 40.42361640930176\n",
      "test_loss: tensor(35.9754)\n",
      "epoch: 2590 train_loss: 40.42386264801026\n",
      "test_loss: tensor(35.9778)\n",
      "epoch: 2600 train_loss: 40.42391920089722\n",
      "test_loss: tensor(35.9740)\n",
      "epoch: 2610 train_loss: 40.42542390823364\n",
      "test_loss: tensor(35.9736)\n",
      "epoch: 2620 train_loss: 40.42387351989746\n",
      "test_loss: tensor(35.9771)\n",
      "epoch: 2630 train_loss: 40.42401075363159\n",
      "test_loss: tensor(35.9732)\n",
      "epoch: 2640 train_loss: 40.42539796829224\n",
      "test_loss: tensor(35.9806)\n",
      "epoch: 2650 train_loss: 40.42389450073242\n",
      "test_loss: tensor(35.9763)\n",
      "epoch: 2660 train_loss: 40.42440919876098\n",
      "test_loss: tensor(35.9729)\n",
      "epoch: 2670 train_loss: 40.4202392578125\n",
      "test_loss: tensor(35.9902)\n",
      "epoch: 2680 train_loss: 40.42388763427734\n",
      "test_loss: tensor(35.9755)\n",
      "epoch: 2690 train_loss: 40.424046421051024\n",
      "test_loss: tensor(35.9749)\n",
      "epoch: 2700 train_loss: 40.4239387512207\n",
      "test_loss: tensor(35.9728)\n",
      "epoch: 2710 train_loss: 40.42394342422485\n",
      "test_loss: tensor(35.9746)\n",
      "epoch: 2720 train_loss: 40.423599815368654\n",
      "test_loss: tensor(35.9758)\n",
      "epoch: 2730 train_loss: 40.423848152160645\n",
      "test_loss: tensor(35.9666)\n",
      "epoch: 2740 train_loss: 40.42399234771729\n",
      "test_loss: tensor(35.9739)\n",
      "epoch: 2750 train_loss: 40.425400257110596\n",
      "test_loss: tensor(35.9740)\n",
      "epoch: 2760 train_loss: 40.423854732513426\n",
      "test_loss: tensor(35.9772)\n",
      "epoch: 2770 train_loss: 40.42390327453613\n",
      "test_loss: tensor(35.9736)\n",
      "epoch: 2780 train_loss: 40.42537794113159\n",
      "test_loss: tensor(35.9810)\n",
      "epoch: 2790 train_loss: 40.42384796142578\n",
      "test_loss: tensor(35.9765)\n",
      "epoch: 2800 train_loss: 40.42400932312012\n",
      "test_loss: tensor(35.9729)\n",
      "epoch: 2810 train_loss: 40.42020263671875\n",
      "test_loss: tensor(35.9906)\n",
      "epoch: 2820 train_loss: 40.42387065887451\n",
      "test_loss: tensor(35.9757)\n",
      "epoch: 2830 train_loss: 40.424390983581546\n",
      "test_loss: tensor(35.9725)\n",
      "epoch: 2840 train_loss: 40.42391586303711\n",
      "test_loss: tensor(35.9732)\n",
      "epoch: 2850 train_loss: 40.423917865753175\n",
      "test_loss: tensor(35.9748)\n",
      "epoch: 2860 train_loss: 40.424036502838135\n",
      "test_loss: tensor(35.9744)\n",
      "epoch: 2870 train_loss: 40.423926162719724\n",
      "test_loss: tensor(35.9671)\n",
      "epoch: 2880 train_loss: 40.42396621704101\n",
      "test_loss: tensor(35.9742)\n",
      "epoch: 2890 train_loss: 40.423590087890624\n",
      "test_loss: tensor(35.9753)\n",
      "epoch: 2900 train_loss: 40.42381296157837\n",
      "test_loss: tensor(35.9777)\n",
      "epoch: 2910 train_loss: 40.423886108398435\n",
      "test_loss: tensor(35.9739)\n",
      "epoch: 2920 train_loss: 40.42538175582886\n",
      "test_loss: tensor(35.9735)\n",
      "epoch: 2930 train_loss: 40.42385454177857\n",
      "test_loss: tensor(35.9769)\n",
      "epoch: 2940 train_loss: 40.423989391326906\n",
      "test_loss: tensor(35.9731)\n",
      "epoch: 2950 train_loss: 40.425367546081546\n",
      "test_loss: tensor(35.9805)\n",
      "epoch: 2960 train_loss: 40.423851013183594\n",
      "test_loss: tensor(35.9762)\n",
      "epoch: 2970 train_loss: 40.424367332458495\n",
      "test_loss: tensor(35.9728)\n",
      "epoch: 2980 train_loss: 40.42018995285034\n",
      "test_loss: tensor(35.9901)\n",
      "epoch: 2990 train_loss: 40.42384300231934\n",
      "test_loss: tensor(35.9754)\n",
      "epoch: 3000 train_loss: 40.423998546600345\n",
      "test_loss: tensor(35.9748)\n",
      "epoch: 3010 train_loss: 40.42390327453613\n",
      "test_loss: tensor(35.9726)\n",
      "epoch: 3020 train_loss: 40.4239104270935\n",
      "test_loss: tensor(35.9745)\n",
      "epoch: 3030 train_loss: 40.42356491088867\n",
      "test_loss: tensor(35.9756)\n",
      "epoch: 3040 train_loss: 40.42380313873291\n",
      "test_loss: tensor(35.9665)\n",
      "epoch: 3050 train_loss: 40.42395172119141\n",
      "test_loss: tensor(35.9738)\n",
      "epoch: 3060 train_loss: 40.425346565246585\n",
      "test_loss: tensor(35.9739)\n",
      "epoch: 3070 train_loss: 40.423822498321535\n",
      "test_loss: tensor(35.9771)\n",
      "epoch: 3080 train_loss: 40.42386932373047\n",
      "test_loss: tensor(35.9735)\n",
      "epoch: 3090 train_loss: 40.425330543518065\n",
      "test_loss: tensor(35.9809)\n",
      "epoch: 3100 train_loss: 40.42381734848023\n",
      "test_loss: tensor(35.9764)\n",
      "epoch: 3110 train_loss: 40.42397165298462\n",
      "test_loss: tensor(35.9728)\n",
      "epoch: 3120 train_loss: 40.42016515731812\n",
      "test_loss: tensor(35.9904)\n",
      "epoch: 3130 train_loss: 40.423822212219235\n",
      "test_loss: tensor(35.9756)\n",
      "epoch: 3140 train_loss: 40.42434921264648\n",
      "test_loss: tensor(35.9724)\n",
      "epoch: 3150 train_loss: 40.42388601303101\n",
      "test_loss: tensor(35.9731)\n",
      "epoch: 3160 train_loss: 40.42388563156128\n",
      "test_loss: tensor(35.9747)\n",
      "epoch: 3170 train_loss: 40.42398157119751\n",
      "test_loss: tensor(35.9743)\n",
      "epoch: 3180 train_loss: 40.42388105392456\n",
      "test_loss: tensor(35.9670)\n",
      "epoch: 3190 train_loss: 40.42393999099731\n",
      "test_loss: tensor(35.9741)\n",
      "epoch: 3200 train_loss: 40.42354145050049\n",
      "test_loss: tensor(35.9752)\n",
      "epoch: 3210 train_loss: 40.42378158569336\n",
      "test_loss: tensor(35.9776)\n",
      "epoch: 3220 train_loss: 40.423843479156496\n",
      "test_loss: tensor(35.9738)\n",
      "epoch: 3230 train_loss: 40.425344467163086\n",
      "test_loss: tensor(35.9734)\n",
      "epoch: 3240 train_loss: 40.42381210327149\n",
      "test_loss: tensor(35.9768)\n",
      "epoch: 3250 train_loss: 40.42392635345459\n",
      "test_loss: tensor(35.9730)\n",
      "epoch: 3260 train_loss: 40.425322914123534\n",
      "test_loss: tensor(35.9804)\n",
      "epoch: 3270 train_loss: 40.4238000869751\n",
      "test_loss: tensor(35.9760)\n",
      "epoch: 3280 train_loss: 40.42432680130005\n",
      "test_loss: tensor(35.9727)\n",
      "epoch: 3290 train_loss: 40.42015781402588\n",
      "test_loss: tensor(35.9900)\n",
      "epoch: 3300 train_loss: 40.42380771636963\n",
      "test_loss: tensor(35.9753)\n",
      "epoch: 3310 train_loss: 40.423976230621335\n",
      "test_loss: tensor(35.9746)\n",
      "epoch: 3320 train_loss: 40.423879051208495\n",
      "test_loss: tensor(35.9726)\n",
      "epoch: 3330 train_loss: 40.423876190185545\n",
      "test_loss: tensor(35.9744)\n",
      "epoch: 3340 train_loss: 40.42352285385132\n",
      "test_loss: tensor(35.9756)\n",
      "epoch: 3350 train_loss: 40.42374982833862\n",
      "test_loss: tensor(35.9664)\n",
      "epoch: 3360 train_loss: 40.42391185760498\n",
      "test_loss: tensor(35.9738)\n",
      "epoch: 3370 train_loss: 40.425319290161134\n",
      "test_loss: tensor(35.9738)\n",
      "epoch: 3380 train_loss: 40.42378330230713\n",
      "test_loss: tensor(35.9770)\n",
      "epoch: 3390 train_loss: 40.42382707595825\n",
      "test_loss: tensor(35.9734)\n",
      "epoch: 3400 train_loss: 40.42529554367066\n",
      "test_loss: tensor(35.9808)\n",
      "epoch: 3410 train_loss: 40.42377576828003\n",
      "test_loss: tensor(35.9763)\n",
      "epoch: 3420 train_loss: 40.42393283843994\n",
      "test_loss: tensor(35.9726)\n",
      "epoch: 3430 train_loss: 40.42011556625366\n",
      "test_loss: tensor(35.9903)\n",
      "epoch: 3440 train_loss: 40.42377986907959\n",
      "test_loss: tensor(35.9755)\n",
      "epoch: 3450 train_loss: 40.42431640625\n",
      "test_loss: tensor(35.9723)\n",
      "epoch: 3460 train_loss: 40.423850440979\n",
      "test_loss: tensor(35.9730)\n",
      "epoch: 3470 train_loss: 40.423843479156496\n",
      "test_loss: tensor(35.9747)\n",
      "epoch: 3480 train_loss: 40.42396297454834\n",
      "test_loss: tensor(35.9742)\n",
      "epoch: 3490 train_loss: 40.423826122283934\n",
      "test_loss: tensor(35.9669)\n",
      "epoch: 3500 train_loss: 40.42389354705811\n",
      "test_loss: tensor(35.9740)\n",
      "epoch: 3510 train_loss: 40.42352113723755\n",
      "test_loss: tensor(35.9751)\n",
      "epoch: 3520 train_loss: 40.423750972747804\n",
      "test_loss: tensor(35.9775)\n",
      "epoch: 3530 train_loss: 40.42380962371826\n",
      "test_loss: tensor(35.9737)\n",
      "epoch: 3540 train_loss: 40.42530298233032\n",
      "test_loss: tensor(35.9733)\n",
      "epoch: 3550 train_loss: 40.42376651763916\n",
      "test_loss: tensor(35.9767)\n",
      "epoch: 3560 train_loss: 40.423897171020506\n",
      "test_loss: tensor(35.9730)\n",
      "epoch: 3570 train_loss: 40.42529010772705\n",
      "test_loss: tensor(35.9803)\n",
      "epoch: 3580 train_loss: 40.42377052307129\n",
      "test_loss: tensor(35.9760)\n",
      "epoch: 3590 train_loss: 40.42428712844848\n",
      "test_loss: tensor(35.9726)\n",
      "epoch: 3600 train_loss: 40.420116329193114\n",
      "test_loss: tensor(35.9898)\n",
      "epoch: 3610 train_loss: 40.423786640167236\n",
      "test_loss: tensor(35.9752)\n",
      "epoch: 3620 train_loss: 40.42394685745239\n",
      "test_loss: tensor(35.9746)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3630 train_loss: 40.42382783889771\n",
      "test_loss: tensor(35.9725)\n",
      "epoch: 3640 train_loss: 40.42383737564087\n",
      "test_loss: tensor(35.9743)\n",
      "epoch: 3650 train_loss: 40.42347917556763\n",
      "test_loss: tensor(35.9755)\n",
      "epoch: 3660 train_loss: 40.42372341156006\n",
      "test_loss: tensor(35.9663)\n",
      "epoch: 3670 train_loss: 40.423880863189694\n",
      "test_loss: tensor(35.9737)\n",
      "epoch: 3680 train_loss: 40.425279235839845\n",
      "test_loss: tensor(35.9737)\n",
      "epoch: 3690 train_loss: 40.42374696731567\n",
      "test_loss: tensor(35.9769)\n",
      "epoch: 3700 train_loss: 40.42379875183106\n",
      "test_loss: tensor(35.9733)\n",
      "epoch: 3710 train_loss: 40.42526073455811\n",
      "test_loss: tensor(35.9807)\n",
      "epoch: 3720 train_loss: 40.42374439239502\n",
      "test_loss: tensor(35.9762)\n",
      "epoch: 3730 train_loss: 40.423886966705325\n",
      "test_loss: tensor(35.9726)\n",
      "epoch: 3740 train_loss: 40.42009334564209\n",
      "test_loss: tensor(35.9902)\n",
      "epoch: 3750 train_loss: 40.42375345230103\n",
      "test_loss: tensor(35.9754)\n",
      "epoch: 3760 train_loss: 40.42427005767822\n",
      "test_loss: tensor(35.9723)\n",
      "epoch: 3770 train_loss: 40.42380790710449\n",
      "test_loss: tensor(35.9729)\n",
      "epoch: 3780 train_loss: 40.42381744384765\n",
      "test_loss: tensor(35.9746)\n",
      "epoch: 3790 train_loss: 40.423923110961915\n",
      "test_loss: tensor(35.9741)\n",
      "epoch: 3800 train_loss: 40.42379302978516\n",
      "test_loss: tensor(35.9668)\n",
      "epoch: 3810 train_loss: 40.423863887786865\n",
      "test_loss: tensor(35.9739)\n",
      "epoch: 3820 train_loss: 40.42347469329834\n",
      "test_loss: tensor(35.9750)\n",
      "epoch: 3830 train_loss: 40.423716163635255\n",
      "test_loss: tensor(35.9774)\n",
      "epoch: 3840 train_loss: 40.42378120422363\n",
      "test_loss: tensor(35.9736)\n",
      "epoch: 3850 train_loss: 40.425274562835696\n",
      "test_loss: tensor(35.9733)\n",
      "epoch: 3860 train_loss: 40.42371807098389\n",
      "test_loss: tensor(35.9766)\n",
      "epoch: 3870 train_loss: 40.42386169433594\n",
      "test_loss: tensor(35.9729)\n",
      "epoch: 3880 train_loss: 40.425249862670896\n",
      "test_loss: tensor(35.9802)\n",
      "epoch: 3890 train_loss: 40.4237340927124\n",
      "test_loss: tensor(35.9759)\n",
      "epoch: 3900 train_loss: 40.424241638183595\n",
      "test_loss: tensor(35.9726)\n",
      "epoch: 3910 train_loss: 40.42007942199707\n",
      "test_loss: tensor(35.9898)\n",
      "epoch: 3920 train_loss: 40.42374563217163\n",
      "test_loss: tensor(35.9751)\n",
      "epoch: 3930 train_loss: 40.423904991149904\n",
      "test_loss: tensor(35.9745)\n",
      "epoch: 3940 train_loss: 40.423824310302734\n",
      "test_loss: tensor(35.9724)\n",
      "epoch: 3950 train_loss: 40.42379589080811\n",
      "test_loss: tensor(35.9742)\n",
      "epoch: 3960 train_loss: 40.42345018386841\n",
      "test_loss: tensor(35.9754)\n",
      "epoch: 3970 train_loss: 40.423665046691895\n",
      "test_loss: tensor(35.9663)\n",
      "epoch: 3980 train_loss: 40.4238468170166\n",
      "test_loss: tensor(35.9736)\n",
      "epoch: 3990 train_loss: 40.425249099731445\n",
      "test_loss: tensor(35.9737)\n",
      "epoch: 4000 train_loss: 40.42370319366455\n",
      "test_loss: tensor(35.9768)\n",
      "epoch: 4010 train_loss: 40.42375602722168\n",
      "test_loss: tensor(35.9732)\n",
      "epoch: 4020 train_loss: 40.4252142906189\n",
      "test_loss: tensor(35.9806)\n",
      "epoch: 4030 train_loss: 40.423695755004886\n",
      "test_loss: tensor(35.9761)\n",
      "epoch: 4040 train_loss: 40.423851013183594\n",
      "test_loss: tensor(35.9725)\n",
      "epoch: 4050 train_loss: 40.420054054260255\n",
      "test_loss: tensor(35.9902)\n",
      "epoch: 4060 train_loss: 40.42372379302979\n",
      "test_loss: tensor(35.9753)\n",
      "epoch: 4070 train_loss: 40.42424488067627\n",
      "test_loss: tensor(35.9722)\n",
      "epoch: 4080 train_loss: 40.423771381378174\n",
      "test_loss: tensor(35.9728)\n",
      "epoch: 4090 train_loss: 40.423780059814455\n",
      "test_loss: tensor(35.9745)\n",
      "epoch: 4100 train_loss: 40.4238883972168\n",
      "test_loss: tensor(35.9741)\n",
      "epoch: 4110 train_loss: 40.423750686645505\n",
      "test_loss: tensor(35.9667)\n",
      "epoch: 4120 train_loss: 40.42380590438843\n",
      "test_loss: tensor(35.9738)\n",
      "epoch: 4130 train_loss: 40.4234335899353\n",
      "test_loss: tensor(35.9749)\n",
      "epoch: 4140 train_loss: 40.42367095947266\n",
      "test_loss: tensor(35.9774)\n",
      "epoch: 4150 train_loss: 40.42374038696289\n",
      "test_loss: tensor(35.9735)\n",
      "epoch: 4160 train_loss: 40.42523422241211\n",
      "test_loss: tensor(35.9732)\n",
      "epoch: 4170 train_loss: 40.42368249893188\n",
      "test_loss: tensor(35.9766)\n",
      "epoch: 4180 train_loss: 40.42383050918579\n",
      "test_loss: tensor(35.9728)\n",
      "epoch: 4190 train_loss: 40.42520809173584\n",
      "test_loss: tensor(35.9801)\n",
      "epoch: 4200 train_loss: 40.42370204925537\n",
      "test_loss: tensor(35.9758)\n",
      "epoch: 4210 train_loss: 40.424213600158694\n",
      "test_loss: tensor(35.9725)\n",
      "epoch: 4220 train_loss: 40.42003736495972\n",
      "test_loss: tensor(35.9897)\n",
      "epoch: 4230 train_loss: 40.423693084716795\n",
      "test_loss: tensor(35.9750)\n",
      "epoch: 4240 train_loss: 40.42386341094971\n",
      "test_loss: tensor(35.9744)\n",
      "epoch: 4250 train_loss: 40.423767471313475\n",
      "test_loss: tensor(35.9723)\n",
      "epoch: 4260 train_loss: 40.42375316619873\n",
      "test_loss: tensor(35.9742)\n",
      "epoch: 4270 train_loss: 40.42340803146362\n",
      "test_loss: tensor(35.9753)\n",
      "epoch: 4280 train_loss: 40.423635959625244\n",
      "test_loss: tensor(35.9662)\n",
      "epoch: 4290 train_loss: 40.42381753921509\n",
      "test_loss: tensor(35.9735)\n",
      "epoch: 4300 train_loss: 40.425215816497804\n",
      "test_loss: tensor(35.9736)\n",
      "epoch: 4310 train_loss: 40.42366256713867\n",
      "test_loss: tensor(35.9768)\n",
      "epoch: 4320 train_loss: 40.42371463775635\n",
      "test_loss: tensor(35.9731)\n",
      "epoch: 4330 train_loss: 40.42519817352295\n",
      "test_loss: tensor(35.9806)\n",
      "epoch: 4340 train_loss: 40.42367057800293\n",
      "test_loss: tensor(35.9761)\n",
      "epoch: 4350 train_loss: 40.42382583618164\n",
      "test_loss: tensor(35.9724)\n",
      "epoch: 4360 train_loss: 40.42001829147339\n",
      "test_loss: tensor(35.9901)\n",
      "epoch: 4370 train_loss: 40.42368087768555\n",
      "test_loss: tensor(35.9752)\n",
      "epoch: 4380 train_loss: 40.424196338653566\n",
      "test_loss: tensor(35.9721)\n",
      "epoch: 4390 train_loss: 40.42374982833862\n",
      "test_loss: tensor(35.9728)\n",
      "epoch: 4400 train_loss: 40.4237473487854\n",
      "test_loss: tensor(35.9744)\n",
      "epoch: 4410 train_loss: 40.42383728027344\n",
      "test_loss: tensor(35.9740)\n",
      "epoch: 4420 train_loss: 40.423713779449464\n",
      "test_loss: tensor(35.9667)\n",
      "epoch: 4430 train_loss: 40.423768520355225\n",
      "test_loss: tensor(35.9738)\n",
      "epoch: 4440 train_loss: 40.425191688537595\n",
      "test_loss: tensor(35.9737)\n",
      "epoch: 4450 train_loss: 40.42365369796753\n",
      "test_loss: tensor(35.9769)\n",
      "epoch: 4460 train_loss: 40.423707008361816\n",
      "test_loss: tensor(35.9732)\n",
      "epoch: 4470 train_loss: 40.4251633644104\n",
      "test_loss: tensor(35.9805)\n",
      "epoch: 4480 train_loss: 40.423671913146975\n",
      "test_loss: tensor(35.9760)\n",
      "epoch: 4490 train_loss: 40.42380723953247\n",
      "test_loss: tensor(35.9724)\n",
      "epoch: 4500 train_loss: 40.41999578475952\n",
      "test_loss: tensor(35.9901)\n",
      "epoch: 4510 train_loss: 40.423666095733644\n",
      "test_loss: tensor(35.9752)\n",
      "epoch: 4520 train_loss: 40.424203872680664\n",
      "test_loss: tensor(35.9720)\n",
      "epoch: 4530 train_loss: 40.4237156867981\n",
      "test_loss: tensor(35.9727)\n",
      "epoch: 4540 train_loss: 40.42371768951416\n",
      "test_loss: tensor(35.9744)\n",
      "epoch: 4550 train_loss: 40.423825359344484\n",
      "test_loss: tensor(35.9740)\n",
      "epoch: 4560 train_loss: 40.42370204925537\n",
      "test_loss: tensor(35.9666)\n",
      "epoch: 4570 train_loss: 40.42376499176025\n",
      "test_loss: tensor(35.9738)\n",
      "epoch: 4580 train_loss: 40.423387718200686\n",
      "test_loss: tensor(35.9748)\n",
      "epoch: 4590 train_loss: 40.4236083984375\n",
      "test_loss: tensor(35.9773)\n",
      "epoch: 4600 train_loss: 40.423686027526855\n",
      "test_loss: tensor(35.9734)\n",
      "epoch: 4610 train_loss: 40.425187301635745\n",
      "test_loss: tensor(35.9731)\n",
      "epoch: 4620 train_loss: 40.42363948822022\n",
      "test_loss: tensor(35.9765)\n",
      "epoch: 4630 train_loss: 40.42377338409424\n",
      "test_loss: tensor(35.9727)\n",
      "epoch: 4640 train_loss: 40.41997652053833\n",
      "test_loss: tensor(35.9903)\n",
      "epoch: 4650 train_loss: 40.42364730834961\n",
      "test_loss: tensor(35.9754)\n",
      "epoch: 4660 train_loss: 40.42416334152222\n",
      "test_loss: tensor(35.9721)\n",
      "epoch: 4670 train_loss: 40.42371082305908\n",
      "test_loss: tensor(35.9727)\n",
      "epoch: 4680 train_loss: 40.4237024307251\n",
      "test_loss: tensor(35.9744)\n",
      "epoch: 4690 train_loss: 40.42381362915039\n",
      "test_loss: tensor(35.9740)\n",
      "epoch: 4700 train_loss: 40.423676109313966\n",
      "test_loss: tensor(35.9666)\n",
      "epoch: 4710 train_loss: 40.4237564086914\n",
      "test_loss: tensor(35.9737)\n",
      "epoch: 4720 train_loss: 40.423379516601564\n",
      "test_loss: tensor(35.9748)\n",
      "epoch: 4730 train_loss: 40.423591709136964\n",
      "test_loss: tensor(35.9772)\n",
      "epoch: 4740 train_loss: 40.42367515563965\n",
      "test_loss: tensor(35.9734)\n",
      "epoch: 4750 train_loss: 40.42516460418701\n",
      "test_loss: tensor(35.9731)\n",
      "epoch: 4760 train_loss: 40.42361307144165\n",
      "test_loss: tensor(35.9764)\n",
      "epoch: 4770 train_loss: 40.42375898361206\n",
      "test_loss: tensor(35.9727)\n",
      "epoch: 4780 train_loss: 40.42514533996582\n",
      "test_loss: tensor(35.9800)\n",
      "epoch: 4790 train_loss: 40.423629188537596\n",
      "test_loss: tensor(35.9757)\n",
      "epoch: 4800 train_loss: 40.42413539886475\n",
      "test_loss: tensor(35.9724)\n",
      "epoch: 4810 train_loss: 40.41997146606445\n",
      "test_loss: tensor(35.9896)\n",
      "epoch: 4820 train_loss: 40.42363748550415\n",
      "test_loss: tensor(35.9749)\n",
      "epoch: 4830 train_loss: 40.42379455566406\n",
      "test_loss: tensor(35.9743)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4840 train_loss: 40.42370443344116\n",
      "test_loss: tensor(35.9668)\n",
      "epoch: 4850 train_loss: 40.423733711242676\n",
      "test_loss: tensor(35.9739)\n",
      "epoch: 4860 train_loss: 40.423351764678955\n",
      "test_loss: tensor(35.9749)\n",
      "epoch: 4870 train_loss: 40.423583316802976\n",
      "test_loss: tensor(35.9772)\n",
      "epoch: 4880 train_loss: 40.42364559173584\n",
      "test_loss: tensor(35.9734)\n",
      "epoch: 4890 train_loss: 40.4251353263855\n",
      "test_loss: tensor(35.9730)\n",
      "epoch: 4900 train_loss: 40.4236026763916\n",
      "test_loss: tensor(35.9764)\n",
      "epoch: 4910 train_loss: 40.423743057250974\n",
      "test_loss: tensor(35.9727)\n",
      "epoch: 4920 train_loss: 40.4251145362854\n",
      "test_loss: tensor(35.9800)\n",
      "epoch: 4930 train_loss: 40.4236120223999\n",
      "test_loss: tensor(35.9757)\n",
      "epoch: 4940 train_loss: 40.42412929534912\n",
      "test_loss: tensor(35.9724)\n",
      "epoch: 4950 train_loss: 40.41995429992676\n",
      "test_loss: tensor(35.9895)\n",
      "epoch: 4960 train_loss: 40.4236026763916\n",
      "test_loss: tensor(35.9749)\n",
      "epoch: 4970 train_loss: 40.42378149032593\n",
      "test_loss: tensor(35.9743)\n",
      "epoch: 4980 train_loss: 40.423688888549805\n",
      "test_loss: tensor(35.9721)\n",
      "epoch: 4990 train_loss: 40.423660564422605\n",
      "test_loss: tensor(35.9740)\n",
      "epoch: 5000 train_loss: 40.4233341217041\n",
      "test_loss: tensor(35.9752)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    for epoch in range(5000):\n",
    "        train1(epoch)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            model1.eval()\n",
    "            test1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dd55e74f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = model1(Xtest2_tensor)\n",
    "y = pd.concat([pd.Series(Xtest2[:, 0].reshape(-1), name='send rates'), pd.Series(Xtest2[:, 1].reshape(-1), name='block size'), \n",
    "               pd.Series(Ytest2_tensor.numpy().reshape(-1), name='throughput_true'), \n",
    "               pd.Series(y_pred.numpy().reshape(-1), name='throughput_pred')], axis=1)\n",
    "y.to_csv('./throughput_true_pred_related1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5557c67f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>send rates</th>\n",
       "      <th>block size</th>\n",
       "      <th>throughput_true</th>\n",
       "      <th>throughput_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>197.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>163.25279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.2</td>\n",
       "      <td>60.0</td>\n",
       "      <td>63.2</td>\n",
       "      <td>62.05043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>170.2</td>\n",
       "      <td>90.0</td>\n",
       "      <td>128.5</td>\n",
       "      <td>133.67148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170.3</td>\n",
       "      <td>200.0</td>\n",
       "      <td>159.6</td>\n",
       "      <td>144.64705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.5</td>\n",
       "      <td>130.0</td>\n",
       "      <td>80.6</td>\n",
       "      <td>79.03754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   send rates  block size  throughput_true  throughput_pred\n",
       "0       197.0       190.0            163.0        163.25279\n",
       "1        70.2        60.0             63.2         62.05043\n",
       "2       170.2        90.0            128.5        133.67148\n",
       "3       170.3       200.0            159.6        144.64705\n",
       "4        90.5       130.0             80.6         79.03754"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the test set MAE RMSE MAPE\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./throughput_true_pred_related1.csv')\n",
    "data.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "275fbb3c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([163. ,  63.2, 128.5, 159.6,  80.6, 129.1,  98.6, 117.4,  19.9,\n",
       "       118. ,  81.3, 159.4,  83.3, 125.4, 122.6,  99.1, 134.4,  10. ,\n",
       "        37.7, 119.3,  61.7, 103.5, 134.1,  96.7,  10. ,  47.8, 134.9,\n",
       "        90.9, 133.5,  92.3,  50.1,  10. ,  78.3, 121.5,   9.9,  50.1,\n",
       "        28.4,  53.9, 163.5,  69.8, 109.1,  92.7,  78.4,  37.3, 139.4,\n",
       "        46.9, 138.7, 123.1, 121.6, 121.4,  38.3,  98.9, 103.3,  10. ,\n",
       "       120.7, 116. , 121.4,  59.5, 121.9, 126.8,  55.2,  38.3,  97.2,\n",
       "       103.9, 157.9,  96.5,  54.3, 120.9, 109.4, 121.8,  96.2,  48.2,\n",
       "       130. , 138.2,  10. , 132.7,  30.1,  83.7,  61.6,  99.2])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['throughput_true'].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a5823ab8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([163.25279 ,  62.05043 , 133.67148 , 144.64705 ,  79.03754 ,\n",
       "       126.85877 ,  87.41215 , 127.68475 ,  21.337149, 117.75988 ,\n",
       "        79.06961 , 149.71494 ,  86.81833 , 126.68283 , 119.89191 ,\n",
       "       103.26853 , 147.40732 ,  12.856003,  38.27462 , 102.881065,\n",
       "        61.961452, 105.49646 , 132.35321 ,  95.33157 ,  13.538788,\n",
       "        46.186775, 138.94624 ,  94.51016 , 128.90276 ,  95.17842 ,\n",
       "        45.479168,  12.799105,  78.55753 , 120.14911 ,  12.912899,\n",
       "        45.42227 ,  30.021063,  53.78962 , 162.3078  ,  62.928726,\n",
       "       119.58738 ,  94.92602 ,  78.89892 ,  37.364243, 141.42978 ,\n",
       "        45.706764, 145.73715 , 127.45184 , 136.1907  , 120.31981 ,\n",
       "        37.534935, 103.23645 , 103.30063 ,  13.595686, 128.05096 ,\n",
       "       121.452   , 119.978424,  54.6431  , 111.90282 , 123.122696,\n",
       "        54.074116,  37.648735, 103.66683 , 111.46518 , 146.63794 ,\n",
       "       101.10092 ,  54.017212, 133.01202 , 119.86461 , 136.32208 ,\n",
       "        95.64087 ,  46.275753, 141.53937 , 145.07794 ,  13.197393,\n",
       "       136.19897 ,  29.053785,  86.36316 ,  62.448715, 103.01612 ])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = data['throughput_pred'].values\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5633d8da",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7946ad5d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  4.3392459\n",
      "RMSE:  5.997928346305283\n",
      "MAPE:  0.06390820799899966\n"
     ]
    }
   ],
   "source": [
    "MAE = metrics.mean_absolute_error(y, y_hat)\n",
    "RMSE = metrics.mean_squared_error(y, y_hat) ** 0.5\n",
    "MAPE = metrics.mean_absolute_percentage_error(y, y_hat)\n",
    "print('MAE: ', MAE)\n",
    "print('RMSE: ', RMSE)\n",
    "print('MAPE: ', MAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3099e69e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Choose the optimal block size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae3dc70",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## MLP1 to predict latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4f7783b0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 50,\n",
       " 50,\n",
       " 50,\n",
       " 50,\n",
       " 50,\n",
       " 50,\n",
       " 50,\n",
       " 50,\n",
       " 50,\n",
       " 50,\n",
       " 50,\n",
       " 50,\n",
       " 50,\n",
       " 50,\n",
       " 50,\n",
       " 50,\n",
       " 50,\n",
       " 50,\n",
       " 50,\n",
       " 50,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 70,\n",
       " 70,\n",
       " 70,\n",
       " 70,\n",
       " 70,\n",
       " 70,\n",
       " 70,\n",
       " 70,\n",
       " 70,\n",
       " 70,\n",
       " 70,\n",
       " 70,\n",
       " 70,\n",
       " 70,\n",
       " 70,\n",
       " 70,\n",
       " 70,\n",
       " 70,\n",
       " 70,\n",
       " 70,\n",
       " 80,\n",
       " 80,\n",
       " 80,\n",
       " 80,\n",
       " 80,\n",
       " 80,\n",
       " 80,\n",
       " 80,\n",
       " 80,\n",
       " 80,\n",
       " 80,\n",
       " 80,\n",
       " 80,\n",
       " 80,\n",
       " 80,\n",
       " 80,\n",
       " 80,\n",
       " 80,\n",
       " 80,\n",
       " 80,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 160,\n",
       " 160,\n",
       " 160,\n",
       " 160,\n",
       " 160,\n",
       " 160,\n",
       " 160,\n",
       " 160,\n",
       " 160,\n",
       " 160,\n",
       " 160,\n",
       " 160,\n",
       " 160,\n",
       " 160,\n",
       " 160,\n",
       " 160,\n",
       " 160,\n",
       " 160,\n",
       " 160,\n",
       " 160,\n",
       " 170,\n",
       " 170,\n",
       " 170,\n",
       " 170,\n",
       " 170,\n",
       " 170,\n",
       " 170,\n",
       " 170,\n",
       " 170,\n",
       " 170,\n",
       " 170,\n",
       " 170,\n",
       " 170,\n",
       " 170,\n",
       " 170,\n",
       " 170,\n",
       " 170,\n",
       " 170,\n",
       " 170,\n",
       " 170,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 190,\n",
       " 190,\n",
       " 190,\n",
       " 190,\n",
       " 190,\n",
       " 190,\n",
       " 190,\n",
       " 190,\n",
       " 190,\n",
       " 190,\n",
       " 190,\n",
       " 190,\n",
       " 190,\n",
       " 190,\n",
       " 190,\n",
       " 190,\n",
       " 190,\n",
       " 190,\n",
       " 190,\n",
       " 190,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TPS = []\n",
    "for i in range(10,210,10):\n",
    "    for j in range(20):\n",
    "        TPS.append(i)\n",
    "TPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cf0d1fdd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10,\n",
       " 20,\n",
       " 30,\n",
       " 40,\n",
       " 50,\n",
       " 60,\n",
       " 70,\n",
       " 80,\n",
       " 90,\n",
       " 100,\n",
       " 110,\n",
       " 120,\n",
       " 130,\n",
       " 140,\n",
       " 150,\n",
       " 160,\n",
       " 170,\n",
       " 180,\n",
       " 190,\n",
       " 200,\n",
       " 10,\n",
       " 20,\n",
       " 30,\n",
       " 40,\n",
       " 50,\n",
       " 60,\n",
       " 70,\n",
       " 80,\n",
       " 90,\n",
       " 100,\n",
       " 110,\n",
       " 120,\n",
       " 130,\n",
       " 140,\n",
       " 150,\n",
       " 160,\n",
       " 170,\n",
       " 180,\n",
       " 190,\n",
       " 200,\n",
       " 10,\n",
       " 20,\n",
       " 30,\n",
       " 40,\n",
       " 50,\n",
       " 60,\n",
       " 70,\n",
       " 80,\n",
       " 90,\n",
       " 100,\n",
       " 110,\n",
       " 120,\n",
       " 130,\n",
       " 140,\n",
       " 150,\n",
       " 160,\n",
       " 170,\n",
       " 180,\n",
       " 190,\n",
       " 200,\n",
       " 10,\n",
       " 20,\n",
       " 30,\n",
       " 40,\n",
       " 50,\n",
       " 60,\n",
       " 70,\n",
       " 80,\n",
       " 90,\n",
       " 100,\n",
       " 110,\n",
       " 120,\n",
       " 130,\n",
       " 140,\n",
       " 150,\n",
       " 160,\n",
       " 170,\n",
       " 180,\n",
       " 190,\n",
       " 200,\n",
       " 10,\n",
       " 20,\n",
       " 30,\n",
       " 40,\n",
       " 50,\n",
       " 60,\n",
       " 70,\n",
       " 80,\n",
       " 90,\n",
       " 100,\n",
       " 110,\n",
       " 120,\n",
       " 130,\n",
       " 140,\n",
       " 150,\n",
       " 160,\n",
       " 170,\n",
       " 180,\n",
       " 190,\n",
       " 200,\n",
       " 10,\n",
       " 20,\n",
       " 30,\n",
       " 40,\n",
       " 50,\n",
       " 60,\n",
       " 70,\n",
       " 80,\n",
       " 90,\n",
       " 100,\n",
       " 110,\n",
       " 120,\n",
       " 130,\n",
       " 140,\n",
       " 150,\n",
       " 160,\n",
       " 170,\n",
       " 180,\n",
       " 190,\n",
       " 200,\n",
       " 10,\n",
       " 20,\n",
       " 30,\n",
       " 40,\n",
       " 50,\n",
       " 60,\n",
       " 70,\n",
       " 80,\n",
       " 90,\n",
       " 100,\n",
       " 110,\n",
       " 120,\n",
       " 130,\n",
       " 140,\n",
       " 150,\n",
       " 160,\n",
       " 170,\n",
       " 180,\n",
       " 190,\n",
       " 200,\n",
       " 10,\n",
       " 20,\n",
       " 30,\n",
       " 40,\n",
       " 50,\n",
       " 60,\n",
       " 70,\n",
       " 80,\n",
       " 90,\n",
       " 100,\n",
       " 110,\n",
       " 120,\n",
       " 130,\n",
       " 140,\n",
       " 150,\n",
       " 160,\n",
       " 170,\n",
       " 180,\n",
       " 190,\n",
       " 200,\n",
       " 10,\n",
       " 20,\n",
       " 30,\n",
       " 40,\n",
       " 50,\n",
       " 60,\n",
       " 70,\n",
       " 80,\n",
       " 90,\n",
       " 100,\n",
       " 110,\n",
       " 120,\n",
       " 130,\n",
       " 140,\n",
       " 150,\n",
       " 160,\n",
       " 170,\n",
       " 180,\n",
       " 190,\n",
       " 200,\n",
       " 10,\n",
       " 20,\n",
       " 30,\n",
       " 40,\n",
       " 50,\n",
       " 60,\n",
       " 70,\n",
       " 80,\n",
       " 90,\n",
       " 100,\n",
       " 110,\n",
       " 120,\n",
       " 130,\n",
       " 140,\n",
       " 150,\n",
       " 160,\n",
       " 170,\n",
       " 180,\n",
       " 190,\n",
       " 200,\n",
       " 10,\n",
       " 20,\n",
       " 30,\n",
       " 40,\n",
       " 50,\n",
       " 60,\n",
       " 70,\n",
       " 80,\n",
       " 90,\n",
       " 100,\n",
       " 110,\n",
       " 120,\n",
       " 130,\n",
       " 140,\n",
       " 150,\n",
       " 160,\n",
       " 170,\n",
       " 180,\n",
       " 190,\n",
       " 200,\n",
       " 10,\n",
       " 20,\n",
       " 30,\n",
       " 40,\n",
       " 50,\n",
       " 60,\n",
       " 70,\n",
       " 80,\n",
       " 90,\n",
       " 100,\n",
       " 110,\n",
       " 120,\n",
       " 130,\n",
       " 140,\n",
       " 150,\n",
       " 160,\n",
       " 170,\n",
       " 180,\n",
       " 190,\n",
       " 200,\n",
       " 10,\n",
       " 20,\n",
       " 30,\n",
       " 40,\n",
       " 50,\n",
       " 60,\n",
       " 70,\n",
       " 80,\n",
       " 90,\n",
       " 100,\n",
       " 110,\n",
       " 120,\n",
       " 130,\n",
       " 140,\n",
       " 150,\n",
       " 160,\n",
       " 170,\n",
       " 180,\n",
       " 190,\n",
       " 200,\n",
       " 10,\n",
       " 20,\n",
       " 30,\n",
       " 40,\n",
       " 50,\n",
       " 60,\n",
       " 70,\n",
       " 80,\n",
       " 90,\n",
       " 100,\n",
       " 110,\n",
       " 120,\n",
       " 130,\n",
       " 140,\n",
       " 150,\n",
       " 160,\n",
       " 170,\n",
       " 180,\n",
       " 190,\n",
       " 200,\n",
       " 10,\n",
       " 20,\n",
       " 30,\n",
       " 40,\n",
       " 50,\n",
       " 60,\n",
       " 70,\n",
       " 80,\n",
       " 90,\n",
       " 100,\n",
       " 110,\n",
       " 120,\n",
       " 130,\n",
       " 140,\n",
       " 150,\n",
       " 160,\n",
       " 170,\n",
       " 180,\n",
       " 190,\n",
       " 200,\n",
       " 10,\n",
       " 20,\n",
       " 30,\n",
       " 40,\n",
       " 50,\n",
       " 60,\n",
       " 70,\n",
       " 80,\n",
       " 90,\n",
       " 100,\n",
       " 110,\n",
       " 120,\n",
       " 130,\n",
       " 140,\n",
       " 150,\n",
       " 160,\n",
       " 170,\n",
       " 180,\n",
       " 190,\n",
       " 200,\n",
       " 10,\n",
       " 20,\n",
       " 30,\n",
       " 40,\n",
       " 50,\n",
       " 60,\n",
       " 70,\n",
       " 80,\n",
       " 90,\n",
       " 100,\n",
       " 110,\n",
       " 120,\n",
       " 130,\n",
       " 140,\n",
       " 150,\n",
       " 160,\n",
       " 170,\n",
       " 180,\n",
       " 190,\n",
       " 200,\n",
       " 10,\n",
       " 20,\n",
       " 30,\n",
       " 40,\n",
       " 50,\n",
       " 60,\n",
       " 70,\n",
       " 80,\n",
       " 90,\n",
       " 100,\n",
       " 110,\n",
       " 120,\n",
       " 130,\n",
       " 140,\n",
       " 150,\n",
       " 160,\n",
       " 170,\n",
       " 180,\n",
       " 190,\n",
       " 200,\n",
       " 10,\n",
       " 20,\n",
       " 30,\n",
       " 40,\n",
       " 50,\n",
       " 60,\n",
       " 70,\n",
       " 80,\n",
       " 90,\n",
       " 100,\n",
       " 110,\n",
       " 120,\n",
       " 130,\n",
       " 140,\n",
       " 150,\n",
       " 160,\n",
       " 170,\n",
       " 180,\n",
       " 190,\n",
       " 200,\n",
       " 10,\n",
       " 20,\n",
       " 30,\n",
       " 40,\n",
       " 50,\n",
       " 60,\n",
       " 70,\n",
       " 80,\n",
       " 90,\n",
       " 100,\n",
       " 110,\n",
       " 120,\n",
       " 130,\n",
       " 140,\n",
       " 150,\n",
       " 160,\n",
       " 170,\n",
       " 180,\n",
       " 190,\n",
       " 200]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BS = list(range(10, 210, 10)) * 20\n",
    "BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d289723b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4915dbef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Xp': [10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  30,\n",
       "  30,\n",
       "  30,\n",
       "  30,\n",
       "  30,\n",
       "  30,\n",
       "  30,\n",
       "  30,\n",
       "  30,\n",
       "  30,\n",
       "  30,\n",
       "  30,\n",
       "  30,\n",
       "  30,\n",
       "  30,\n",
       "  30,\n",
       "  30,\n",
       "  30,\n",
       "  30,\n",
       "  30,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  50,\n",
       "  50,\n",
       "  50,\n",
       "  50,\n",
       "  50,\n",
       "  50,\n",
       "  50,\n",
       "  50,\n",
       "  50,\n",
       "  50,\n",
       "  50,\n",
       "  50,\n",
       "  50,\n",
       "  50,\n",
       "  50,\n",
       "  50,\n",
       "  50,\n",
       "  50,\n",
       "  50,\n",
       "  50,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  70,\n",
       "  70,\n",
       "  70,\n",
       "  70,\n",
       "  70,\n",
       "  70,\n",
       "  70,\n",
       "  70,\n",
       "  70,\n",
       "  70,\n",
       "  70,\n",
       "  70,\n",
       "  70,\n",
       "  70,\n",
       "  70,\n",
       "  70,\n",
       "  70,\n",
       "  70,\n",
       "  70,\n",
       "  70,\n",
       "  80,\n",
       "  80,\n",
       "  80,\n",
       "  80,\n",
       "  80,\n",
       "  80,\n",
       "  80,\n",
       "  80,\n",
       "  80,\n",
       "  80,\n",
       "  80,\n",
       "  80,\n",
       "  80,\n",
       "  80,\n",
       "  80,\n",
       "  80,\n",
       "  80,\n",
       "  80,\n",
       "  80,\n",
       "  80,\n",
       "  90,\n",
       "  90,\n",
       "  90,\n",
       "  90,\n",
       "  90,\n",
       "  90,\n",
       "  90,\n",
       "  90,\n",
       "  90,\n",
       "  90,\n",
       "  90,\n",
       "  90,\n",
       "  90,\n",
       "  90,\n",
       "  90,\n",
       "  90,\n",
       "  90,\n",
       "  90,\n",
       "  90,\n",
       "  90,\n",
       "  100,\n",
       "  100,\n",
       "  100,\n",
       "  100,\n",
       "  100,\n",
       "  100,\n",
       "  100,\n",
       "  100,\n",
       "  100,\n",
       "  100,\n",
       "  100,\n",
       "  100,\n",
       "  100,\n",
       "  100,\n",
       "  100,\n",
       "  100,\n",
       "  100,\n",
       "  100,\n",
       "  100,\n",
       "  100,\n",
       "  110,\n",
       "  110,\n",
       "  110,\n",
       "  110,\n",
       "  110,\n",
       "  110,\n",
       "  110,\n",
       "  110,\n",
       "  110,\n",
       "  110,\n",
       "  110,\n",
       "  110,\n",
       "  110,\n",
       "  110,\n",
       "  110,\n",
       "  110,\n",
       "  110,\n",
       "  110,\n",
       "  110,\n",
       "  110,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  130,\n",
       "  130,\n",
       "  130,\n",
       "  130,\n",
       "  130,\n",
       "  130,\n",
       "  130,\n",
       "  130,\n",
       "  130,\n",
       "  130,\n",
       "  130,\n",
       "  130,\n",
       "  130,\n",
       "  130,\n",
       "  130,\n",
       "  130,\n",
       "  130,\n",
       "  130,\n",
       "  130,\n",
       "  130,\n",
       "  140,\n",
       "  140,\n",
       "  140,\n",
       "  140,\n",
       "  140,\n",
       "  140,\n",
       "  140,\n",
       "  140,\n",
       "  140,\n",
       "  140,\n",
       "  140,\n",
       "  140,\n",
       "  140,\n",
       "  140,\n",
       "  140,\n",
       "  140,\n",
       "  140,\n",
       "  140,\n",
       "  140,\n",
       "  140,\n",
       "  150,\n",
       "  150,\n",
       "  150,\n",
       "  150,\n",
       "  150,\n",
       "  150,\n",
       "  150,\n",
       "  150,\n",
       "  150,\n",
       "  150,\n",
       "  150,\n",
       "  150,\n",
       "  150,\n",
       "  150,\n",
       "  150,\n",
       "  150,\n",
       "  150,\n",
       "  150,\n",
       "  150,\n",
       "  150,\n",
       "  160,\n",
       "  160,\n",
       "  160,\n",
       "  160,\n",
       "  160,\n",
       "  160,\n",
       "  160,\n",
       "  160,\n",
       "  160,\n",
       "  160,\n",
       "  160,\n",
       "  160,\n",
       "  160,\n",
       "  160,\n",
       "  160,\n",
       "  160,\n",
       "  160,\n",
       "  160,\n",
       "  160,\n",
       "  160,\n",
       "  170,\n",
       "  170,\n",
       "  170,\n",
       "  170,\n",
       "  170,\n",
       "  170,\n",
       "  170,\n",
       "  170,\n",
       "  170,\n",
       "  170,\n",
       "  170,\n",
       "  170,\n",
       "  170,\n",
       "  170,\n",
       "  170,\n",
       "  170,\n",
       "  170,\n",
       "  170,\n",
       "  170,\n",
       "  170,\n",
       "  180,\n",
       "  180,\n",
       "  180,\n",
       "  180,\n",
       "  180,\n",
       "  180,\n",
       "  180,\n",
       "  180,\n",
       "  180,\n",
       "  180,\n",
       "  180,\n",
       "  180,\n",
       "  180,\n",
       "  180,\n",
       "  180,\n",
       "  180,\n",
       "  180,\n",
       "  180,\n",
       "  180,\n",
       "  180,\n",
       "  190,\n",
       "  190,\n",
       "  190,\n",
       "  190,\n",
       "  190,\n",
       "  190,\n",
       "  190,\n",
       "  190,\n",
       "  190,\n",
       "  190,\n",
       "  190,\n",
       "  190,\n",
       "  190,\n",
       "  190,\n",
       "  190,\n",
       "  190,\n",
       "  190,\n",
       "  190,\n",
       "  190,\n",
       "  190,\n",
       "  200,\n",
       "  200,\n",
       "  200,\n",
       "  200,\n",
       "  200,\n",
       "  200,\n",
       "  200,\n",
       "  200,\n",
       "  200,\n",
       "  200,\n",
       "  200,\n",
       "  200,\n",
       "  200,\n",
       "  200,\n",
       "  200,\n",
       "  200,\n",
       "  200,\n",
       "  200,\n",
       "  200,\n",
       "  200],\n",
       " 'BS': [10,\n",
       "  20,\n",
       "  30,\n",
       "  40,\n",
       "  50,\n",
       "  60,\n",
       "  70,\n",
       "  80,\n",
       "  90,\n",
       "  100,\n",
       "  110,\n",
       "  120,\n",
       "  130,\n",
       "  140,\n",
       "  150,\n",
       "  160,\n",
       "  170,\n",
       "  180,\n",
       "  190,\n",
       "  200,\n",
       "  10,\n",
       "  20,\n",
       "  30,\n",
       "  40,\n",
       "  50,\n",
       "  60,\n",
       "  70,\n",
       "  80,\n",
       "  90,\n",
       "  100,\n",
       "  110,\n",
       "  120,\n",
       "  130,\n",
       "  140,\n",
       "  150,\n",
       "  160,\n",
       "  170,\n",
       "  180,\n",
       "  190,\n",
       "  200,\n",
       "  10,\n",
       "  20,\n",
       "  30,\n",
       "  40,\n",
       "  50,\n",
       "  60,\n",
       "  70,\n",
       "  80,\n",
       "  90,\n",
       "  100,\n",
       "  110,\n",
       "  120,\n",
       "  130,\n",
       "  140,\n",
       "  150,\n",
       "  160,\n",
       "  170,\n",
       "  180,\n",
       "  190,\n",
       "  200,\n",
       "  10,\n",
       "  20,\n",
       "  30,\n",
       "  40,\n",
       "  50,\n",
       "  60,\n",
       "  70,\n",
       "  80,\n",
       "  90,\n",
       "  100,\n",
       "  110,\n",
       "  120,\n",
       "  130,\n",
       "  140,\n",
       "  150,\n",
       "  160,\n",
       "  170,\n",
       "  180,\n",
       "  190,\n",
       "  200,\n",
       "  10,\n",
       "  20,\n",
       "  30,\n",
       "  40,\n",
       "  50,\n",
       "  60,\n",
       "  70,\n",
       "  80,\n",
       "  90,\n",
       "  100,\n",
       "  110,\n",
       "  120,\n",
       "  130,\n",
       "  140,\n",
       "  150,\n",
       "  160,\n",
       "  170,\n",
       "  180,\n",
       "  190,\n",
       "  200,\n",
       "  10,\n",
       "  20,\n",
       "  30,\n",
       "  40,\n",
       "  50,\n",
       "  60,\n",
       "  70,\n",
       "  80,\n",
       "  90,\n",
       "  100,\n",
       "  110,\n",
       "  120,\n",
       "  130,\n",
       "  140,\n",
       "  150,\n",
       "  160,\n",
       "  170,\n",
       "  180,\n",
       "  190,\n",
       "  200,\n",
       "  10,\n",
       "  20,\n",
       "  30,\n",
       "  40,\n",
       "  50,\n",
       "  60,\n",
       "  70,\n",
       "  80,\n",
       "  90,\n",
       "  100,\n",
       "  110,\n",
       "  120,\n",
       "  130,\n",
       "  140,\n",
       "  150,\n",
       "  160,\n",
       "  170,\n",
       "  180,\n",
       "  190,\n",
       "  200,\n",
       "  10,\n",
       "  20,\n",
       "  30,\n",
       "  40,\n",
       "  50,\n",
       "  60,\n",
       "  70,\n",
       "  80,\n",
       "  90,\n",
       "  100,\n",
       "  110,\n",
       "  120,\n",
       "  130,\n",
       "  140,\n",
       "  150,\n",
       "  160,\n",
       "  170,\n",
       "  180,\n",
       "  190,\n",
       "  200,\n",
       "  10,\n",
       "  20,\n",
       "  30,\n",
       "  40,\n",
       "  50,\n",
       "  60,\n",
       "  70,\n",
       "  80,\n",
       "  90,\n",
       "  100,\n",
       "  110,\n",
       "  120,\n",
       "  130,\n",
       "  140,\n",
       "  150,\n",
       "  160,\n",
       "  170,\n",
       "  180,\n",
       "  190,\n",
       "  200,\n",
       "  10,\n",
       "  20,\n",
       "  30,\n",
       "  40,\n",
       "  50,\n",
       "  60,\n",
       "  70,\n",
       "  80,\n",
       "  90,\n",
       "  100,\n",
       "  110,\n",
       "  120,\n",
       "  130,\n",
       "  140,\n",
       "  150,\n",
       "  160,\n",
       "  170,\n",
       "  180,\n",
       "  190,\n",
       "  200,\n",
       "  10,\n",
       "  20,\n",
       "  30,\n",
       "  40,\n",
       "  50,\n",
       "  60,\n",
       "  70,\n",
       "  80,\n",
       "  90,\n",
       "  100,\n",
       "  110,\n",
       "  120,\n",
       "  130,\n",
       "  140,\n",
       "  150,\n",
       "  160,\n",
       "  170,\n",
       "  180,\n",
       "  190,\n",
       "  200,\n",
       "  10,\n",
       "  20,\n",
       "  30,\n",
       "  40,\n",
       "  50,\n",
       "  60,\n",
       "  70,\n",
       "  80,\n",
       "  90,\n",
       "  100,\n",
       "  110,\n",
       "  120,\n",
       "  130,\n",
       "  140,\n",
       "  150,\n",
       "  160,\n",
       "  170,\n",
       "  180,\n",
       "  190,\n",
       "  200,\n",
       "  10,\n",
       "  20,\n",
       "  30,\n",
       "  40,\n",
       "  50,\n",
       "  60,\n",
       "  70,\n",
       "  80,\n",
       "  90,\n",
       "  100,\n",
       "  110,\n",
       "  120,\n",
       "  130,\n",
       "  140,\n",
       "  150,\n",
       "  160,\n",
       "  170,\n",
       "  180,\n",
       "  190,\n",
       "  200,\n",
       "  10,\n",
       "  20,\n",
       "  30,\n",
       "  40,\n",
       "  50,\n",
       "  60,\n",
       "  70,\n",
       "  80,\n",
       "  90,\n",
       "  100,\n",
       "  110,\n",
       "  120,\n",
       "  130,\n",
       "  140,\n",
       "  150,\n",
       "  160,\n",
       "  170,\n",
       "  180,\n",
       "  190,\n",
       "  200,\n",
       "  10,\n",
       "  20,\n",
       "  30,\n",
       "  40,\n",
       "  50,\n",
       "  60,\n",
       "  70,\n",
       "  80,\n",
       "  90,\n",
       "  100,\n",
       "  110,\n",
       "  120,\n",
       "  130,\n",
       "  140,\n",
       "  150,\n",
       "  160,\n",
       "  170,\n",
       "  180,\n",
       "  190,\n",
       "  200,\n",
       "  10,\n",
       "  20,\n",
       "  30,\n",
       "  40,\n",
       "  50,\n",
       "  60,\n",
       "  70,\n",
       "  80,\n",
       "  90,\n",
       "  100,\n",
       "  110,\n",
       "  120,\n",
       "  130,\n",
       "  140,\n",
       "  150,\n",
       "  160,\n",
       "  170,\n",
       "  180,\n",
       "  190,\n",
       "  200,\n",
       "  10,\n",
       "  20,\n",
       "  30,\n",
       "  40,\n",
       "  50,\n",
       "  60,\n",
       "  70,\n",
       "  80,\n",
       "  90,\n",
       "  100,\n",
       "  110,\n",
       "  120,\n",
       "  130,\n",
       "  140,\n",
       "  150,\n",
       "  160,\n",
       "  170,\n",
       "  180,\n",
       "  190,\n",
       "  200,\n",
       "  10,\n",
       "  20,\n",
       "  30,\n",
       "  40,\n",
       "  50,\n",
       "  60,\n",
       "  70,\n",
       "  80,\n",
       "  90,\n",
       "  100,\n",
       "  110,\n",
       "  120,\n",
       "  130,\n",
       "  140,\n",
       "  150,\n",
       "  160,\n",
       "  170,\n",
       "  180,\n",
       "  190,\n",
       "  200,\n",
       "  10,\n",
       "  20,\n",
       "  30,\n",
       "  40,\n",
       "  50,\n",
       "  60,\n",
       "  70,\n",
       "  80,\n",
       "  90,\n",
       "  100,\n",
       "  110,\n",
       "  120,\n",
       "  130,\n",
       "  140,\n",
       "  150,\n",
       "  160,\n",
       "  170,\n",
       "  180,\n",
       "  190,\n",
       "  200,\n",
       "  10,\n",
       "  20,\n",
       "  30,\n",
       "  40,\n",
       "  50,\n",
       "  60,\n",
       "  70,\n",
       "  80,\n",
       "  90,\n",
       "  100,\n",
       "  110,\n",
       "  120,\n",
       "  130,\n",
       "  140,\n",
       "  150,\n",
       "  160,\n",
       "  170,\n",
       "  180,\n",
       "  190,\n",
       "  200]}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XpBS = {\"Xp\": TPS, \"BS\": BS}\n",
    "XpBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "aa6a6f04",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Xp</th>\n",
       "      <th>BS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>200</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>200</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>200</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>200</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Xp   BS\n",
       "0     10   10\n",
       "1     10   20\n",
       "2     10   30\n",
       "3     10   40\n",
       "4     10   50\n",
       "..   ...  ...\n",
       "395  200  160\n",
       "396  200  170\n",
       "397  200  180\n",
       "398  200  190\n",
       "399  200  200\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XpBS = pd.DataFrame(XpBS)\n",
    "XpBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "262e54c7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10,  10],\n",
       "       [ 10,  20],\n",
       "       [ 10,  30],\n",
       "       [ 10,  40],\n",
       "       [ 10,  50],\n",
       "       [ 10,  60],\n",
       "       [ 10,  70],\n",
       "       [ 10,  80],\n",
       "       [ 10,  90],\n",
       "       [ 10, 100],\n",
       "       [ 10, 110],\n",
       "       [ 10, 120],\n",
       "       [ 10, 130],\n",
       "       [ 10, 140],\n",
       "       [ 10, 150],\n",
       "       [ 10, 160],\n",
       "       [ 10, 170],\n",
       "       [ 10, 180],\n",
       "       [ 10, 190],\n",
       "       [ 10, 200],\n",
       "       [ 20,  10],\n",
       "       [ 20,  20],\n",
       "       [ 20,  30],\n",
       "       [ 20,  40],\n",
       "       [ 20,  50],\n",
       "       [ 20,  60],\n",
       "       [ 20,  70],\n",
       "       [ 20,  80],\n",
       "       [ 20,  90],\n",
       "       [ 20, 100],\n",
       "       [ 20, 110],\n",
       "       [ 20, 120],\n",
       "       [ 20, 130],\n",
       "       [ 20, 140],\n",
       "       [ 20, 150],\n",
       "       [ 20, 160],\n",
       "       [ 20, 170],\n",
       "       [ 20, 180],\n",
       "       [ 20, 190],\n",
       "       [ 20, 200],\n",
       "       [ 30,  10],\n",
       "       [ 30,  20],\n",
       "       [ 30,  30],\n",
       "       [ 30,  40],\n",
       "       [ 30,  50],\n",
       "       [ 30,  60],\n",
       "       [ 30,  70],\n",
       "       [ 30,  80],\n",
       "       [ 30,  90],\n",
       "       [ 30, 100],\n",
       "       [ 30, 110],\n",
       "       [ 30, 120],\n",
       "       [ 30, 130],\n",
       "       [ 30, 140],\n",
       "       [ 30, 150],\n",
       "       [ 30, 160],\n",
       "       [ 30, 170],\n",
       "       [ 30, 180],\n",
       "       [ 30, 190],\n",
       "       [ 30, 200],\n",
       "       [ 40,  10],\n",
       "       [ 40,  20],\n",
       "       [ 40,  30],\n",
       "       [ 40,  40],\n",
       "       [ 40,  50],\n",
       "       [ 40,  60],\n",
       "       [ 40,  70],\n",
       "       [ 40,  80],\n",
       "       [ 40,  90],\n",
       "       [ 40, 100],\n",
       "       [ 40, 110],\n",
       "       [ 40, 120],\n",
       "       [ 40, 130],\n",
       "       [ 40, 140],\n",
       "       [ 40, 150],\n",
       "       [ 40, 160],\n",
       "       [ 40, 170],\n",
       "       [ 40, 180],\n",
       "       [ 40, 190],\n",
       "       [ 40, 200],\n",
       "       [ 50,  10],\n",
       "       [ 50,  20],\n",
       "       [ 50,  30],\n",
       "       [ 50,  40],\n",
       "       [ 50,  50],\n",
       "       [ 50,  60],\n",
       "       [ 50,  70],\n",
       "       [ 50,  80],\n",
       "       [ 50,  90],\n",
       "       [ 50, 100],\n",
       "       [ 50, 110],\n",
       "       [ 50, 120],\n",
       "       [ 50, 130],\n",
       "       [ 50, 140],\n",
       "       [ 50, 150],\n",
       "       [ 50, 160],\n",
       "       [ 50, 170],\n",
       "       [ 50, 180],\n",
       "       [ 50, 190],\n",
       "       [ 50, 200],\n",
       "       [ 60,  10],\n",
       "       [ 60,  20],\n",
       "       [ 60,  30],\n",
       "       [ 60,  40],\n",
       "       [ 60,  50],\n",
       "       [ 60,  60],\n",
       "       [ 60,  70],\n",
       "       [ 60,  80],\n",
       "       [ 60,  90],\n",
       "       [ 60, 100],\n",
       "       [ 60, 110],\n",
       "       [ 60, 120],\n",
       "       [ 60, 130],\n",
       "       [ 60, 140],\n",
       "       [ 60, 150],\n",
       "       [ 60, 160],\n",
       "       [ 60, 170],\n",
       "       [ 60, 180],\n",
       "       [ 60, 190],\n",
       "       [ 60, 200],\n",
       "       [ 70,  10],\n",
       "       [ 70,  20],\n",
       "       [ 70,  30],\n",
       "       [ 70,  40],\n",
       "       [ 70,  50],\n",
       "       [ 70,  60],\n",
       "       [ 70,  70],\n",
       "       [ 70,  80],\n",
       "       [ 70,  90],\n",
       "       [ 70, 100],\n",
       "       [ 70, 110],\n",
       "       [ 70, 120],\n",
       "       [ 70, 130],\n",
       "       [ 70, 140],\n",
       "       [ 70, 150],\n",
       "       [ 70, 160],\n",
       "       [ 70, 170],\n",
       "       [ 70, 180],\n",
       "       [ 70, 190],\n",
       "       [ 70, 200],\n",
       "       [ 80,  10],\n",
       "       [ 80,  20],\n",
       "       [ 80,  30],\n",
       "       [ 80,  40],\n",
       "       [ 80,  50],\n",
       "       [ 80,  60],\n",
       "       [ 80,  70],\n",
       "       [ 80,  80],\n",
       "       [ 80,  90],\n",
       "       [ 80, 100],\n",
       "       [ 80, 110],\n",
       "       [ 80, 120],\n",
       "       [ 80, 130],\n",
       "       [ 80, 140],\n",
       "       [ 80, 150],\n",
       "       [ 80, 160],\n",
       "       [ 80, 170],\n",
       "       [ 80, 180],\n",
       "       [ 80, 190],\n",
       "       [ 80, 200],\n",
       "       [ 90,  10],\n",
       "       [ 90,  20],\n",
       "       [ 90,  30],\n",
       "       [ 90,  40],\n",
       "       [ 90,  50],\n",
       "       [ 90,  60],\n",
       "       [ 90,  70],\n",
       "       [ 90,  80],\n",
       "       [ 90,  90],\n",
       "       [ 90, 100],\n",
       "       [ 90, 110],\n",
       "       [ 90, 120],\n",
       "       [ 90, 130],\n",
       "       [ 90, 140],\n",
       "       [ 90, 150],\n",
       "       [ 90, 160],\n",
       "       [ 90, 170],\n",
       "       [ 90, 180],\n",
       "       [ 90, 190],\n",
       "       [ 90, 200],\n",
       "       [100,  10],\n",
       "       [100,  20],\n",
       "       [100,  30],\n",
       "       [100,  40],\n",
       "       [100,  50],\n",
       "       [100,  60],\n",
       "       [100,  70],\n",
       "       [100,  80],\n",
       "       [100,  90],\n",
       "       [100, 100],\n",
       "       [100, 110],\n",
       "       [100, 120],\n",
       "       [100, 130],\n",
       "       [100, 140],\n",
       "       [100, 150],\n",
       "       [100, 160],\n",
       "       [100, 170],\n",
       "       [100, 180],\n",
       "       [100, 190],\n",
       "       [100, 200],\n",
       "       [110,  10],\n",
       "       [110,  20],\n",
       "       [110,  30],\n",
       "       [110,  40],\n",
       "       [110,  50],\n",
       "       [110,  60],\n",
       "       [110,  70],\n",
       "       [110,  80],\n",
       "       [110,  90],\n",
       "       [110, 100],\n",
       "       [110, 110],\n",
       "       [110, 120],\n",
       "       [110, 130],\n",
       "       [110, 140],\n",
       "       [110, 150],\n",
       "       [110, 160],\n",
       "       [110, 170],\n",
       "       [110, 180],\n",
       "       [110, 190],\n",
       "       [110, 200],\n",
       "       [120,  10],\n",
       "       [120,  20],\n",
       "       [120,  30],\n",
       "       [120,  40],\n",
       "       [120,  50],\n",
       "       [120,  60],\n",
       "       [120,  70],\n",
       "       [120,  80],\n",
       "       [120,  90],\n",
       "       [120, 100],\n",
       "       [120, 110],\n",
       "       [120, 120],\n",
       "       [120, 130],\n",
       "       [120, 140],\n",
       "       [120, 150],\n",
       "       [120, 160],\n",
       "       [120, 170],\n",
       "       [120, 180],\n",
       "       [120, 190],\n",
       "       [120, 200],\n",
       "       [130,  10],\n",
       "       [130,  20],\n",
       "       [130,  30],\n",
       "       [130,  40],\n",
       "       [130,  50],\n",
       "       [130,  60],\n",
       "       [130,  70],\n",
       "       [130,  80],\n",
       "       [130,  90],\n",
       "       [130, 100],\n",
       "       [130, 110],\n",
       "       [130, 120],\n",
       "       [130, 130],\n",
       "       [130, 140],\n",
       "       [130, 150],\n",
       "       [130, 160],\n",
       "       [130, 170],\n",
       "       [130, 180],\n",
       "       [130, 190],\n",
       "       [130, 200],\n",
       "       [140,  10],\n",
       "       [140,  20],\n",
       "       [140,  30],\n",
       "       [140,  40],\n",
       "       [140,  50],\n",
       "       [140,  60],\n",
       "       [140,  70],\n",
       "       [140,  80],\n",
       "       [140,  90],\n",
       "       [140, 100],\n",
       "       [140, 110],\n",
       "       [140, 120],\n",
       "       [140, 130],\n",
       "       [140, 140],\n",
       "       [140, 150],\n",
       "       [140, 160],\n",
       "       [140, 170],\n",
       "       [140, 180],\n",
       "       [140, 190],\n",
       "       [140, 200],\n",
       "       [150,  10],\n",
       "       [150,  20],\n",
       "       [150,  30],\n",
       "       [150,  40],\n",
       "       [150,  50],\n",
       "       [150,  60],\n",
       "       [150,  70],\n",
       "       [150,  80],\n",
       "       [150,  90],\n",
       "       [150, 100],\n",
       "       [150, 110],\n",
       "       [150, 120],\n",
       "       [150, 130],\n",
       "       [150, 140],\n",
       "       [150, 150],\n",
       "       [150, 160],\n",
       "       [150, 170],\n",
       "       [150, 180],\n",
       "       [150, 190],\n",
       "       [150, 200],\n",
       "       [160,  10],\n",
       "       [160,  20],\n",
       "       [160,  30],\n",
       "       [160,  40],\n",
       "       [160,  50],\n",
       "       [160,  60],\n",
       "       [160,  70],\n",
       "       [160,  80],\n",
       "       [160,  90],\n",
       "       [160, 100],\n",
       "       [160, 110],\n",
       "       [160, 120],\n",
       "       [160, 130],\n",
       "       [160, 140],\n",
       "       [160, 150],\n",
       "       [160, 160],\n",
       "       [160, 170],\n",
       "       [160, 180],\n",
       "       [160, 190],\n",
       "       [160, 200],\n",
       "       [170,  10],\n",
       "       [170,  20],\n",
       "       [170,  30],\n",
       "       [170,  40],\n",
       "       [170,  50],\n",
       "       [170,  60],\n",
       "       [170,  70],\n",
       "       [170,  80],\n",
       "       [170,  90],\n",
       "       [170, 100],\n",
       "       [170, 110],\n",
       "       [170, 120],\n",
       "       [170, 130],\n",
       "       [170, 140],\n",
       "       [170, 150],\n",
       "       [170, 160],\n",
       "       [170, 170],\n",
       "       [170, 180],\n",
       "       [170, 190],\n",
       "       [170, 200],\n",
       "       [180,  10],\n",
       "       [180,  20],\n",
       "       [180,  30],\n",
       "       [180,  40],\n",
       "       [180,  50],\n",
       "       [180,  60],\n",
       "       [180,  70],\n",
       "       [180,  80],\n",
       "       [180,  90],\n",
       "       [180, 100],\n",
       "       [180, 110],\n",
       "       [180, 120],\n",
       "       [180, 130],\n",
       "       [180, 140],\n",
       "       [180, 150],\n",
       "       [180, 160],\n",
       "       [180, 170],\n",
       "       [180, 180],\n",
       "       [180, 190],\n",
       "       [180, 200],\n",
       "       [190,  10],\n",
       "       [190,  20],\n",
       "       [190,  30],\n",
       "       [190,  40],\n",
       "       [190,  50],\n",
       "       [190,  60],\n",
       "       [190,  70],\n",
       "       [190,  80],\n",
       "       [190,  90],\n",
       "       [190, 100],\n",
       "       [190, 110],\n",
       "       [190, 120],\n",
       "       [190, 130],\n",
       "       [190, 140],\n",
       "       [190, 150],\n",
       "       [190, 160],\n",
       "       [190, 170],\n",
       "       [190, 180],\n",
       "       [190, 190],\n",
       "       [190, 200],\n",
       "       [200,  10],\n",
       "       [200,  20],\n",
       "       [200,  30],\n",
       "       [200,  40],\n",
       "       [200,  50],\n",
       "       [200,  60],\n",
       "       [200,  70],\n",
       "       [200,  80],\n",
       "       [200,  90],\n",
       "       [200, 100],\n",
       "       [200, 110],\n",
       "       [200, 120],\n",
       "       [200, 130],\n",
       "       [200, 140],\n",
       "       [200, 150],\n",
       "       [200, 160],\n",
       "       [200, 170],\n",
       "       [200, 180],\n",
       "       [200, 190],\n",
       "       [200, 200]], dtype=int64)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XpBS_values = XpBS.values\n",
    "XpBS_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e7ba194c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        ],\n",
       "       [0.        , 0.05263158],\n",
       "       [0.        , 0.10526316],\n",
       "       [0.        , 0.15789474],\n",
       "       [0.        , 0.21052632],\n",
       "       [0.        , 0.26315789],\n",
       "       [0.        , 0.31578947],\n",
       "       [0.        , 0.36842105],\n",
       "       [0.        , 0.42105263],\n",
       "       [0.        , 0.47368421],\n",
       "       [0.        , 0.52631579],\n",
       "       [0.        , 0.57894737],\n",
       "       [0.        , 0.63157895],\n",
       "       [0.        , 0.68421053],\n",
       "       [0.        , 0.73684211],\n",
       "       [0.        , 0.78947368],\n",
       "       [0.        , 0.84210526],\n",
       "       [0.        , 0.89473684],\n",
       "       [0.        , 0.94736842],\n",
       "       [0.        , 1.        ],\n",
       "       [0.05243838, 0.        ],\n",
       "       [0.05243838, 0.05263158],\n",
       "       [0.05243838, 0.10526316],\n",
       "       [0.05243838, 0.15789474],\n",
       "       [0.05243838, 0.21052632],\n",
       "       [0.05243838, 0.26315789],\n",
       "       [0.05243838, 0.31578947],\n",
       "       [0.05243838, 0.36842105],\n",
       "       [0.05243838, 0.42105263],\n",
       "       [0.05243838, 0.47368421],\n",
       "       [0.05243838, 0.52631579],\n",
       "       [0.05243838, 0.57894737],\n",
       "       [0.05243838, 0.63157895],\n",
       "       [0.05243838, 0.68421053],\n",
       "       [0.05243838, 0.73684211],\n",
       "       [0.05243838, 0.78947368],\n",
       "       [0.05243838, 0.84210526],\n",
       "       [0.05243838, 0.89473684],\n",
       "       [0.05243838, 0.94736842],\n",
       "       [0.05243838, 1.        ],\n",
       "       [0.10487677, 0.        ],\n",
       "       [0.10487677, 0.05263158],\n",
       "       [0.10487677, 0.10526316],\n",
       "       [0.10487677, 0.15789474],\n",
       "       [0.10487677, 0.21052632],\n",
       "       [0.10487677, 0.26315789],\n",
       "       [0.10487677, 0.31578947],\n",
       "       [0.10487677, 0.36842105],\n",
       "       [0.10487677, 0.42105263],\n",
       "       [0.10487677, 0.47368421],\n",
       "       [0.10487677, 0.52631579],\n",
       "       [0.10487677, 0.57894737],\n",
       "       [0.10487677, 0.63157895],\n",
       "       [0.10487677, 0.68421053],\n",
       "       [0.10487677, 0.73684211],\n",
       "       [0.10487677, 0.78947368],\n",
       "       [0.10487677, 0.84210526],\n",
       "       [0.10487677, 0.89473684],\n",
       "       [0.10487677, 0.94736842],\n",
       "       [0.10487677, 1.        ],\n",
       "       [0.15731515, 0.        ],\n",
       "       [0.15731515, 0.05263158],\n",
       "       [0.15731515, 0.10526316],\n",
       "       [0.15731515, 0.15789474],\n",
       "       [0.15731515, 0.21052632],\n",
       "       [0.15731515, 0.26315789],\n",
       "       [0.15731515, 0.31578947],\n",
       "       [0.15731515, 0.36842105],\n",
       "       [0.15731515, 0.42105263],\n",
       "       [0.15731515, 0.47368421],\n",
       "       [0.15731515, 0.52631579],\n",
       "       [0.15731515, 0.57894737],\n",
       "       [0.15731515, 0.63157895],\n",
       "       [0.15731515, 0.68421053],\n",
       "       [0.15731515, 0.73684211],\n",
       "       [0.15731515, 0.78947368],\n",
       "       [0.15731515, 0.84210526],\n",
       "       [0.15731515, 0.89473684],\n",
       "       [0.15731515, 0.94736842],\n",
       "       [0.15731515, 1.        ],\n",
       "       [0.20975354, 0.        ],\n",
       "       [0.20975354, 0.05263158],\n",
       "       [0.20975354, 0.10526316],\n",
       "       [0.20975354, 0.15789474],\n",
       "       [0.20975354, 0.21052632],\n",
       "       [0.20975354, 0.26315789],\n",
       "       [0.20975354, 0.31578947],\n",
       "       [0.20975354, 0.36842105],\n",
       "       [0.20975354, 0.42105263],\n",
       "       [0.20975354, 0.47368421],\n",
       "       [0.20975354, 0.52631579],\n",
       "       [0.20975354, 0.57894737],\n",
       "       [0.20975354, 0.63157895],\n",
       "       [0.20975354, 0.68421053],\n",
       "       [0.20975354, 0.73684211],\n",
       "       [0.20975354, 0.78947368],\n",
       "       [0.20975354, 0.84210526],\n",
       "       [0.20975354, 0.89473684],\n",
       "       [0.20975354, 0.94736842],\n",
       "       [0.20975354, 1.        ],\n",
       "       [0.26219192, 0.        ],\n",
       "       [0.26219192, 0.05263158],\n",
       "       [0.26219192, 0.10526316],\n",
       "       [0.26219192, 0.15789474],\n",
       "       [0.26219192, 0.21052632],\n",
       "       [0.26219192, 0.26315789],\n",
       "       [0.26219192, 0.31578947],\n",
       "       [0.26219192, 0.36842105],\n",
       "       [0.26219192, 0.42105263],\n",
       "       [0.26219192, 0.47368421],\n",
       "       [0.26219192, 0.52631579],\n",
       "       [0.26219192, 0.57894737],\n",
       "       [0.26219192, 0.63157895],\n",
       "       [0.26219192, 0.68421053],\n",
       "       [0.26219192, 0.73684211],\n",
       "       [0.26219192, 0.78947368],\n",
       "       [0.26219192, 0.84210526],\n",
       "       [0.26219192, 0.89473684],\n",
       "       [0.26219192, 0.94736842],\n",
       "       [0.26219192, 1.        ],\n",
       "       [0.31463031, 0.        ],\n",
       "       [0.31463031, 0.05263158],\n",
       "       [0.31463031, 0.10526316],\n",
       "       [0.31463031, 0.15789474],\n",
       "       [0.31463031, 0.21052632],\n",
       "       [0.31463031, 0.26315789],\n",
       "       [0.31463031, 0.31578947],\n",
       "       [0.31463031, 0.36842105],\n",
       "       [0.31463031, 0.42105263],\n",
       "       [0.31463031, 0.47368421],\n",
       "       [0.31463031, 0.52631579],\n",
       "       [0.31463031, 0.57894737],\n",
       "       [0.31463031, 0.63157895],\n",
       "       [0.31463031, 0.68421053],\n",
       "       [0.31463031, 0.73684211],\n",
       "       [0.31463031, 0.78947368],\n",
       "       [0.31463031, 0.84210526],\n",
       "       [0.31463031, 0.89473684],\n",
       "       [0.31463031, 0.94736842],\n",
       "       [0.31463031, 1.        ],\n",
       "       [0.36706869, 0.        ],\n",
       "       [0.36706869, 0.05263158],\n",
       "       [0.36706869, 0.10526316],\n",
       "       [0.36706869, 0.15789474],\n",
       "       [0.36706869, 0.21052632],\n",
       "       [0.36706869, 0.26315789],\n",
       "       [0.36706869, 0.31578947],\n",
       "       [0.36706869, 0.36842105],\n",
       "       [0.36706869, 0.42105263],\n",
       "       [0.36706869, 0.47368421],\n",
       "       [0.36706869, 0.52631579],\n",
       "       [0.36706869, 0.57894737],\n",
       "       [0.36706869, 0.63157895],\n",
       "       [0.36706869, 0.68421053],\n",
       "       [0.36706869, 0.73684211],\n",
       "       [0.36706869, 0.78947368],\n",
       "       [0.36706869, 0.84210526],\n",
       "       [0.36706869, 0.89473684],\n",
       "       [0.36706869, 0.94736842],\n",
       "       [0.36706869, 1.        ],\n",
       "       [0.41950708, 0.        ],\n",
       "       [0.41950708, 0.05263158],\n",
       "       [0.41950708, 0.10526316],\n",
       "       [0.41950708, 0.15789474],\n",
       "       [0.41950708, 0.21052632],\n",
       "       [0.41950708, 0.26315789],\n",
       "       [0.41950708, 0.31578947],\n",
       "       [0.41950708, 0.36842105],\n",
       "       [0.41950708, 0.42105263],\n",
       "       [0.41950708, 0.47368421],\n",
       "       [0.41950708, 0.52631579],\n",
       "       [0.41950708, 0.57894737],\n",
       "       [0.41950708, 0.63157895],\n",
       "       [0.41950708, 0.68421053],\n",
       "       [0.41950708, 0.73684211],\n",
       "       [0.41950708, 0.78947368],\n",
       "       [0.41950708, 0.84210526],\n",
       "       [0.41950708, 0.89473684],\n",
       "       [0.41950708, 0.94736842],\n",
       "       [0.41950708, 1.        ],\n",
       "       [0.47194546, 0.        ],\n",
       "       [0.47194546, 0.05263158],\n",
       "       [0.47194546, 0.10526316],\n",
       "       [0.47194546, 0.15789474],\n",
       "       [0.47194546, 0.21052632],\n",
       "       [0.47194546, 0.26315789],\n",
       "       [0.47194546, 0.31578947],\n",
       "       [0.47194546, 0.36842105],\n",
       "       [0.47194546, 0.42105263],\n",
       "       [0.47194546, 0.47368421],\n",
       "       [0.47194546, 0.52631579],\n",
       "       [0.47194546, 0.57894737],\n",
       "       [0.47194546, 0.63157895],\n",
       "       [0.47194546, 0.68421053],\n",
       "       [0.47194546, 0.73684211],\n",
       "       [0.47194546, 0.78947368],\n",
       "       [0.47194546, 0.84210526],\n",
       "       [0.47194546, 0.89473684],\n",
       "       [0.47194546, 0.94736842],\n",
       "       [0.47194546, 1.        ],\n",
       "       [0.52438385, 0.        ],\n",
       "       [0.52438385, 0.05263158],\n",
       "       [0.52438385, 0.10526316],\n",
       "       [0.52438385, 0.15789474],\n",
       "       [0.52438385, 0.21052632],\n",
       "       [0.52438385, 0.26315789],\n",
       "       [0.52438385, 0.31578947],\n",
       "       [0.52438385, 0.36842105],\n",
       "       [0.52438385, 0.42105263],\n",
       "       [0.52438385, 0.47368421],\n",
       "       [0.52438385, 0.52631579],\n",
       "       [0.52438385, 0.57894737],\n",
       "       [0.52438385, 0.63157895],\n",
       "       [0.52438385, 0.68421053],\n",
       "       [0.52438385, 0.73684211],\n",
       "       [0.52438385, 0.78947368],\n",
       "       [0.52438385, 0.84210526],\n",
       "       [0.52438385, 0.89473684],\n",
       "       [0.52438385, 0.94736842],\n",
       "       [0.52438385, 1.        ],\n",
       "       [0.57682223, 0.        ],\n",
       "       [0.57682223, 0.05263158],\n",
       "       [0.57682223, 0.10526316],\n",
       "       [0.57682223, 0.15789474],\n",
       "       [0.57682223, 0.21052632],\n",
       "       [0.57682223, 0.26315789],\n",
       "       [0.57682223, 0.31578947],\n",
       "       [0.57682223, 0.36842105],\n",
       "       [0.57682223, 0.42105263],\n",
       "       [0.57682223, 0.47368421],\n",
       "       [0.57682223, 0.52631579],\n",
       "       [0.57682223, 0.57894737],\n",
       "       [0.57682223, 0.63157895],\n",
       "       [0.57682223, 0.68421053],\n",
       "       [0.57682223, 0.73684211],\n",
       "       [0.57682223, 0.78947368],\n",
       "       [0.57682223, 0.84210526],\n",
       "       [0.57682223, 0.89473684],\n",
       "       [0.57682223, 0.94736842],\n",
       "       [0.57682223, 1.        ],\n",
       "       [0.62926062, 0.        ],\n",
       "       [0.62926062, 0.05263158],\n",
       "       [0.62926062, 0.10526316],\n",
       "       [0.62926062, 0.15789474],\n",
       "       [0.62926062, 0.21052632],\n",
       "       [0.62926062, 0.26315789],\n",
       "       [0.62926062, 0.31578947],\n",
       "       [0.62926062, 0.36842105],\n",
       "       [0.62926062, 0.42105263],\n",
       "       [0.62926062, 0.47368421],\n",
       "       [0.62926062, 0.52631579],\n",
       "       [0.62926062, 0.57894737],\n",
       "       [0.62926062, 0.63157895],\n",
       "       [0.62926062, 0.68421053],\n",
       "       [0.62926062, 0.73684211],\n",
       "       [0.62926062, 0.78947368],\n",
       "       [0.62926062, 0.84210526],\n",
       "       [0.62926062, 0.89473684],\n",
       "       [0.62926062, 0.94736842],\n",
       "       [0.62926062, 1.        ],\n",
       "       [0.681699  , 0.        ],\n",
       "       [0.681699  , 0.05263158],\n",
       "       [0.681699  , 0.10526316],\n",
       "       [0.681699  , 0.15789474],\n",
       "       [0.681699  , 0.21052632],\n",
       "       [0.681699  , 0.26315789],\n",
       "       [0.681699  , 0.31578947],\n",
       "       [0.681699  , 0.36842105],\n",
       "       [0.681699  , 0.42105263],\n",
       "       [0.681699  , 0.47368421],\n",
       "       [0.681699  , 0.52631579],\n",
       "       [0.681699  , 0.57894737],\n",
       "       [0.681699  , 0.63157895],\n",
       "       [0.681699  , 0.68421053],\n",
       "       [0.681699  , 0.73684211],\n",
       "       [0.681699  , 0.78947368],\n",
       "       [0.681699  , 0.84210526],\n",
       "       [0.681699  , 0.89473684],\n",
       "       [0.681699  , 0.94736842],\n",
       "       [0.681699  , 1.        ],\n",
       "       [0.73413739, 0.        ],\n",
       "       [0.73413739, 0.05263158],\n",
       "       [0.73413739, 0.10526316],\n",
       "       [0.73413739, 0.15789474],\n",
       "       [0.73413739, 0.21052632],\n",
       "       [0.73413739, 0.26315789],\n",
       "       [0.73413739, 0.31578947],\n",
       "       [0.73413739, 0.36842105],\n",
       "       [0.73413739, 0.42105263],\n",
       "       [0.73413739, 0.47368421],\n",
       "       [0.73413739, 0.52631579],\n",
       "       [0.73413739, 0.57894737],\n",
       "       [0.73413739, 0.63157895],\n",
       "       [0.73413739, 0.68421053],\n",
       "       [0.73413739, 0.73684211],\n",
       "       [0.73413739, 0.78947368],\n",
       "       [0.73413739, 0.84210526],\n",
       "       [0.73413739, 0.89473684],\n",
       "       [0.73413739, 0.94736842],\n",
       "       [0.73413739, 1.        ],\n",
       "       [0.78657577, 0.        ],\n",
       "       [0.78657577, 0.05263158],\n",
       "       [0.78657577, 0.10526316],\n",
       "       [0.78657577, 0.15789474],\n",
       "       [0.78657577, 0.21052632],\n",
       "       [0.78657577, 0.26315789],\n",
       "       [0.78657577, 0.31578947],\n",
       "       [0.78657577, 0.36842105],\n",
       "       [0.78657577, 0.42105263],\n",
       "       [0.78657577, 0.47368421],\n",
       "       [0.78657577, 0.52631579],\n",
       "       [0.78657577, 0.57894737],\n",
       "       [0.78657577, 0.63157895],\n",
       "       [0.78657577, 0.68421053],\n",
       "       [0.78657577, 0.73684211],\n",
       "       [0.78657577, 0.78947368],\n",
       "       [0.78657577, 0.84210526],\n",
       "       [0.78657577, 0.89473684],\n",
       "       [0.78657577, 0.94736842],\n",
       "       [0.78657577, 1.        ],\n",
       "       [0.83901416, 0.        ],\n",
       "       [0.83901416, 0.05263158],\n",
       "       [0.83901416, 0.10526316],\n",
       "       [0.83901416, 0.15789474],\n",
       "       [0.83901416, 0.21052632],\n",
       "       [0.83901416, 0.26315789],\n",
       "       [0.83901416, 0.31578947],\n",
       "       [0.83901416, 0.36842105],\n",
       "       [0.83901416, 0.42105263],\n",
       "       [0.83901416, 0.47368421],\n",
       "       [0.83901416, 0.52631579],\n",
       "       [0.83901416, 0.57894737],\n",
       "       [0.83901416, 0.63157895],\n",
       "       [0.83901416, 0.68421053],\n",
       "       [0.83901416, 0.73684211],\n",
       "       [0.83901416, 0.78947368],\n",
       "       [0.83901416, 0.84210526],\n",
       "       [0.83901416, 0.89473684],\n",
       "       [0.83901416, 0.94736842],\n",
       "       [0.83901416, 1.        ],\n",
       "       [0.89145254, 0.        ],\n",
       "       [0.89145254, 0.05263158],\n",
       "       [0.89145254, 0.10526316],\n",
       "       [0.89145254, 0.15789474],\n",
       "       [0.89145254, 0.21052632],\n",
       "       [0.89145254, 0.26315789],\n",
       "       [0.89145254, 0.31578947],\n",
       "       [0.89145254, 0.36842105],\n",
       "       [0.89145254, 0.42105263],\n",
       "       [0.89145254, 0.47368421],\n",
       "       [0.89145254, 0.52631579],\n",
       "       [0.89145254, 0.57894737],\n",
       "       [0.89145254, 0.63157895],\n",
       "       [0.89145254, 0.68421053],\n",
       "       [0.89145254, 0.73684211],\n",
       "       [0.89145254, 0.78947368],\n",
       "       [0.89145254, 0.84210526],\n",
       "       [0.89145254, 0.89473684],\n",
       "       [0.89145254, 0.94736842],\n",
       "       [0.89145254, 1.        ],\n",
       "       [0.94389093, 0.        ],\n",
       "       [0.94389093, 0.05263158],\n",
       "       [0.94389093, 0.10526316],\n",
       "       [0.94389093, 0.15789474],\n",
       "       [0.94389093, 0.21052632],\n",
       "       [0.94389093, 0.26315789],\n",
       "       [0.94389093, 0.31578947],\n",
       "       [0.94389093, 0.36842105],\n",
       "       [0.94389093, 0.42105263],\n",
       "       [0.94389093, 0.47368421],\n",
       "       [0.94389093, 0.52631579],\n",
       "       [0.94389093, 0.57894737],\n",
       "       [0.94389093, 0.63157895],\n",
       "       [0.94389093, 0.68421053],\n",
       "       [0.94389093, 0.73684211],\n",
       "       [0.94389093, 0.78947368],\n",
       "       [0.94389093, 0.84210526],\n",
       "       [0.94389093, 0.89473684],\n",
       "       [0.94389093, 0.94736842],\n",
       "       [0.94389093, 1.        ],\n",
       "       [0.99632931, 0.        ],\n",
       "       [0.99632931, 0.05263158],\n",
       "       [0.99632931, 0.10526316],\n",
       "       [0.99632931, 0.15789474],\n",
       "       [0.99632931, 0.21052632],\n",
       "       [0.99632931, 0.26315789],\n",
       "       [0.99632931, 0.31578947],\n",
       "       [0.99632931, 0.36842105],\n",
       "       [0.99632931, 0.42105263],\n",
       "       [0.99632931, 0.47368421],\n",
       "       [0.99632931, 0.52631579],\n",
       "       [0.99632931, 0.57894737],\n",
       "       [0.99632931, 0.63157895],\n",
       "       [0.99632931, 0.68421053],\n",
       "       [0.99632931, 0.73684211],\n",
       "       [0.99632931, 0.78947368],\n",
       "       [0.99632931, 0.84210526],\n",
       "       [0.99632931, 0.89473684],\n",
       "       [0.99632931, 0.94736842],\n",
       "       [0.99632931, 1.        ]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalization\n",
    "XpBS_minmax = min_max_scaler1.transform(XpBS_values)\n",
    "XpBS_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "938a9638",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "XpBS_tensor = torch.from_numpy(XpBS_minmax).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9675ac94",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    latency_pred = model(XpBS_tensor)\n",
    "y = pd.concat([pd.Series(XpBS_values[:, 0].reshape(-1), name='send rates'), pd.Series(XpBS_values[:, 1].reshape(-1), name='block size'), \n",
    "               pd.Series(latency_pred.numpy().reshape(-1), name='latency_pred')], axis=1)\n",
    "y.index = XpBS.index\n",
    "y.to_csv('./latency_pred_related1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "988c69eb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>send rates</th>\n",
       "      <th>block size</th>\n",
       "      <th>latency_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.313954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.820229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>1.092091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>1.255364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>1.405114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>200</td>\n",
       "      <td>160</td>\n",
       "      <td>1.715595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>200</td>\n",
       "      <td>170</td>\n",
       "      <td>1.646274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>200</td>\n",
       "      <td>180</td>\n",
       "      <td>1.592673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>200</td>\n",
       "      <td>190</td>\n",
       "      <td>1.570900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>1.548800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     send rates  block size  latency_pred\n",
       "0            10          10      0.313954\n",
       "1            10          20      0.820229\n",
       "2            10          30      1.092091\n",
       "3            10          40      1.255364\n",
       "4            10          50      1.405114\n",
       "..          ...         ...           ...\n",
       "395         200         160      1.715595\n",
       "396         200         170      1.646274\n",
       "397         200         180      1.592673\n",
       "398         200         190      1.570900\n",
       "399         200         200      1.548800\n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a84f43",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## MLP2 to predict throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ccacfde7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        ],\n",
       "       [0.        , 0.05263158],\n",
       "       [0.        , 0.10526316],\n",
       "       [0.        , 0.15789474],\n",
       "       [0.        , 0.21052632],\n",
       "       [0.        , 0.26315789],\n",
       "       [0.        , 0.31578947],\n",
       "       [0.        , 0.36842105],\n",
       "       [0.        , 0.42105263],\n",
       "       [0.        , 0.47368421],\n",
       "       [0.        , 0.52631579],\n",
       "       [0.        , 0.57894737],\n",
       "       [0.        , 0.63157895],\n",
       "       [0.        , 0.68421053],\n",
       "       [0.        , 0.73684211],\n",
       "       [0.        , 0.78947368],\n",
       "       [0.        , 0.84210526],\n",
       "       [0.        , 0.89473684],\n",
       "       [0.        , 0.94736842],\n",
       "       [0.        , 1.        ],\n",
       "       [0.05243838, 0.        ],\n",
       "       [0.05243838, 0.05263158],\n",
       "       [0.05243838, 0.10526316],\n",
       "       [0.05243838, 0.15789474],\n",
       "       [0.05243838, 0.21052632],\n",
       "       [0.05243838, 0.26315789],\n",
       "       [0.05243838, 0.31578947],\n",
       "       [0.05243838, 0.36842105],\n",
       "       [0.05243838, 0.42105263],\n",
       "       [0.05243838, 0.47368421],\n",
       "       [0.05243838, 0.52631579],\n",
       "       [0.05243838, 0.57894737],\n",
       "       [0.05243838, 0.63157895],\n",
       "       [0.05243838, 0.68421053],\n",
       "       [0.05243838, 0.73684211],\n",
       "       [0.05243838, 0.78947368],\n",
       "       [0.05243838, 0.84210526],\n",
       "       [0.05243838, 0.89473684],\n",
       "       [0.05243838, 0.94736842],\n",
       "       [0.05243838, 1.        ],\n",
       "       [0.10487677, 0.        ],\n",
       "       [0.10487677, 0.05263158],\n",
       "       [0.10487677, 0.10526316],\n",
       "       [0.10487677, 0.15789474],\n",
       "       [0.10487677, 0.21052632],\n",
       "       [0.10487677, 0.26315789],\n",
       "       [0.10487677, 0.31578947],\n",
       "       [0.10487677, 0.36842105],\n",
       "       [0.10487677, 0.42105263],\n",
       "       [0.10487677, 0.47368421],\n",
       "       [0.10487677, 0.52631579],\n",
       "       [0.10487677, 0.57894737],\n",
       "       [0.10487677, 0.63157895],\n",
       "       [0.10487677, 0.68421053],\n",
       "       [0.10487677, 0.73684211],\n",
       "       [0.10487677, 0.78947368],\n",
       "       [0.10487677, 0.84210526],\n",
       "       [0.10487677, 0.89473684],\n",
       "       [0.10487677, 0.94736842],\n",
       "       [0.10487677, 1.        ],\n",
       "       [0.15731515, 0.        ],\n",
       "       [0.15731515, 0.05263158],\n",
       "       [0.15731515, 0.10526316],\n",
       "       [0.15731515, 0.15789474],\n",
       "       [0.15731515, 0.21052632],\n",
       "       [0.15731515, 0.26315789],\n",
       "       [0.15731515, 0.31578947],\n",
       "       [0.15731515, 0.36842105],\n",
       "       [0.15731515, 0.42105263],\n",
       "       [0.15731515, 0.47368421],\n",
       "       [0.15731515, 0.52631579],\n",
       "       [0.15731515, 0.57894737],\n",
       "       [0.15731515, 0.63157895],\n",
       "       [0.15731515, 0.68421053],\n",
       "       [0.15731515, 0.73684211],\n",
       "       [0.15731515, 0.78947368],\n",
       "       [0.15731515, 0.84210526],\n",
       "       [0.15731515, 0.89473684],\n",
       "       [0.15731515, 0.94736842],\n",
       "       [0.15731515, 1.        ],\n",
       "       [0.20975354, 0.        ],\n",
       "       [0.20975354, 0.05263158],\n",
       "       [0.20975354, 0.10526316],\n",
       "       [0.20975354, 0.15789474],\n",
       "       [0.20975354, 0.21052632],\n",
       "       [0.20975354, 0.26315789],\n",
       "       [0.20975354, 0.31578947],\n",
       "       [0.20975354, 0.36842105],\n",
       "       [0.20975354, 0.42105263],\n",
       "       [0.20975354, 0.47368421],\n",
       "       [0.20975354, 0.52631579],\n",
       "       [0.20975354, 0.57894737],\n",
       "       [0.20975354, 0.63157895],\n",
       "       [0.20975354, 0.68421053],\n",
       "       [0.20975354, 0.73684211],\n",
       "       [0.20975354, 0.78947368],\n",
       "       [0.20975354, 0.84210526],\n",
       "       [0.20975354, 0.89473684],\n",
       "       [0.20975354, 0.94736842],\n",
       "       [0.20975354, 1.        ],\n",
       "       [0.26219192, 0.        ],\n",
       "       [0.26219192, 0.05263158],\n",
       "       [0.26219192, 0.10526316],\n",
       "       [0.26219192, 0.15789474],\n",
       "       [0.26219192, 0.21052632],\n",
       "       [0.26219192, 0.26315789],\n",
       "       [0.26219192, 0.31578947],\n",
       "       [0.26219192, 0.36842105],\n",
       "       [0.26219192, 0.42105263],\n",
       "       [0.26219192, 0.47368421],\n",
       "       [0.26219192, 0.52631579],\n",
       "       [0.26219192, 0.57894737],\n",
       "       [0.26219192, 0.63157895],\n",
       "       [0.26219192, 0.68421053],\n",
       "       [0.26219192, 0.73684211],\n",
       "       [0.26219192, 0.78947368],\n",
       "       [0.26219192, 0.84210526],\n",
       "       [0.26219192, 0.89473684],\n",
       "       [0.26219192, 0.94736842],\n",
       "       [0.26219192, 1.        ],\n",
       "       [0.31463031, 0.        ],\n",
       "       [0.31463031, 0.05263158],\n",
       "       [0.31463031, 0.10526316],\n",
       "       [0.31463031, 0.15789474],\n",
       "       [0.31463031, 0.21052632],\n",
       "       [0.31463031, 0.26315789],\n",
       "       [0.31463031, 0.31578947],\n",
       "       [0.31463031, 0.36842105],\n",
       "       [0.31463031, 0.42105263],\n",
       "       [0.31463031, 0.47368421],\n",
       "       [0.31463031, 0.52631579],\n",
       "       [0.31463031, 0.57894737],\n",
       "       [0.31463031, 0.63157895],\n",
       "       [0.31463031, 0.68421053],\n",
       "       [0.31463031, 0.73684211],\n",
       "       [0.31463031, 0.78947368],\n",
       "       [0.31463031, 0.84210526],\n",
       "       [0.31463031, 0.89473684],\n",
       "       [0.31463031, 0.94736842],\n",
       "       [0.31463031, 1.        ],\n",
       "       [0.36706869, 0.        ],\n",
       "       [0.36706869, 0.05263158],\n",
       "       [0.36706869, 0.10526316],\n",
       "       [0.36706869, 0.15789474],\n",
       "       [0.36706869, 0.21052632],\n",
       "       [0.36706869, 0.26315789],\n",
       "       [0.36706869, 0.31578947],\n",
       "       [0.36706869, 0.36842105],\n",
       "       [0.36706869, 0.42105263],\n",
       "       [0.36706869, 0.47368421],\n",
       "       [0.36706869, 0.52631579],\n",
       "       [0.36706869, 0.57894737],\n",
       "       [0.36706869, 0.63157895],\n",
       "       [0.36706869, 0.68421053],\n",
       "       [0.36706869, 0.73684211],\n",
       "       [0.36706869, 0.78947368],\n",
       "       [0.36706869, 0.84210526],\n",
       "       [0.36706869, 0.89473684],\n",
       "       [0.36706869, 0.94736842],\n",
       "       [0.36706869, 1.        ],\n",
       "       [0.41950708, 0.        ],\n",
       "       [0.41950708, 0.05263158],\n",
       "       [0.41950708, 0.10526316],\n",
       "       [0.41950708, 0.15789474],\n",
       "       [0.41950708, 0.21052632],\n",
       "       [0.41950708, 0.26315789],\n",
       "       [0.41950708, 0.31578947],\n",
       "       [0.41950708, 0.36842105],\n",
       "       [0.41950708, 0.42105263],\n",
       "       [0.41950708, 0.47368421],\n",
       "       [0.41950708, 0.52631579],\n",
       "       [0.41950708, 0.57894737],\n",
       "       [0.41950708, 0.63157895],\n",
       "       [0.41950708, 0.68421053],\n",
       "       [0.41950708, 0.73684211],\n",
       "       [0.41950708, 0.78947368],\n",
       "       [0.41950708, 0.84210526],\n",
       "       [0.41950708, 0.89473684],\n",
       "       [0.41950708, 0.94736842],\n",
       "       [0.41950708, 1.        ],\n",
       "       [0.47194546, 0.        ],\n",
       "       [0.47194546, 0.05263158],\n",
       "       [0.47194546, 0.10526316],\n",
       "       [0.47194546, 0.15789474],\n",
       "       [0.47194546, 0.21052632],\n",
       "       [0.47194546, 0.26315789],\n",
       "       [0.47194546, 0.31578947],\n",
       "       [0.47194546, 0.36842105],\n",
       "       [0.47194546, 0.42105263],\n",
       "       [0.47194546, 0.47368421],\n",
       "       [0.47194546, 0.52631579],\n",
       "       [0.47194546, 0.57894737],\n",
       "       [0.47194546, 0.63157895],\n",
       "       [0.47194546, 0.68421053],\n",
       "       [0.47194546, 0.73684211],\n",
       "       [0.47194546, 0.78947368],\n",
       "       [0.47194546, 0.84210526],\n",
       "       [0.47194546, 0.89473684],\n",
       "       [0.47194546, 0.94736842],\n",
       "       [0.47194546, 1.        ],\n",
       "       [0.52438385, 0.        ],\n",
       "       [0.52438385, 0.05263158],\n",
       "       [0.52438385, 0.10526316],\n",
       "       [0.52438385, 0.15789474],\n",
       "       [0.52438385, 0.21052632],\n",
       "       [0.52438385, 0.26315789],\n",
       "       [0.52438385, 0.31578947],\n",
       "       [0.52438385, 0.36842105],\n",
       "       [0.52438385, 0.42105263],\n",
       "       [0.52438385, 0.47368421],\n",
       "       [0.52438385, 0.52631579],\n",
       "       [0.52438385, 0.57894737],\n",
       "       [0.52438385, 0.63157895],\n",
       "       [0.52438385, 0.68421053],\n",
       "       [0.52438385, 0.73684211],\n",
       "       [0.52438385, 0.78947368],\n",
       "       [0.52438385, 0.84210526],\n",
       "       [0.52438385, 0.89473684],\n",
       "       [0.52438385, 0.94736842],\n",
       "       [0.52438385, 1.        ],\n",
       "       [0.57682223, 0.        ],\n",
       "       [0.57682223, 0.05263158],\n",
       "       [0.57682223, 0.10526316],\n",
       "       [0.57682223, 0.15789474],\n",
       "       [0.57682223, 0.21052632],\n",
       "       [0.57682223, 0.26315789],\n",
       "       [0.57682223, 0.31578947],\n",
       "       [0.57682223, 0.36842105],\n",
       "       [0.57682223, 0.42105263],\n",
       "       [0.57682223, 0.47368421],\n",
       "       [0.57682223, 0.52631579],\n",
       "       [0.57682223, 0.57894737],\n",
       "       [0.57682223, 0.63157895],\n",
       "       [0.57682223, 0.68421053],\n",
       "       [0.57682223, 0.73684211],\n",
       "       [0.57682223, 0.78947368],\n",
       "       [0.57682223, 0.84210526],\n",
       "       [0.57682223, 0.89473684],\n",
       "       [0.57682223, 0.94736842],\n",
       "       [0.57682223, 1.        ],\n",
       "       [0.62926062, 0.        ],\n",
       "       [0.62926062, 0.05263158],\n",
       "       [0.62926062, 0.10526316],\n",
       "       [0.62926062, 0.15789474],\n",
       "       [0.62926062, 0.21052632],\n",
       "       [0.62926062, 0.26315789],\n",
       "       [0.62926062, 0.31578947],\n",
       "       [0.62926062, 0.36842105],\n",
       "       [0.62926062, 0.42105263],\n",
       "       [0.62926062, 0.47368421],\n",
       "       [0.62926062, 0.52631579],\n",
       "       [0.62926062, 0.57894737],\n",
       "       [0.62926062, 0.63157895],\n",
       "       [0.62926062, 0.68421053],\n",
       "       [0.62926062, 0.73684211],\n",
       "       [0.62926062, 0.78947368],\n",
       "       [0.62926062, 0.84210526],\n",
       "       [0.62926062, 0.89473684],\n",
       "       [0.62926062, 0.94736842],\n",
       "       [0.62926062, 1.        ],\n",
       "       [0.681699  , 0.        ],\n",
       "       [0.681699  , 0.05263158],\n",
       "       [0.681699  , 0.10526316],\n",
       "       [0.681699  , 0.15789474],\n",
       "       [0.681699  , 0.21052632],\n",
       "       [0.681699  , 0.26315789],\n",
       "       [0.681699  , 0.31578947],\n",
       "       [0.681699  , 0.36842105],\n",
       "       [0.681699  , 0.42105263],\n",
       "       [0.681699  , 0.47368421],\n",
       "       [0.681699  , 0.52631579],\n",
       "       [0.681699  , 0.57894737],\n",
       "       [0.681699  , 0.63157895],\n",
       "       [0.681699  , 0.68421053],\n",
       "       [0.681699  , 0.73684211],\n",
       "       [0.681699  , 0.78947368],\n",
       "       [0.681699  , 0.84210526],\n",
       "       [0.681699  , 0.89473684],\n",
       "       [0.681699  , 0.94736842],\n",
       "       [0.681699  , 1.        ],\n",
       "       [0.73413739, 0.        ],\n",
       "       [0.73413739, 0.05263158],\n",
       "       [0.73413739, 0.10526316],\n",
       "       [0.73413739, 0.15789474],\n",
       "       [0.73413739, 0.21052632],\n",
       "       [0.73413739, 0.26315789],\n",
       "       [0.73413739, 0.31578947],\n",
       "       [0.73413739, 0.36842105],\n",
       "       [0.73413739, 0.42105263],\n",
       "       [0.73413739, 0.47368421],\n",
       "       [0.73413739, 0.52631579],\n",
       "       [0.73413739, 0.57894737],\n",
       "       [0.73413739, 0.63157895],\n",
       "       [0.73413739, 0.68421053],\n",
       "       [0.73413739, 0.73684211],\n",
       "       [0.73413739, 0.78947368],\n",
       "       [0.73413739, 0.84210526],\n",
       "       [0.73413739, 0.89473684],\n",
       "       [0.73413739, 0.94736842],\n",
       "       [0.73413739, 1.        ],\n",
       "       [0.78657577, 0.        ],\n",
       "       [0.78657577, 0.05263158],\n",
       "       [0.78657577, 0.10526316],\n",
       "       [0.78657577, 0.15789474],\n",
       "       [0.78657577, 0.21052632],\n",
       "       [0.78657577, 0.26315789],\n",
       "       [0.78657577, 0.31578947],\n",
       "       [0.78657577, 0.36842105],\n",
       "       [0.78657577, 0.42105263],\n",
       "       [0.78657577, 0.47368421],\n",
       "       [0.78657577, 0.52631579],\n",
       "       [0.78657577, 0.57894737],\n",
       "       [0.78657577, 0.63157895],\n",
       "       [0.78657577, 0.68421053],\n",
       "       [0.78657577, 0.73684211],\n",
       "       [0.78657577, 0.78947368],\n",
       "       [0.78657577, 0.84210526],\n",
       "       [0.78657577, 0.89473684],\n",
       "       [0.78657577, 0.94736842],\n",
       "       [0.78657577, 1.        ],\n",
       "       [0.83901416, 0.        ],\n",
       "       [0.83901416, 0.05263158],\n",
       "       [0.83901416, 0.10526316],\n",
       "       [0.83901416, 0.15789474],\n",
       "       [0.83901416, 0.21052632],\n",
       "       [0.83901416, 0.26315789],\n",
       "       [0.83901416, 0.31578947],\n",
       "       [0.83901416, 0.36842105],\n",
       "       [0.83901416, 0.42105263],\n",
       "       [0.83901416, 0.47368421],\n",
       "       [0.83901416, 0.52631579],\n",
       "       [0.83901416, 0.57894737],\n",
       "       [0.83901416, 0.63157895],\n",
       "       [0.83901416, 0.68421053],\n",
       "       [0.83901416, 0.73684211],\n",
       "       [0.83901416, 0.78947368],\n",
       "       [0.83901416, 0.84210526],\n",
       "       [0.83901416, 0.89473684],\n",
       "       [0.83901416, 0.94736842],\n",
       "       [0.83901416, 1.        ],\n",
       "       [0.89145254, 0.        ],\n",
       "       [0.89145254, 0.05263158],\n",
       "       [0.89145254, 0.10526316],\n",
       "       [0.89145254, 0.15789474],\n",
       "       [0.89145254, 0.21052632],\n",
       "       [0.89145254, 0.26315789],\n",
       "       [0.89145254, 0.31578947],\n",
       "       [0.89145254, 0.36842105],\n",
       "       [0.89145254, 0.42105263],\n",
       "       [0.89145254, 0.47368421],\n",
       "       [0.89145254, 0.52631579],\n",
       "       [0.89145254, 0.57894737],\n",
       "       [0.89145254, 0.63157895],\n",
       "       [0.89145254, 0.68421053],\n",
       "       [0.89145254, 0.73684211],\n",
       "       [0.89145254, 0.78947368],\n",
       "       [0.89145254, 0.84210526],\n",
       "       [0.89145254, 0.89473684],\n",
       "       [0.89145254, 0.94736842],\n",
       "       [0.89145254, 1.        ],\n",
       "       [0.94389093, 0.        ],\n",
       "       [0.94389093, 0.05263158],\n",
       "       [0.94389093, 0.10526316],\n",
       "       [0.94389093, 0.15789474],\n",
       "       [0.94389093, 0.21052632],\n",
       "       [0.94389093, 0.26315789],\n",
       "       [0.94389093, 0.31578947],\n",
       "       [0.94389093, 0.36842105],\n",
       "       [0.94389093, 0.42105263],\n",
       "       [0.94389093, 0.47368421],\n",
       "       [0.94389093, 0.52631579],\n",
       "       [0.94389093, 0.57894737],\n",
       "       [0.94389093, 0.63157895],\n",
       "       [0.94389093, 0.68421053],\n",
       "       [0.94389093, 0.73684211],\n",
       "       [0.94389093, 0.78947368],\n",
       "       [0.94389093, 0.84210526],\n",
       "       [0.94389093, 0.89473684],\n",
       "       [0.94389093, 0.94736842],\n",
       "       [0.94389093, 1.        ],\n",
       "       [0.99632931, 0.        ],\n",
       "       [0.99632931, 0.05263158],\n",
       "       [0.99632931, 0.10526316],\n",
       "       [0.99632931, 0.15789474],\n",
       "       [0.99632931, 0.21052632],\n",
       "       [0.99632931, 0.26315789],\n",
       "       [0.99632931, 0.31578947],\n",
       "       [0.99632931, 0.36842105],\n",
       "       [0.99632931, 0.42105263],\n",
       "       [0.99632931, 0.47368421],\n",
       "       [0.99632931, 0.52631579],\n",
       "       [0.99632931, 0.57894737],\n",
       "       [0.99632931, 0.63157895],\n",
       "       [0.99632931, 0.68421053],\n",
       "       [0.99632931, 0.73684211],\n",
       "       [0.99632931, 0.78947368],\n",
       "       [0.99632931, 0.84210526],\n",
       "       [0.99632931, 0.89473684],\n",
       "       [0.99632931, 0.94736842],\n",
       "       [0.99632931, 1.        ]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalization\n",
    "XpBS_minmax2 = min_max_scaler2.transform(XpBS_values)\n",
    "XpBS_minmax2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e5a4e9b1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "XpBS_tensor2 = torch.from_numpy(XpBS_minmax2).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b62058cc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    throughput_pred = model1(XpBS_tensor2)\n",
    "y = pd.concat([pd.Series(XpBS_values[:, 0].reshape(-1), name='send rates'), pd.Series(XpBS_values[:, 1].reshape(-1), name='block size'), \n",
    "               pd.Series(throughput_pred.numpy().reshape(-1), name='throughput_pred')], axis=1)\n",
    "y.index = XpBS.index\n",
    "y.to_csv('./throughput_pred_related1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "65d7bbe8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>send rates</th>\n",
       "      <th>block size</th>\n",
       "      <th>throughput_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>12.571510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>12.628407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>12.685304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>12.742206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>12.799105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>200</td>\n",
       "      <td>160</td>\n",
       "      <td>159.231079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>200</td>\n",
       "      <td>170</td>\n",
       "      <td>161.011200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>200</td>\n",
       "      <td>180</td>\n",
       "      <td>162.791321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>200</td>\n",
       "      <td>190</td>\n",
       "      <td>164.571457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>166.351593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     send rates  block size  throughput_pred\n",
       "0            10          10        12.571510\n",
       "1            10          20        12.628407\n",
       "2            10          30        12.685304\n",
       "3            10          40        12.742206\n",
       "4            10          50        12.799105\n",
       "..          ...         ...              ...\n",
       "395         200         160       159.231079\n",
       "396         200         170       161.011200\n",
       "397         200         180       162.791321\n",
       "398         200         190       164.571457\n",
       "399         200         200       166.351593\n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c76ea985",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    latency_pred = model(XpBS_tensor)\n",
    "    throughput_pred = model1(XpBS_tensor2)\n",
    "y = pd.concat([pd.Series(XpBS_values[:, 0].reshape(-1), name='send rates'), pd.Series(XpBS_values[:, 1].reshape(-1), name='block size'), \n",
    "               pd.Series(latency_pred.numpy().reshape(-1), name='latency_pred'),\n",
    "               pd.Series(throughput_pred.numpy().reshape(-1), name='throughput_pred')], axis=1)\n",
    "y.index = XpBS.index\n",
    "y.to_csv('./latency_throughput_pred_related1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0c0946",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Set the score function to chose the best block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "92fcb90c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>send rates</th>\n",
       "      <th>block size</th>\n",
       "      <th>latency_pred</th>\n",
       "      <th>throughput_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.313954</td>\n",
       "      <td>12.571510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.820229</td>\n",
       "      <td>12.628407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>1.092091</td>\n",
       "      <td>12.685304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>1.255364</td>\n",
       "      <td>12.742206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>1.405114</td>\n",
       "      <td>12.799105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>200</td>\n",
       "      <td>160</td>\n",
       "      <td>1.715595</td>\n",
       "      <td>159.231079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>200</td>\n",
       "      <td>170</td>\n",
       "      <td>1.646274</td>\n",
       "      <td>161.011200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>200</td>\n",
       "      <td>180</td>\n",
       "      <td>1.592673</td>\n",
       "      <td>162.791321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>200</td>\n",
       "      <td>190</td>\n",
       "      <td>1.570900</td>\n",
       "      <td>164.571457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>1.548800</td>\n",
       "      <td>166.351593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     send rates  block size  latency_pred  throughput_pred\n",
       "0            10          10      0.313954        12.571510\n",
       "1            10          20      0.820229        12.628407\n",
       "2            10          30      1.092091        12.685304\n",
       "3            10          40      1.255364        12.742206\n",
       "4            10          50      1.405114        12.799105\n",
       "..          ...         ...           ...              ...\n",
       "395         200         160      1.715595       159.231079\n",
       "396         200         170      1.646274       161.011200\n",
       "397         200         180      1.592673       162.791321\n",
       "398         200         190      1.570900       164.571457\n",
       "399         200         200      1.548800       166.351593\n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e0cba269",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "    send rates  block size  latency_pred  throughput_pred\n",
      "0           10          10      0.313954        12.571510\n",
      "1           10          20      0.820229        12.628407\n",
      "2           10          30      1.092091        12.685304\n",
      "3           10          40      1.255364        12.742206\n",
      "4           10          50      1.405114        12.799105\n",
      "5           10          60      1.379416        12.856003\n",
      "6           10          70      1.310039        12.912899\n",
      "7           10          80      1.232086        12.969799\n",
      "8           10          90      1.135677        13.026701\n",
      "9           10         100      1.139989        13.083597\n",
      "10          10         110      1.144301        13.140495\n",
      "11          10         120      1.143092        13.197393\n",
      "12          10         130      1.141496        13.254299\n",
      "13          10         140      1.139900        13.311193\n",
      "14          10         150      1.138304        13.368092\n",
      "15          10         160      1.136708        13.424991\n",
      "16          10         170      1.135112        13.481891\n",
      "17          10         180      1.133763        13.538788\n",
      "18          10         190      1.139643        13.595686\n",
      "19          10         200      1.145966        13.652584\n",
      "20\n",
      "    send rates  block size  latency_pred  throughput_pred\n",
      "20          20          10      0.183035        20.743341\n",
      "21          20          20      0.520722        20.800240\n",
      "22          20          30      0.784944        20.857138\n",
      "23          20          40      1.005468        20.914038\n",
      "24          20          50      1.159620        20.970934\n",
      "25          20          60      1.133922        21.027838\n",
      "26          20          70      1.166261        21.084730\n",
      "27          20          80      1.174070        21.141634\n",
      "28          20          90      1.139155        21.198526\n",
      "29          20         100      1.143467        21.255430\n",
      "30          20         110      1.147779        21.312326\n",
      "31          20         120      1.147666        21.369226\n",
      "32          20         130      1.146070        21.426130\n",
      "33          20         140      1.144474        21.483027\n",
      "34          20         150      1.142878        21.539919\n",
      "35          20         160      1.141282        21.596823\n",
      "36          20         170      1.139686        21.653721\n",
      "37          20         180      1.138330        21.710619\n",
      "38          20         190      1.144210        21.767517\n",
      "39          20         200      1.154678        21.824415\n",
      "30\n",
      "    send rates  block size  latency_pred  throughput_pred\n",
      "40          30          10      0.113699        28.915171\n",
      "41          30          20      0.366473        28.972071\n",
      "42          30          30      0.527728        29.028973\n",
      "43          30          40      0.712307        29.085867\n",
      "44          30          50      0.881329        29.142767\n",
      "45          30          60      0.964731        29.199669\n",
      "46          30          70      1.078179        29.256561\n",
      "47          30          80      1.089682        29.313467\n",
      "48          30          90      1.127181        29.370363\n",
      "49          30         100      1.146945        29.427259\n",
      "50          30         110      1.151257        29.484158\n",
      "51          30         120      1.152240        29.541061\n",
      "52          30         130      1.150644        29.597956\n",
      "53          30         140      1.149048        29.654854\n",
      "54          30         150      1.147452        29.711752\n",
      "55          30         160      1.145856        29.768656\n",
      "56          30         170      1.144260        29.825552\n",
      "57          30         180      1.142898        29.882450\n",
      "58          30         190      1.148778        29.939346\n",
      "59          30         200      1.164310        29.996248\n",
      "40\n",
      "    send rates  block size  latency_pred  throughput_pred\n",
      "60          40          10      0.099700        37.087006\n",
      "61          40          20      0.265348        37.143906\n",
      "62          40          30      0.407448        37.200806\n",
      "63          40          40      0.523117        37.257702\n",
      "64          40          50      0.702732        37.314598\n",
      "65          40          60      0.813076        37.371494\n",
      "66          40          70      0.926524        37.428398\n",
      "67          40          80      0.971046        37.485294\n",
      "68          40          90      1.085711        37.542191\n",
      "69          40         100      1.128433        37.599094\n",
      "70          40         110      1.154736        37.655994\n",
      "71          40         120      1.156815        37.712891\n",
      "72          40         130      1.155219        37.769791\n",
      "73          40         140      1.153623        37.826687\n",
      "74          40         150      1.152027        37.883591\n",
      "75          40         160      1.150431        37.940487\n",
      "76          40         170      1.148834        37.997383\n",
      "77          40         180      1.147465        38.054283\n",
      "78          40         190      1.153345        38.111183\n",
      "79          40         200      1.173941        38.168083\n",
      "50\n",
      "    send rates  block size  latency_pred  throughput_pred\n",
      "80          50          10      0.096375        45.258831\n",
      "81          50          20      0.233367        45.315735\n",
      "82          50          30      0.331235        45.372635\n",
      "83          50          40      0.437836        45.429535\n",
      "84          50          50      0.628839        45.486435\n",
      "85          50          60      0.692968        45.543327\n",
      "86          50          70      0.774868        45.600227\n",
      "87          50          80      0.841310        45.657127\n",
      "88          50          90      0.971387        45.714020\n",
      "89          50         100      1.064261        45.770927\n",
      "90          50         110      1.103954        45.827827\n",
      "91          50         120      1.140323        45.884716\n",
      "92          50         130      1.153359        45.941620\n",
      "93          50         140      1.158197        45.998520\n",
      "94          50         150      1.156601        46.055420\n",
      "95          50         160      1.155005        46.112320\n",
      "96          50         170      1.153409        46.169220\n",
      "97          50         180      1.152033        46.226120\n",
      "98          50         190      1.151459        46.283012\n",
      "99          50         200      1.149421        46.339912\n",
      "60\n",
      "     send rates  block size  latency_pred  throughput_pred\n",
      "100          60          10      0.093051        53.430668\n",
      "101          60          20      0.228047        53.487564\n",
      "102          60          30      0.316917        53.544468\n",
      "103          60          40      0.385414        53.601364\n",
      "104          60          50      0.556661        53.658264\n",
      "105          60          60      0.619485        53.715157\n",
      "106          60          70      0.683203        53.772064\n",
      "107          60          80      0.722313        53.828957\n",
      "108          60          90      0.857064        53.885857\n",
      "109          60         100      1.000088        53.942757\n",
      "110          60         110      1.039782        53.999657\n",
      "111          60         120      1.079434        54.056549\n",
      "112          60         130      1.112587        54.113457\n",
      "113          60         140      1.125623        54.170357\n",
      "114          60         150      1.138659        54.227249\n",
      "115          60         160      1.151695        54.284149\n",
      "116          60         170      1.141066        54.341042\n",
      "117          60         180      1.111985        54.397942\n",
      "118          60         190      1.090168        54.454842\n",
      "119          60         200      1.093194        54.511738\n",
      "70\n",
      "     send rates  block size  latency_pred  throughput_pred\n",
      "120          70          10      0.090240        61.602497\n",
      "121          70          20      0.227214        61.659393\n",
      "122          70          30      0.309250        61.716301\n",
      "123          70          40      0.367316        61.773193\n",
      "124          70          50      0.506767        61.830093\n",
      "125          70          60      0.554884        61.886993\n",
      "126          70          70      0.612525        61.943886\n",
      "127          70          80      0.671383        62.000793\n",
      "128          70          90      0.752937        62.057690\n",
      "129          70         100      0.911892        62.114586\n",
      "130          70         110      0.975609        62.171486\n",
      "131          70         120      1.015302        62.228382\n",
      "132          70         130      1.050142        62.285278\n",
      "133          70         140      1.083928        62.342186\n",
      "134          70         150      1.070507        62.399086\n",
      "135          70         160      1.055845        62.455982\n",
      "136          70         170      1.041184        62.512878\n",
      "137          70         180      1.026729        62.569778\n",
      "138          70         190      1.019543        62.626671\n",
      "139          70         200      1.036968        62.683575\n",
      "80\n",
      "     send rates  block size  latency_pred  throughput_pred\n",
      "140          80          10      0.089850        69.774338\n",
      "141          80          20      0.226674        69.831238\n",
      "142          80          30      0.293460        69.888123\n",
      "143          80          40      0.367750        69.945030\n",
      "144          80          50      0.460253        70.001923\n",
      "145          80          60      0.508370        70.058830\n",
      "146          80          70      0.556487        70.115723\n",
      "147          80          80      0.613910        70.172623\n",
      "148          80          90      0.712887        70.229523\n",
      "149          80         100      0.798131        70.286423\n",
      "150          80         110      0.911436        70.343323\n",
      "151          80         120      0.940984        70.400223\n",
      "152          80         130      0.949223        70.457115\n",
      "153          80         140      0.955310        70.514023\n",
      "154          80         150      0.961398        70.570915\n",
      "155          80         160      0.949215        70.627808\n",
      "156          80         170      0.934553        70.684708\n",
      "157          80         180      0.920092        70.741615\n",
      "158          80         190      0.912906        70.798508\n",
      "159          80         200      0.940693        70.855408\n",
      "90\n",
      "     send rates  block size  latency_pred  throughput_pred\n",
      "160          90          10      0.090206        77.946159\n",
      "161          90          20      0.227030        78.003067\n",
      "162          90          30      0.279350        78.059967\n",
      "163          90          40      0.388283        78.116867\n",
      "164          90          50      0.443162        78.173752\n",
      "165          90          60      0.484864        78.230652\n",
      "166          90          70      0.529059        78.287552\n",
      "167          90          80      0.587153        78.344452\n",
      "168          90          90      0.689269        78.401337\n",
      "169          90         100      0.761349        78.458252\n",
      "170          90         110      0.819903        78.515137\n",
      "171          90         120      0.816414        78.572037\n",
      "172          90         130      0.820288        78.628944\n",
      "173          90         140      0.826375        78.685852\n",
      "174          90         150      0.832463        78.742744\n",
      "175          90         160      0.838550        78.799644\n",
      "176          90         170      0.827923        78.856552\n",
      "177          90         180      0.813454        78.913437\n",
      "178          90         190      0.806269        78.970352\n",
      "179          90         200      0.839120        79.027245\n",
      "100\n",
      "     send rates  block size  latency_pred  throughput_pred\n",
      "180         100          10      0.092920        86.117989\n",
      "181         100          20      0.258307        86.174896\n",
      "182         100          30      0.269154        86.231796\n",
      "183         100          40      0.424628        86.288696\n",
      "184         100          50      0.434653        86.345589\n",
      "185         100          60      0.470193        86.402489\n",
      "186         100          70      0.511887        86.459396\n",
      "187         100          80      0.565513        86.516281\n",
      "188         100          90      0.667637        86.573174\n",
      "189         100         100      0.729108        86.630089\n",
      "190         100         110      0.792850        86.686981\n",
      "191         100         120      0.807064        86.743881\n",
      "192         100         130      0.796041        86.800781\n",
      "193         100         140      0.789833        86.857689\n",
      "194         100         150      0.783626        86.914581\n",
      "195         100         160      0.777419        86.971466\n",
      "196         100         170      0.771211        87.028366\n",
      "197         100         180      0.758041        87.085266\n",
      "198         100         190      0.751922        87.142166\n",
      "199         100         200      0.768138        87.199074\n",
      "110\n",
      "     send rates  block size  latency_pred  throughput_pred\n",
      "200         110          10      0.116099        92.969315\n",
      "201         110          20      0.451027        94.346718\n",
      "202         110          30      0.262916        94.403610\n",
      "203         110          40      0.513995        94.460518\n",
      "204         110          50      0.426948        94.517418\n",
      "205         110          60      0.452910        94.574326\n",
      "206         110          70      0.478871        94.631210\n",
      "207         110          80      0.541231        94.688103\n",
      "208         110          90      0.658695        94.745010\n",
      "209         110         100      0.721272        94.801918\n",
      "210         110         110      0.783848        94.858810\n",
      "211         110         120      0.824487        94.915695\n",
      "212         110         130      0.814433        94.972610\n",
      "213         110         140      0.801998        95.029503\n",
      "214         110         150      0.791181        95.086403\n",
      "215         110         160      0.786079        95.143295\n",
      "216         110         170      0.780976        95.200203\n",
      "217         110         180      0.776038        95.257103\n",
      "218         110         190      0.777446        95.313995\n",
      "219         110         200      0.793608        95.370895\n",
      "120\n",
      "     send rates  block size  latency_pred  throughput_pred\n",
      "220         120          10      0.307180        97.364853\n",
      "221         120          20      0.688821        99.144989\n",
      "222         120          30      0.307015       100.925110\n",
      "223         120          40      0.665460       102.632339\n",
      "224         120          50      0.422038       102.689247\n",
      "225         120          60      0.438179       102.746140\n",
      "226         120          70      0.460111       102.803040\n",
      "227         120          80      0.530066       102.859947\n",
      "228         120          90      0.651747       102.916840\n",
      "229         120         100      0.724343       102.973740\n",
      "230         120         110      0.786920       103.030632\n",
      "231         120         120      0.866201       103.087540\n",
      "232         120         130      0.854257       103.144440\n",
      "233         120         140      0.828598       103.201340\n",
      "234         120         150      0.816162       103.258240\n",
      "235         120         160      0.801613       103.315140\n",
      "236         120         170      0.789073       103.372025\n",
      "237         120         180      0.781403       103.428925\n",
      "238         120         190      0.790705       103.485840\n",
      "239         120         200      0.810944       103.542725\n",
      "130\n",
      "     send rates  block size  latency_pred  throughput_pred\n",
      "240         130          10      0.594171       101.760391\n",
      "241         130          20      0.821625       103.540527\n",
      "242         130          30      0.326867       105.320656\n",
      "243         130          40      0.796792       107.100777\n",
      "244         130          50      0.452911       108.880905\n",
      "245         130          60      0.436942       110.661034\n",
      "246         130          70      0.457373       110.974884\n",
      "247         130          80      0.523141       111.031784\n",
      "248         130          90      0.631896       111.088669\n",
      "249         130         100      0.716003       111.145584\n",
      "250         130         110      0.775853       111.202477\n",
      "251         130         120      0.848042       111.259377\n",
      "252         130         130      0.896848       111.316284\n",
      "253         130         140      0.860473       111.373169\n",
      "254         130         150      0.817721       111.430061\n",
      "255         130         160      0.802560       111.486969\n",
      "256         130         170      0.789233       111.543869\n",
      "257         130         180      0.776933       111.600769\n",
      "258         130         190      0.787139       111.657654\n",
      "259         130         200      0.819935       111.714569\n",
      "140\n",
      "     send rates  block size  latency_pred  throughput_pred\n",
      "260         140          10      0.876689       106.155937\n",
      "261         140          20      1.022289       107.936050\n",
      "262         140          30      0.483978       109.716187\n",
      "263         140          40      1.135574       111.496307\n",
      "264         140          50      0.509122       113.276436\n",
      "265         140          60      0.408295       115.056572\n",
      "266         140          70      0.410121       116.836700\n",
      "267         140          80      0.488967       118.616821\n",
      "268         140          90      0.601092       119.260498\n",
      "269         140         100      0.692605       119.317406\n",
      "270         140         110      0.745967       119.374306\n",
      "271         140         120      0.819427       119.431198\n",
      "272         140         130      0.918384       119.488106\n",
      "273         140         140      0.898091       119.544991\n",
      "274         140         150      0.867047       119.601898\n",
      "275         140         160      0.822625       119.658806\n",
      "276         140         170      0.796275       119.715698\n",
      "277         140         180      0.783969       119.772591\n",
      "278         140         190      0.793609       119.829491\n",
      "279         140         200      0.826415       119.886383\n",
      "150\n",
      "     send rates  block size  latency_pred  throughput_pred\n",
      "280         150          10      1.143600       110.551468\n",
      "281         150          20      1.211390       112.331596\n",
      "282         150          30      0.714434       114.111732\n",
      "283         150          40      1.488943       115.891853\n",
      "284         150          50      0.602885       117.671989\n",
      "285         150          60      0.425659       119.452118\n",
      "286         150          70      0.427485       121.232239\n",
      "287         150          80      0.500148       123.012360\n",
      "288         150          90      0.592311       124.792496\n",
      "289         150         100      0.678098       126.572617\n",
      "290         150         110      0.716453       127.546135\n",
      "291         150         120      0.775702       127.603043\n",
      "292         150         130      0.878678       127.659927\n",
      "293         150         140      0.908228       127.716835\n",
      "294         150         150      0.904451       127.773727\n",
      "295         150         160      0.883401       127.830635\n",
      "296         150         170      0.849468       127.887535\n",
      "297         150         180      0.814075       127.944420\n",
      "298         150         190      0.833212       128.001328\n",
      "299         150         200      0.868960       128.058228\n",
      "160\n",
      "     send rates  block size  latency_pred  throughput_pred\n",
      "300         160          10      1.410510       114.947014\n",
      "301         160          20      1.400491       116.727135\n",
      "302         160          30      0.945928       118.507271\n",
      "303         160          40      1.719398       120.287399\n",
      "304         160          50      0.943916       122.067513\n",
      "305         160          60      0.443023       123.847656\n",
      "306         160          70      0.444849       125.627769\n",
      "307         160          80      0.527002       127.407906\n",
      "308         160          90      0.636521       129.188034\n",
      "309         160         100      0.775058       130.968170\n",
      "310         160         110      0.839773       132.748291\n",
      "311         160         120      0.892386       134.528412\n",
      "312         160         130      0.944999       135.831757\n",
      "313         160         140      0.954261       135.888672\n",
      "314         160         150      0.909045       135.945557\n",
      "315         160         160      0.889720       136.002472\n",
      "316         160         170      0.867526       136.059357\n",
      "317         160         180      0.833739       136.116272\n",
      "318         160         190      0.856393       136.173172\n",
      "319         160         200      0.902630       136.230057\n",
      "170\n",
      "     send rates  block size  latency_pred  throughput_pred\n",
      "320         170          10      1.677421       119.342545\n",
      "321         170          20      1.589593       121.122665\n",
      "322         170          30      1.177780       122.902802\n",
      "323         170          40      1.949942       124.682922\n",
      "324         170          50      1.311027       126.463058\n",
      "325         170          60      0.518340       128.243179\n",
      "326         170          70      0.506402       130.023300\n",
      "327         170          80      0.646301       131.803436\n",
      "328         170          90      0.789920       133.583557\n",
      "329         170         100      0.933539       135.363708\n",
      "330         170         110      1.020175       137.143814\n",
      "331         170         120      1.072788       138.923950\n",
      "332         170         130      1.125400       140.704071\n",
      "333         170         140      1.178013       142.484207\n",
      "334         170         150      1.103156       144.117371\n",
      "335         170         160      1.020401       144.174286\n",
      "336         170         170      0.937647       144.231171\n",
      "337         170         180      0.858911       144.288086\n",
      "338         170         190      0.885958       144.344971\n",
      "339         170         200      0.913006       144.401886\n",
      "180\n",
      "     send rates  block size  latency_pred  throughput_pred\n",
      "340         180          10      1.889910       123.738075\n",
      "341         180          20      1.748126       125.518211\n",
      "342         180          30      1.402918       127.298325\n",
      "343         180          40      2.181794       129.078461\n",
      "344         180          50      1.678137       130.858582\n",
      "345         180          60      0.699092       132.638702\n",
      "346         180          70      0.661163       134.418854\n",
      "347         180          80      0.804782       136.198975\n",
      "348         180          90      0.948401       137.979095\n",
      "349         180         100      1.092021       139.759232\n",
      "350         180         110      1.200576       141.539368\n",
      "351         180         120      1.253189       143.319489\n",
      "352         180         130      1.305802       145.099625\n",
      "353         180         140      1.358415       146.879745\n",
      "354         180         150      1.334804       148.659851\n",
      "355         180         160      1.252050       150.440018\n",
      "356         180         170      1.169378       152.220139\n",
      "357         180         180      1.105659       152.459915\n",
      "358         180         190      1.063181       152.516800\n",
      "359         180         200      1.011251       152.573730\n",
      "190\n",
      "     send rates  block size  latency_pred  throughput_pred\n",
      "360         190          10      2.046844       128.133484\n",
      "361         190          20      1.835736       129.913742\n",
      "362         190          30      1.534822       131.693878\n",
      "363         190          40      2.339685       133.473999\n",
      "364         190          50      2.004519       135.254120\n",
      "365         190          60      0.912501       137.034241\n",
      "366         190          70      0.806854       138.814377\n",
      "367         190          80      0.963263       140.594498\n",
      "368         190          90      1.106883       142.374634\n",
      "369         190         100      1.250502       144.154755\n",
      "370         190         110      1.380977       145.934875\n",
      "371         190         120      1.433590       147.715012\n",
      "372         190         130      1.486203       149.495163\n",
      "373         190         140      1.538816       151.275284\n",
      "374         190         150      1.566452       153.055389\n",
      "375         190         160      1.483698       154.835541\n",
      "376         190         170      1.407825       156.615662\n",
      "377         190         180      1.349166       158.395798\n",
      "378         190         190      1.327393       160.175903\n",
      "379         190         200      1.283770       160.745575\n",
      "200\n",
      "     send rates  block size  latency_pred  throughput_pred\n",
      "380         200          10      2.216622       132.525269\n",
      "381         200          20      1.926367       134.306488\n",
      "382         200          30      1.683847       136.087738\n",
      "383         200          40      2.489892       137.868988\n",
      "384         200          50      2.291440       139.649658\n",
      "385         200          60      1.190730       141.429779\n",
      "386         200          70      0.863849       143.209915\n",
      "387         200          80      1.031321       144.990051\n",
      "388         200          90      1.198794       146.770172\n",
      "389         200         100      1.366266       148.550293\n",
      "390         200         110      1.533739       150.330429\n",
      "391         200         120      1.613992       152.110565\n",
      "392         200         130      1.666605       153.890686\n",
      "393         200         140      1.719218       155.670822\n",
      "394         200         150      1.769411       157.450928\n",
      "395         200         160      1.715595       159.231079\n",
      "396         200         170      1.646274       161.011200\n",
      "397         200         180      1.592673       162.791321\n",
      "398         200         190      1.570900       164.571457\n",
      "399         200         200      1.548800       166.351593\n"
     ]
    }
   ],
   "source": [
    "for name, group in y.groupby('send rates', sort=False):\n",
    "    print(name)\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "11c0210f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>send rates</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.405114</td>\n",
       "      <td>0.313954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.174070</td>\n",
       "      <td>0.183035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.164310</td>\n",
       "      <td>0.113699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.173941</td>\n",
       "      <td>0.099700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.158197</td>\n",
       "      <td>0.096375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.151695</td>\n",
       "      <td>0.093051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1.083928</td>\n",
       "      <td>0.090240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.961398</td>\n",
       "      <td>0.089850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.839120</td>\n",
       "      <td>0.090206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.807064</td>\n",
       "      <td>0.092920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.824487</td>\n",
       "      <td>0.116099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.866201</td>\n",
       "      <td>0.307015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.896848</td>\n",
       "      <td>0.326867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1.135574</td>\n",
       "      <td>0.408295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>1.488943</td>\n",
       "      <td>0.425659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1.719398</td>\n",
       "      <td>0.443023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1.949942</td>\n",
       "      <td>0.506402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2.181794</td>\n",
       "      <td>0.661163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>2.339685</td>\n",
       "      <td>0.806854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2.489892</td>\n",
       "      <td>0.863849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 max       min\n",
       "send rates                    \n",
       "10          1.405114  0.313954\n",
       "20          1.174070  0.183035\n",
       "30          1.164310  0.113699\n",
       "40          1.173941  0.099700\n",
       "50          1.158197  0.096375\n",
       "60          1.151695  0.093051\n",
       "70          1.083928  0.090240\n",
       "80          0.961398  0.089850\n",
       "90          0.839120  0.090206\n",
       "100         0.807064  0.092920\n",
       "110         0.824487  0.116099\n",
       "120         0.866201  0.307015\n",
       "130         0.896848  0.326867\n",
       "140         1.135574  0.408295\n",
       "150         1.488943  0.425659\n",
       "160         1.719398  0.443023\n",
       "170         1.949942  0.506402\n",
       "180         2.181794  0.661163\n",
       "190         2.339685  0.806854\n",
       "200         2.489892  0.863849"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la_max_min = y.groupby('send rates', sort=False)['latency_pred'].agg(['max', 'min'])\n",
    "la_max_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9b23e119",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latency_max</th>\n",
       "      <th>latency_min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>send rates</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.405114</td>\n",
       "      <td>0.313954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.174070</td>\n",
       "      <td>0.183035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.164310</td>\n",
       "      <td>0.113699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.173941</td>\n",
       "      <td>0.099700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.158197</td>\n",
       "      <td>0.096375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.151695</td>\n",
       "      <td>0.093051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1.083928</td>\n",
       "      <td>0.090240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.961398</td>\n",
       "      <td>0.089850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.839120</td>\n",
       "      <td>0.090206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.807064</td>\n",
       "      <td>0.092920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.824487</td>\n",
       "      <td>0.116099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.866201</td>\n",
       "      <td>0.307015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.896848</td>\n",
       "      <td>0.326867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1.135574</td>\n",
       "      <td>0.408295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>1.488943</td>\n",
       "      <td>0.425659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1.719398</td>\n",
       "      <td>0.443023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1.949942</td>\n",
       "      <td>0.506402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2.181794</td>\n",
       "      <td>0.661163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>2.339685</td>\n",
       "      <td>0.806854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2.489892</td>\n",
       "      <td>0.863849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            latency_max  latency_min\n",
       "send rates                          \n",
       "10             1.405114     0.313954\n",
       "20             1.174070     0.183035\n",
       "30             1.164310     0.113699\n",
       "40             1.173941     0.099700\n",
       "50             1.158197     0.096375\n",
       "60             1.151695     0.093051\n",
       "70             1.083928     0.090240\n",
       "80             0.961398     0.089850\n",
       "90             0.839120     0.090206\n",
       "100            0.807064     0.092920\n",
       "110            0.824487     0.116099\n",
       "120            0.866201     0.307015\n",
       "130            0.896848     0.326867\n",
       "140            1.135574     0.408295\n",
       "150            1.488943     0.425659\n",
       "160            1.719398     0.443023\n",
       "170            1.949942     0.506402\n",
       "180            2.181794     0.661163\n",
       "190            2.339685     0.806854\n",
       "200            2.489892     0.863849"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la_col=['latency_max', 'latency_min']\n",
    "la_max_min.columns = la_col\n",
    "la_max_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0e951a74",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>send rates</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13.652584</td>\n",
       "      <td>12.571510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.824415</td>\n",
       "      <td>20.743341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>29.996248</td>\n",
       "      <td>28.915171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>38.168083</td>\n",
       "      <td>37.087006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>46.339912</td>\n",
       "      <td>45.258831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>54.511738</td>\n",
       "      <td>53.430668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>62.683575</td>\n",
       "      <td>61.602497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>70.855408</td>\n",
       "      <td>69.774338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>79.027245</td>\n",
       "      <td>77.946159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>87.199074</td>\n",
       "      <td>86.117989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>95.370895</td>\n",
       "      <td>92.969315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>103.542725</td>\n",
       "      <td>97.364853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>111.714569</td>\n",
       "      <td>101.760391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>119.886383</td>\n",
       "      <td>106.155937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>128.058228</td>\n",
       "      <td>110.551468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>136.230057</td>\n",
       "      <td>114.947014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>144.401886</td>\n",
       "      <td>119.342545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>152.573730</td>\n",
       "      <td>123.738075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>160.745575</td>\n",
       "      <td>128.133484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>166.351593</td>\n",
       "      <td>132.525269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   max         min\n",
       "send rates                        \n",
       "10           13.652584   12.571510\n",
       "20           21.824415   20.743341\n",
       "30           29.996248   28.915171\n",
       "40           38.168083   37.087006\n",
       "50           46.339912   45.258831\n",
       "60           54.511738   53.430668\n",
       "70           62.683575   61.602497\n",
       "80           70.855408   69.774338\n",
       "90           79.027245   77.946159\n",
       "100          87.199074   86.117989\n",
       "110          95.370895   92.969315\n",
       "120         103.542725   97.364853\n",
       "130         111.714569  101.760391\n",
       "140         119.886383  106.155937\n",
       "150         128.058228  110.551468\n",
       "160         136.230057  114.947014\n",
       "170         144.401886  119.342545\n",
       "180         152.573730  123.738075\n",
       "190         160.745575  128.133484\n",
       "200         166.351593  132.525269"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th_max_min = y.groupby('send rates', sort=False)['throughput_pred'].agg(['max', 'min'])\n",
    "th_max_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "951451c3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>throughput_max</th>\n",
       "      <th>throughput_min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>send rates</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13.652584</td>\n",
       "      <td>12.571510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.824415</td>\n",
       "      <td>20.743341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>29.996248</td>\n",
       "      <td>28.915171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>38.168083</td>\n",
       "      <td>37.087006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>46.339912</td>\n",
       "      <td>45.258831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>54.511738</td>\n",
       "      <td>53.430668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>62.683575</td>\n",
       "      <td>61.602497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>70.855408</td>\n",
       "      <td>69.774338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>79.027245</td>\n",
       "      <td>77.946159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>87.199074</td>\n",
       "      <td>86.117989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>95.370895</td>\n",
       "      <td>92.969315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>103.542725</td>\n",
       "      <td>97.364853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>111.714569</td>\n",
       "      <td>101.760391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>119.886383</td>\n",
       "      <td>106.155937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>128.058228</td>\n",
       "      <td>110.551468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>136.230057</td>\n",
       "      <td>114.947014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>144.401886</td>\n",
       "      <td>119.342545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>152.573730</td>\n",
       "      <td>123.738075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>160.745575</td>\n",
       "      <td>128.133484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>166.351593</td>\n",
       "      <td>132.525269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            throughput_max  throughput_min\n",
       "send rates                                \n",
       "10               13.652584       12.571510\n",
       "20               21.824415       20.743341\n",
       "30               29.996248       28.915171\n",
       "40               38.168083       37.087006\n",
       "50               46.339912       45.258831\n",
       "60               54.511738       53.430668\n",
       "70               62.683575       61.602497\n",
       "80               70.855408       69.774338\n",
       "90               79.027245       77.946159\n",
       "100              87.199074       86.117989\n",
       "110              95.370895       92.969315\n",
       "120             103.542725       97.364853\n",
       "130             111.714569      101.760391\n",
       "140             119.886383      106.155937\n",
       "150             128.058228      110.551468\n",
       "160             136.230057      114.947014\n",
       "170             144.401886      119.342545\n",
       "180             152.573730      123.738075\n",
       "190             160.745575      128.133484\n",
       "200             166.351593      132.525269"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th_col=['throughput_max', 'throughput_min']\n",
    "th_max_min.columns = th_col\n",
    "th_max_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "771622b1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>send rates</th>\n",
       "      <th>latency_max</th>\n",
       "      <th>latency_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1.405114</td>\n",
       "      <td>0.313954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>1.174070</td>\n",
       "      <td>0.183035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>1.164310</td>\n",
       "      <td>0.113699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>1.173941</td>\n",
       "      <td>0.099700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>1.158197</td>\n",
       "      <td>0.096375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>1.151695</td>\n",
       "      <td>0.093051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70</td>\n",
       "      <td>1.083928</td>\n",
       "      <td>0.090240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>0.961398</td>\n",
       "      <td>0.089850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>90</td>\n",
       "      <td>0.839120</td>\n",
       "      <td>0.090206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>0.807064</td>\n",
       "      <td>0.092920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>110</td>\n",
       "      <td>0.824487</td>\n",
       "      <td>0.116099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>120</td>\n",
       "      <td>0.866201</td>\n",
       "      <td>0.307015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>130</td>\n",
       "      <td>0.896848</td>\n",
       "      <td>0.326867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>140</td>\n",
       "      <td>1.135574</td>\n",
       "      <td>0.408295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>150</td>\n",
       "      <td>1.488943</td>\n",
       "      <td>0.425659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>160</td>\n",
       "      <td>1.719398</td>\n",
       "      <td>0.443023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>170</td>\n",
       "      <td>1.949942</td>\n",
       "      <td>0.506402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>180</td>\n",
       "      <td>2.181794</td>\n",
       "      <td>0.661163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>190</td>\n",
       "      <td>2.339685</td>\n",
       "      <td>0.806854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>200</td>\n",
       "      <td>2.489892</td>\n",
       "      <td>0.863849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    send rates  latency_max  latency_min\n",
       "0           10     1.405114     0.313954\n",
       "1           20     1.174070     0.183035\n",
       "2           30     1.164310     0.113699\n",
       "3           40     1.173941     0.099700\n",
       "4           50     1.158197     0.096375\n",
       "5           60     1.151695     0.093051\n",
       "6           70     1.083928     0.090240\n",
       "7           80     0.961398     0.089850\n",
       "8           90     0.839120     0.090206\n",
       "9          100     0.807064     0.092920\n",
       "10         110     0.824487     0.116099\n",
       "11         120     0.866201     0.307015\n",
       "12         130     0.896848     0.326867\n",
       "13         140     1.135574     0.408295\n",
       "14         150     1.488943     0.425659\n",
       "15         160     1.719398     0.443023\n",
       "16         170     1.949942     0.506402\n",
       "17         180     2.181794     0.661163\n",
       "18         190     2.339685     0.806854\n",
       "19         200     2.489892     0.863849"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restore the grouping index to the column\n",
    "la_max_min.reset_index(inplace=True)\n",
    "la_max_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a5161e13",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>send rates</th>\n",
       "      <th>throughput_max</th>\n",
       "      <th>throughput_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>13.652584</td>\n",
       "      <td>12.571510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>21.824415</td>\n",
       "      <td>20.743341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>29.996248</td>\n",
       "      <td>28.915171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>38.168083</td>\n",
       "      <td>37.087006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>46.339912</td>\n",
       "      <td>45.258831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>54.511738</td>\n",
       "      <td>53.430668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70</td>\n",
       "      <td>62.683575</td>\n",
       "      <td>61.602497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>70.855408</td>\n",
       "      <td>69.774338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>90</td>\n",
       "      <td>79.027245</td>\n",
       "      <td>77.946159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>87.199074</td>\n",
       "      <td>86.117989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>110</td>\n",
       "      <td>95.370895</td>\n",
       "      <td>92.969315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>120</td>\n",
       "      <td>103.542725</td>\n",
       "      <td>97.364853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>130</td>\n",
       "      <td>111.714569</td>\n",
       "      <td>101.760391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>140</td>\n",
       "      <td>119.886383</td>\n",
       "      <td>106.155937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>150</td>\n",
       "      <td>128.058228</td>\n",
       "      <td>110.551468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>160</td>\n",
       "      <td>136.230057</td>\n",
       "      <td>114.947014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>170</td>\n",
       "      <td>144.401886</td>\n",
       "      <td>119.342545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>180</td>\n",
       "      <td>152.573730</td>\n",
       "      <td>123.738075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>190</td>\n",
       "      <td>160.745575</td>\n",
       "      <td>128.133484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>200</td>\n",
       "      <td>166.351593</td>\n",
       "      <td>132.525269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    send rates  throughput_max  throughput_min\n",
       "0           10       13.652584       12.571510\n",
       "1           20       21.824415       20.743341\n",
       "2           30       29.996248       28.915171\n",
       "3           40       38.168083       37.087006\n",
       "4           50       46.339912       45.258831\n",
       "5           60       54.511738       53.430668\n",
       "6           70       62.683575       61.602497\n",
       "7           80       70.855408       69.774338\n",
       "8           90       79.027245       77.946159\n",
       "9          100       87.199074       86.117989\n",
       "10         110       95.370895       92.969315\n",
       "11         120      103.542725       97.364853\n",
       "12         130      111.714569      101.760391\n",
       "13         140      119.886383      106.155937\n",
       "14         150      128.058228      110.551468\n",
       "15         160      136.230057      114.947014\n",
       "16         170      144.401886      119.342545\n",
       "17         180      152.573730      123.738075\n",
       "18         190      160.745575      128.133484\n",
       "19         200      166.351593      132.525269"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th_max_min.reset_index(inplace=True)\n",
    "th_max_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "98389d08",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la_max = la_max_min['latency_max'].values\n",
    "la_max = list(la_max)\n",
    "la_max\n",
    "len(la_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5f35a501",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.4051139,\n",
       " 1.4051139,\n",
       " 1.4051139,\n",
       " 1.4051139,\n",
       " 1.4051139,\n",
       " 1.4051139,\n",
       " 1.4051139,\n",
       " 1.4051139,\n",
       " 1.4051139,\n",
       " 1.4051139,\n",
       " 1.4051139,\n",
       " 1.4051139,\n",
       " 1.4051139,\n",
       " 1.4051139,\n",
       " 1.4051139,\n",
       " 1.4051139,\n",
       " 1.4051139,\n",
       " 1.4051139,\n",
       " 1.4051139,\n",
       " 1.4051139,\n",
       " 1.1740704,\n",
       " 1.1740704,\n",
       " 1.1740704,\n",
       " 1.1740704,\n",
       " 1.1740704,\n",
       " 1.1740704,\n",
       " 1.1740704,\n",
       " 1.1740704,\n",
       " 1.1740704,\n",
       " 1.1740704,\n",
       " 1.1740704,\n",
       " 1.1740704,\n",
       " 1.1740704,\n",
       " 1.1740704,\n",
       " 1.1740704,\n",
       " 1.1740704,\n",
       " 1.1740704,\n",
       " 1.1740704,\n",
       " 1.1740704,\n",
       " 1.1740704,\n",
       " 1.1643097,\n",
       " 1.1643097,\n",
       " 1.1643097,\n",
       " 1.1643097,\n",
       " 1.1643097,\n",
       " 1.1643097,\n",
       " 1.1643097,\n",
       " 1.1643097,\n",
       " 1.1643097,\n",
       " 1.1643097,\n",
       " 1.1643097,\n",
       " 1.1643097,\n",
       " 1.1643097,\n",
       " 1.1643097,\n",
       " 1.1643097,\n",
       " 1.1643097,\n",
       " 1.1643097,\n",
       " 1.1643097,\n",
       " 1.1643097,\n",
       " 1.1643097,\n",
       " 1.173941,\n",
       " 1.173941,\n",
       " 1.173941,\n",
       " 1.173941,\n",
       " 1.173941,\n",
       " 1.173941,\n",
       " 1.173941,\n",
       " 1.173941,\n",
       " 1.173941,\n",
       " 1.173941,\n",
       " 1.173941,\n",
       " 1.173941,\n",
       " 1.173941,\n",
       " 1.173941,\n",
       " 1.173941,\n",
       " 1.173941,\n",
       " 1.173941,\n",
       " 1.173941,\n",
       " 1.173941,\n",
       " 1.173941,\n",
       " 1.1581967,\n",
       " 1.1581967,\n",
       " 1.1581967,\n",
       " 1.1581967,\n",
       " 1.1581967,\n",
       " 1.1581967,\n",
       " 1.1581967,\n",
       " 1.1581967,\n",
       " 1.1581967,\n",
       " 1.1581967,\n",
       " 1.1581967,\n",
       " 1.1581967,\n",
       " 1.1581967,\n",
       " 1.1581967,\n",
       " 1.1581967,\n",
       " 1.1581967,\n",
       " 1.1581967,\n",
       " 1.1581967,\n",
       " 1.1581967,\n",
       " 1.1581967,\n",
       " 1.151695,\n",
       " 1.151695,\n",
       " 1.151695,\n",
       " 1.151695,\n",
       " 1.151695,\n",
       " 1.151695,\n",
       " 1.151695,\n",
       " 1.151695,\n",
       " 1.151695,\n",
       " 1.151695,\n",
       " 1.151695,\n",
       " 1.151695,\n",
       " 1.151695,\n",
       " 1.151695,\n",
       " 1.151695,\n",
       " 1.151695,\n",
       " 1.151695,\n",
       " 1.151695,\n",
       " 1.151695,\n",
       " 1.151695,\n",
       " 1.0839276,\n",
       " 1.0839276,\n",
       " 1.0839276,\n",
       " 1.0839276,\n",
       " 1.0839276,\n",
       " 1.0839276,\n",
       " 1.0839276,\n",
       " 1.0839276,\n",
       " 1.0839276,\n",
       " 1.0839276,\n",
       " 1.0839276,\n",
       " 1.0839276,\n",
       " 1.0839276,\n",
       " 1.0839276,\n",
       " 1.0839276,\n",
       " 1.0839276,\n",
       " 1.0839276,\n",
       " 1.0839276,\n",
       " 1.0839276,\n",
       " 1.0839276,\n",
       " 0.9613975,\n",
       " 0.9613975,\n",
       " 0.9613975,\n",
       " 0.9613975,\n",
       " 0.9613975,\n",
       " 0.9613975,\n",
       " 0.9613975,\n",
       " 0.9613975,\n",
       " 0.9613975,\n",
       " 0.9613975,\n",
       " 0.9613975,\n",
       " 0.9613975,\n",
       " 0.9613975,\n",
       " 0.9613975,\n",
       " 0.9613975,\n",
       " 0.9613975,\n",
       " 0.9613975,\n",
       " 0.9613975,\n",
       " 0.9613975,\n",
       " 0.9613975,\n",
       " 0.8391198,\n",
       " 0.8391198,\n",
       " 0.8391198,\n",
       " 0.8391198,\n",
       " 0.8391198,\n",
       " 0.8391198,\n",
       " 0.8391198,\n",
       " 0.8391198,\n",
       " 0.8391198,\n",
       " 0.8391198,\n",
       " 0.8391198,\n",
       " 0.8391198,\n",
       " 0.8391198,\n",
       " 0.8391198,\n",
       " 0.8391198,\n",
       " 0.8391198,\n",
       " 0.8391198,\n",
       " 0.8391198,\n",
       " 0.8391198,\n",
       " 0.8391198,\n",
       " 0.807064,\n",
       " 0.807064,\n",
       " 0.807064,\n",
       " 0.807064,\n",
       " 0.807064,\n",
       " 0.807064,\n",
       " 0.807064,\n",
       " 0.807064,\n",
       " 0.807064,\n",
       " 0.807064,\n",
       " 0.807064,\n",
       " 0.807064,\n",
       " 0.807064,\n",
       " 0.807064,\n",
       " 0.807064,\n",
       " 0.807064,\n",
       " 0.807064,\n",
       " 0.807064,\n",
       " 0.807064,\n",
       " 0.807064,\n",
       " 0.8244867,\n",
       " 0.8244867,\n",
       " 0.8244867,\n",
       " 0.8244867,\n",
       " 0.8244867,\n",
       " 0.8244867,\n",
       " 0.8244867,\n",
       " 0.8244867,\n",
       " 0.8244867,\n",
       " 0.8244867,\n",
       " 0.8244867,\n",
       " 0.8244867,\n",
       " 0.8244867,\n",
       " 0.8244867,\n",
       " 0.8244867,\n",
       " 0.8244867,\n",
       " 0.8244867,\n",
       " 0.8244867,\n",
       " 0.8244867,\n",
       " 0.8244867,\n",
       " 0.8662006,\n",
       " 0.8662006,\n",
       " 0.8662006,\n",
       " 0.8662006,\n",
       " 0.8662006,\n",
       " 0.8662006,\n",
       " 0.8662006,\n",
       " 0.8662006,\n",
       " 0.8662006,\n",
       " 0.8662006,\n",
       " 0.8662006,\n",
       " 0.8662006,\n",
       " 0.8662006,\n",
       " 0.8662006,\n",
       " 0.8662006,\n",
       " 0.8662006,\n",
       " 0.8662006,\n",
       " 0.8662006,\n",
       " 0.8662006,\n",
       " 0.8662006,\n",
       " 0.896848,\n",
       " 0.896848,\n",
       " 0.896848,\n",
       " 0.896848,\n",
       " 0.896848,\n",
       " 0.896848,\n",
       " 0.896848,\n",
       " 0.896848,\n",
       " 0.896848,\n",
       " 0.896848,\n",
       " 0.896848,\n",
       " 0.896848,\n",
       " 0.896848,\n",
       " 0.896848,\n",
       " 0.896848,\n",
       " 0.896848,\n",
       " 0.896848,\n",
       " 0.896848,\n",
       " 0.896848,\n",
       " 0.896848,\n",
       " 1.1355741,\n",
       " 1.1355741,\n",
       " 1.1355741,\n",
       " 1.1355741,\n",
       " 1.1355741,\n",
       " 1.1355741,\n",
       " 1.1355741,\n",
       " 1.1355741,\n",
       " 1.1355741,\n",
       " 1.1355741,\n",
       " 1.1355741,\n",
       " 1.1355741,\n",
       " 1.1355741,\n",
       " 1.1355741,\n",
       " 1.1355741,\n",
       " 1.1355741,\n",
       " 1.1355741,\n",
       " 1.1355741,\n",
       " 1.1355741,\n",
       " 1.1355741,\n",
       " 1.4889426,\n",
       " 1.4889426,\n",
       " 1.4889426,\n",
       " 1.4889426,\n",
       " 1.4889426,\n",
       " 1.4889426,\n",
       " 1.4889426,\n",
       " 1.4889426,\n",
       " 1.4889426,\n",
       " 1.4889426,\n",
       " 1.4889426,\n",
       " 1.4889426,\n",
       " 1.4889426,\n",
       " 1.4889426,\n",
       " 1.4889426,\n",
       " 1.4889426,\n",
       " 1.4889426,\n",
       " 1.4889426,\n",
       " 1.4889426,\n",
       " 1.4889426,\n",
       " 1.7193985,\n",
       " 1.7193985,\n",
       " 1.7193985,\n",
       " 1.7193985,\n",
       " 1.7193985,\n",
       " 1.7193985,\n",
       " 1.7193985,\n",
       " 1.7193985,\n",
       " 1.7193985,\n",
       " 1.7193985,\n",
       " 1.7193985,\n",
       " 1.7193985,\n",
       " 1.7193985,\n",
       " 1.7193985,\n",
       " 1.7193985,\n",
       " 1.7193985,\n",
       " 1.7193985,\n",
       " 1.7193985,\n",
       " 1.7193985,\n",
       " 1.7193985,\n",
       " 1.9499424,\n",
       " 1.9499424,\n",
       " 1.9499424,\n",
       " 1.9499424,\n",
       " 1.9499424,\n",
       " 1.9499424,\n",
       " 1.9499424,\n",
       " 1.9499424,\n",
       " 1.9499424,\n",
       " 1.9499424,\n",
       " 1.9499424,\n",
       " 1.9499424,\n",
       " 1.9499424,\n",
       " 1.9499424,\n",
       " 1.9499424,\n",
       " 1.9499424,\n",
       " 1.9499424,\n",
       " 1.9499424,\n",
       " 1.9499424,\n",
       " 1.9499424,\n",
       " 2.1817944,\n",
       " 2.1817944,\n",
       " 2.1817944,\n",
       " 2.1817944,\n",
       " 2.1817944,\n",
       " 2.1817944,\n",
       " 2.1817944,\n",
       " 2.1817944,\n",
       " 2.1817944,\n",
       " 2.1817944,\n",
       " 2.1817944,\n",
       " 2.1817944,\n",
       " 2.1817944,\n",
       " 2.1817944,\n",
       " 2.1817944,\n",
       " 2.1817944,\n",
       " 2.1817944,\n",
       " 2.1817944,\n",
       " 2.1817944,\n",
       " 2.1817944,\n",
       " 2.3396847,\n",
       " 2.3396847,\n",
       " 2.3396847,\n",
       " 2.3396847,\n",
       " 2.3396847,\n",
       " 2.3396847,\n",
       " 2.3396847,\n",
       " 2.3396847,\n",
       " 2.3396847,\n",
       " 2.3396847,\n",
       " 2.3396847,\n",
       " 2.3396847,\n",
       " 2.3396847,\n",
       " 2.3396847,\n",
       " 2.3396847,\n",
       " 2.3396847,\n",
       " 2.3396847,\n",
       " 2.3396847,\n",
       " 2.3396847,\n",
       " 2.3396847,\n",
       " 2.4898918,\n",
       " 2.4898918,\n",
       " 2.4898918,\n",
       " 2.4898918,\n",
       " 2.4898918,\n",
       " 2.4898918,\n",
       " 2.4898918,\n",
       " 2.4898918,\n",
       " 2.4898918,\n",
       " 2.4898918,\n",
       " 2.4898918,\n",
       " 2.4898918,\n",
       " 2.4898918,\n",
       " 2.4898918,\n",
       " 2.4898918,\n",
       " 2.4898918,\n",
       " 2.4898918,\n",
       " 2.4898918,\n",
       " 2.4898918,\n",
       " 2.4898918]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la_max_all = []\n",
    "for i in range(len(la_max)):\n",
    "    la_max_all.extend([la_max[i]]*20)\n",
    "    \n",
    "la_max_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "bafb453b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.31395432,\n",
       " 0.18303476,\n",
       " 0.11369938,\n",
       " 0.09969959,\n",
       " 0.09637543,\n",
       " 0.09305138,\n",
       " 0.09023982,\n",
       " 0.08984975,\n",
       " 0.09020576,\n",
       " 0.09291993,\n",
       " 0.11609901,\n",
       " 0.3070148,\n",
       " 0.32686746,\n",
       " 0.4082949,\n",
       " 0.4256592,\n",
       " 0.44302332,\n",
       " 0.5064016,\n",
       " 0.6611626,\n",
       " 0.8068545,\n",
       " 0.8638486]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la_min = la_max_min['latency_min'].values\n",
    "la_min = list(la_min)\n",
    "la_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0a7696c1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.31395432,\n",
       " 0.31395432,\n",
       " 0.31395432,\n",
       " 0.31395432,\n",
       " 0.31395432,\n",
       " 0.31395432,\n",
       " 0.31395432,\n",
       " 0.31395432,\n",
       " 0.31395432,\n",
       " 0.31395432,\n",
       " 0.31395432,\n",
       " 0.31395432,\n",
       " 0.31395432,\n",
       " 0.31395432,\n",
       " 0.31395432,\n",
       " 0.31395432,\n",
       " 0.31395432,\n",
       " 0.31395432,\n",
       " 0.31395432,\n",
       " 0.31395432,\n",
       " 0.18303476,\n",
       " 0.18303476,\n",
       " 0.18303476,\n",
       " 0.18303476,\n",
       " 0.18303476,\n",
       " 0.18303476,\n",
       " 0.18303476,\n",
       " 0.18303476,\n",
       " 0.18303476,\n",
       " 0.18303476,\n",
       " 0.18303476,\n",
       " 0.18303476,\n",
       " 0.18303476,\n",
       " 0.18303476,\n",
       " 0.18303476,\n",
       " 0.18303476,\n",
       " 0.18303476,\n",
       " 0.18303476,\n",
       " 0.18303476,\n",
       " 0.18303476,\n",
       " 0.11369938,\n",
       " 0.11369938,\n",
       " 0.11369938,\n",
       " 0.11369938,\n",
       " 0.11369938,\n",
       " 0.11369938,\n",
       " 0.11369938,\n",
       " 0.11369938,\n",
       " 0.11369938,\n",
       " 0.11369938,\n",
       " 0.11369938,\n",
       " 0.11369938,\n",
       " 0.11369938,\n",
       " 0.11369938,\n",
       " 0.11369938,\n",
       " 0.11369938,\n",
       " 0.11369938,\n",
       " 0.11369938,\n",
       " 0.11369938,\n",
       " 0.11369938,\n",
       " 0.09969959,\n",
       " 0.09969959,\n",
       " 0.09969959,\n",
       " 0.09969959,\n",
       " 0.09969959,\n",
       " 0.09969959,\n",
       " 0.09969959,\n",
       " 0.09969959,\n",
       " 0.09969959,\n",
       " 0.09969959,\n",
       " 0.09969959,\n",
       " 0.09969959,\n",
       " 0.09969959,\n",
       " 0.09969959,\n",
       " 0.09969959,\n",
       " 0.09969959,\n",
       " 0.09969959,\n",
       " 0.09969959,\n",
       " 0.09969959,\n",
       " 0.09969959,\n",
       " 0.09637543,\n",
       " 0.09637543,\n",
       " 0.09637543,\n",
       " 0.09637543,\n",
       " 0.09637543,\n",
       " 0.09637543,\n",
       " 0.09637543,\n",
       " 0.09637543,\n",
       " 0.09637543,\n",
       " 0.09637543,\n",
       " 0.09637543,\n",
       " 0.09637543,\n",
       " 0.09637543,\n",
       " 0.09637543,\n",
       " 0.09637543,\n",
       " 0.09637543,\n",
       " 0.09637543,\n",
       " 0.09637543,\n",
       " 0.09637543,\n",
       " 0.09637543,\n",
       " 0.09305138,\n",
       " 0.09305138,\n",
       " 0.09305138,\n",
       " 0.09305138,\n",
       " 0.09305138,\n",
       " 0.09305138,\n",
       " 0.09305138,\n",
       " 0.09305138,\n",
       " 0.09305138,\n",
       " 0.09305138,\n",
       " 0.09305138,\n",
       " 0.09305138,\n",
       " 0.09305138,\n",
       " 0.09305138,\n",
       " 0.09305138,\n",
       " 0.09305138,\n",
       " 0.09305138,\n",
       " 0.09305138,\n",
       " 0.09305138,\n",
       " 0.09305138,\n",
       " 0.09023982,\n",
       " 0.09023982,\n",
       " 0.09023982,\n",
       " 0.09023982,\n",
       " 0.09023982,\n",
       " 0.09023982,\n",
       " 0.09023982,\n",
       " 0.09023982,\n",
       " 0.09023982,\n",
       " 0.09023982,\n",
       " 0.09023982,\n",
       " 0.09023982,\n",
       " 0.09023982,\n",
       " 0.09023982,\n",
       " 0.09023982,\n",
       " 0.09023982,\n",
       " 0.09023982,\n",
       " 0.09023982,\n",
       " 0.09023982,\n",
       " 0.09023982,\n",
       " 0.08984975,\n",
       " 0.08984975,\n",
       " 0.08984975,\n",
       " 0.08984975,\n",
       " 0.08984975,\n",
       " 0.08984975,\n",
       " 0.08984975,\n",
       " 0.08984975,\n",
       " 0.08984975,\n",
       " 0.08984975,\n",
       " 0.08984975,\n",
       " 0.08984975,\n",
       " 0.08984975,\n",
       " 0.08984975,\n",
       " 0.08984975,\n",
       " 0.08984975,\n",
       " 0.08984975,\n",
       " 0.08984975,\n",
       " 0.08984975,\n",
       " 0.08984975,\n",
       " 0.09020576,\n",
       " 0.09020576,\n",
       " 0.09020576,\n",
       " 0.09020576,\n",
       " 0.09020576,\n",
       " 0.09020576,\n",
       " 0.09020576,\n",
       " 0.09020576,\n",
       " 0.09020576,\n",
       " 0.09020576,\n",
       " 0.09020576,\n",
       " 0.09020576,\n",
       " 0.09020576,\n",
       " 0.09020576,\n",
       " 0.09020576,\n",
       " 0.09020576,\n",
       " 0.09020576,\n",
       " 0.09020576,\n",
       " 0.09020576,\n",
       " 0.09020576,\n",
       " 0.09291993,\n",
       " 0.09291993,\n",
       " 0.09291993,\n",
       " 0.09291993,\n",
       " 0.09291993,\n",
       " 0.09291993,\n",
       " 0.09291993,\n",
       " 0.09291993,\n",
       " 0.09291993,\n",
       " 0.09291993,\n",
       " 0.09291993,\n",
       " 0.09291993,\n",
       " 0.09291993,\n",
       " 0.09291993,\n",
       " 0.09291993,\n",
       " 0.09291993,\n",
       " 0.09291993,\n",
       " 0.09291993,\n",
       " 0.09291993,\n",
       " 0.09291993,\n",
       " 0.11609901,\n",
       " 0.11609901,\n",
       " 0.11609901,\n",
       " 0.11609901,\n",
       " 0.11609901,\n",
       " 0.11609901,\n",
       " 0.11609901,\n",
       " 0.11609901,\n",
       " 0.11609901,\n",
       " 0.11609901,\n",
       " 0.11609901,\n",
       " 0.11609901,\n",
       " 0.11609901,\n",
       " 0.11609901,\n",
       " 0.11609901,\n",
       " 0.11609901,\n",
       " 0.11609901,\n",
       " 0.11609901,\n",
       " 0.11609901,\n",
       " 0.11609901,\n",
       " 0.3070148,\n",
       " 0.3070148,\n",
       " 0.3070148,\n",
       " 0.3070148,\n",
       " 0.3070148,\n",
       " 0.3070148,\n",
       " 0.3070148,\n",
       " 0.3070148,\n",
       " 0.3070148,\n",
       " 0.3070148,\n",
       " 0.3070148,\n",
       " 0.3070148,\n",
       " 0.3070148,\n",
       " 0.3070148,\n",
       " 0.3070148,\n",
       " 0.3070148,\n",
       " 0.3070148,\n",
       " 0.3070148,\n",
       " 0.3070148,\n",
       " 0.3070148,\n",
       " 0.32686746,\n",
       " 0.32686746,\n",
       " 0.32686746,\n",
       " 0.32686746,\n",
       " 0.32686746,\n",
       " 0.32686746,\n",
       " 0.32686746,\n",
       " 0.32686746,\n",
       " 0.32686746,\n",
       " 0.32686746,\n",
       " 0.32686746,\n",
       " 0.32686746,\n",
       " 0.32686746,\n",
       " 0.32686746,\n",
       " 0.32686746,\n",
       " 0.32686746,\n",
       " 0.32686746,\n",
       " 0.32686746,\n",
       " 0.32686746,\n",
       " 0.32686746,\n",
       " 0.4082949,\n",
       " 0.4082949,\n",
       " 0.4082949,\n",
       " 0.4082949,\n",
       " 0.4082949,\n",
       " 0.4082949,\n",
       " 0.4082949,\n",
       " 0.4082949,\n",
       " 0.4082949,\n",
       " 0.4082949,\n",
       " 0.4082949,\n",
       " 0.4082949,\n",
       " 0.4082949,\n",
       " 0.4082949,\n",
       " 0.4082949,\n",
       " 0.4082949,\n",
       " 0.4082949,\n",
       " 0.4082949,\n",
       " 0.4082949,\n",
       " 0.4082949,\n",
       " 0.4256592,\n",
       " 0.4256592,\n",
       " 0.4256592,\n",
       " 0.4256592,\n",
       " 0.4256592,\n",
       " 0.4256592,\n",
       " 0.4256592,\n",
       " 0.4256592,\n",
       " 0.4256592,\n",
       " 0.4256592,\n",
       " 0.4256592,\n",
       " 0.4256592,\n",
       " 0.4256592,\n",
       " 0.4256592,\n",
       " 0.4256592,\n",
       " 0.4256592,\n",
       " 0.4256592,\n",
       " 0.4256592,\n",
       " 0.4256592,\n",
       " 0.4256592,\n",
       " 0.44302332,\n",
       " 0.44302332,\n",
       " 0.44302332,\n",
       " 0.44302332,\n",
       " 0.44302332,\n",
       " 0.44302332,\n",
       " 0.44302332,\n",
       " 0.44302332,\n",
       " 0.44302332,\n",
       " 0.44302332,\n",
       " 0.44302332,\n",
       " 0.44302332,\n",
       " 0.44302332,\n",
       " 0.44302332,\n",
       " 0.44302332,\n",
       " 0.44302332,\n",
       " 0.44302332,\n",
       " 0.44302332,\n",
       " 0.44302332,\n",
       " 0.44302332,\n",
       " 0.5064016,\n",
       " 0.5064016,\n",
       " 0.5064016,\n",
       " 0.5064016,\n",
       " 0.5064016,\n",
       " 0.5064016,\n",
       " 0.5064016,\n",
       " 0.5064016,\n",
       " 0.5064016,\n",
       " 0.5064016,\n",
       " 0.5064016,\n",
       " 0.5064016,\n",
       " 0.5064016,\n",
       " 0.5064016,\n",
       " 0.5064016,\n",
       " 0.5064016,\n",
       " 0.5064016,\n",
       " 0.5064016,\n",
       " 0.5064016,\n",
       " 0.5064016,\n",
       " 0.6611626,\n",
       " 0.6611626,\n",
       " 0.6611626,\n",
       " 0.6611626,\n",
       " 0.6611626,\n",
       " 0.6611626,\n",
       " 0.6611626,\n",
       " 0.6611626,\n",
       " 0.6611626,\n",
       " 0.6611626,\n",
       " 0.6611626,\n",
       " 0.6611626,\n",
       " 0.6611626,\n",
       " 0.6611626,\n",
       " 0.6611626,\n",
       " 0.6611626,\n",
       " 0.6611626,\n",
       " 0.6611626,\n",
       " 0.6611626,\n",
       " 0.6611626,\n",
       " 0.8068545,\n",
       " 0.8068545,\n",
       " 0.8068545,\n",
       " 0.8068545,\n",
       " 0.8068545,\n",
       " 0.8068545,\n",
       " 0.8068545,\n",
       " 0.8068545,\n",
       " 0.8068545,\n",
       " 0.8068545,\n",
       " 0.8068545,\n",
       " 0.8068545,\n",
       " 0.8068545,\n",
       " 0.8068545,\n",
       " 0.8068545,\n",
       " 0.8068545,\n",
       " 0.8068545,\n",
       " 0.8068545,\n",
       " 0.8068545,\n",
       " 0.8068545,\n",
       " 0.8638486,\n",
       " 0.8638486,\n",
       " 0.8638486,\n",
       " 0.8638486,\n",
       " 0.8638486,\n",
       " 0.8638486,\n",
       " 0.8638486,\n",
       " 0.8638486,\n",
       " 0.8638486,\n",
       " 0.8638486,\n",
       " 0.8638486,\n",
       " 0.8638486,\n",
       " 0.8638486,\n",
       " 0.8638486,\n",
       " 0.8638486,\n",
       " 0.8638486,\n",
       " 0.8638486,\n",
       " 0.8638486,\n",
       " 0.8638486,\n",
       " 0.8638486]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la_min_all = []\n",
    "for i in range(len(la_min)):\n",
    "    la_min_all.extend([la_min[i]]*20)\n",
    "    \n",
    "la_min_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "699e5383",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>send rates</th>\n",
       "      <th>block size</th>\n",
       "      <th>latency_pred</th>\n",
       "      <th>throughput_pred</th>\n",
       "      <th>latency_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.313954</td>\n",
       "      <td>12.571510</td>\n",
       "      <td>0.313954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.820229</td>\n",
       "      <td>12.628407</td>\n",
       "      <td>0.313954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>1.092091</td>\n",
       "      <td>12.685304</td>\n",
       "      <td>0.313954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>1.255364</td>\n",
       "      <td>12.742206</td>\n",
       "      <td>0.313954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>1.405114</td>\n",
       "      <td>12.799105</td>\n",
       "      <td>0.313954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>200</td>\n",
       "      <td>160</td>\n",
       "      <td>1.715595</td>\n",
       "      <td>159.231079</td>\n",
       "      <td>0.863849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>200</td>\n",
       "      <td>170</td>\n",
       "      <td>1.646274</td>\n",
       "      <td>161.011200</td>\n",
       "      <td>0.863849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>200</td>\n",
       "      <td>180</td>\n",
       "      <td>1.592673</td>\n",
       "      <td>162.791321</td>\n",
       "      <td>0.863849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>200</td>\n",
       "      <td>190</td>\n",
       "      <td>1.570900</td>\n",
       "      <td>164.571457</td>\n",
       "      <td>0.863849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>1.548800</td>\n",
       "      <td>166.351593</td>\n",
       "      <td>0.863849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     send rates  block size  latency_pred  throughput_pred  latency_min\n",
       "0            10          10      0.313954        12.571510     0.313954\n",
       "1            10          20      0.820229        12.628407     0.313954\n",
       "2            10          30      1.092091        12.685304     0.313954\n",
       "3            10          40      1.255364        12.742206     0.313954\n",
       "4            10          50      1.405114        12.799105     0.313954\n",
       "..          ...         ...           ...              ...          ...\n",
       "395         200         160      1.715595       159.231079     0.863849\n",
       "396         200         170      1.646274       161.011200     0.863849\n",
       "397         200         180      1.592673       162.791321     0.863849\n",
       "398         200         190      1.570900       164.571457     0.863849\n",
       "399         200         200      1.548800       166.351593     0.863849\n",
       "\n",
       "[400 rows x 5 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['latency_min'] = la_min_all\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ac4576fd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>send rates</th>\n",
       "      <th>block size</th>\n",
       "      <th>latency_pred</th>\n",
       "      <th>throughput_pred</th>\n",
       "      <th>latency_min</th>\n",
       "      <th>latency_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.313954</td>\n",
       "      <td>12.571510</td>\n",
       "      <td>0.313954</td>\n",
       "      <td>1.405114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.820229</td>\n",
       "      <td>12.628407</td>\n",
       "      <td>0.313954</td>\n",
       "      <td>1.405114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>1.092091</td>\n",
       "      <td>12.685304</td>\n",
       "      <td>0.313954</td>\n",
       "      <td>1.405114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>1.255364</td>\n",
       "      <td>12.742206</td>\n",
       "      <td>0.313954</td>\n",
       "      <td>1.405114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>1.405114</td>\n",
       "      <td>12.799105</td>\n",
       "      <td>0.313954</td>\n",
       "      <td>1.405114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>200</td>\n",
       "      <td>160</td>\n",
       "      <td>1.715595</td>\n",
       "      <td>159.231079</td>\n",
       "      <td>0.863849</td>\n",
       "      <td>2.489892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>200</td>\n",
       "      <td>170</td>\n",
       "      <td>1.646274</td>\n",
       "      <td>161.011200</td>\n",
       "      <td>0.863849</td>\n",
       "      <td>2.489892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>200</td>\n",
       "      <td>180</td>\n",
       "      <td>1.592673</td>\n",
       "      <td>162.791321</td>\n",
       "      <td>0.863849</td>\n",
       "      <td>2.489892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>200</td>\n",
       "      <td>190</td>\n",
       "      <td>1.570900</td>\n",
       "      <td>164.571457</td>\n",
       "      <td>0.863849</td>\n",
       "      <td>2.489892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>1.548800</td>\n",
       "      <td>166.351593</td>\n",
       "      <td>0.863849</td>\n",
       "      <td>2.489892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     send rates  block size  latency_pred  throughput_pred  latency_min  \\\n",
       "0            10          10      0.313954        12.571510     0.313954   \n",
       "1            10          20      0.820229        12.628407     0.313954   \n",
       "2            10          30      1.092091        12.685304     0.313954   \n",
       "3            10          40      1.255364        12.742206     0.313954   \n",
       "4            10          50      1.405114        12.799105     0.313954   \n",
       "..          ...         ...           ...              ...          ...   \n",
       "395         200         160      1.715595       159.231079     0.863849   \n",
       "396         200         170      1.646274       161.011200     0.863849   \n",
       "397         200         180      1.592673       162.791321     0.863849   \n",
       "398         200         190      1.570900       164.571457     0.863849   \n",
       "399         200         200      1.548800       166.351593     0.863849   \n",
       "\n",
       "     latency_max  \n",
       "0       1.405114  \n",
       "1       1.405114  \n",
       "2       1.405114  \n",
       "3       1.405114  \n",
       "4       1.405114  \n",
       "..           ...  \n",
       "395     2.489892  \n",
       "396     2.489892  \n",
       "397     2.489892  \n",
       "398     2.489892  \n",
       "399     2.489892  \n",
       "\n",
       "[400 rows x 6 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['latency_max'] = la_max_all\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2cdd600f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13.652584,\n",
       " 21.824415,\n",
       " 29.996248,\n",
       " 38.168083,\n",
       " 46.339912,\n",
       " 54.511738,\n",
       " 62.683575,\n",
       " 70.85541,\n",
       " 79.027245,\n",
       " 87.19907,\n",
       " 95.370895,\n",
       " 103.542725,\n",
       " 111.71457,\n",
       " 119.88638,\n",
       " 128.05823,\n",
       " 136.23006,\n",
       " 144.40189,\n",
       " 152.57373,\n",
       " 160.74557,\n",
       " 166.3516]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th_max = th_max_min['throughput_max'].values\n",
    "th_max = list(th_max)\n",
    "th_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "245d2ead",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13.652584,\n",
       " 13.652584,\n",
       " 13.652584,\n",
       " 13.652584,\n",
       " 13.652584,\n",
       " 13.652584,\n",
       " 13.652584,\n",
       " 13.652584,\n",
       " 13.652584,\n",
       " 13.652584,\n",
       " 13.652584,\n",
       " 13.652584,\n",
       " 13.652584,\n",
       " 13.652584,\n",
       " 13.652584,\n",
       " 13.652584,\n",
       " 13.652584,\n",
       " 13.652584,\n",
       " 13.652584,\n",
       " 13.652584,\n",
       " 21.824415,\n",
       " 21.824415,\n",
       " 21.824415,\n",
       " 21.824415,\n",
       " 21.824415,\n",
       " 21.824415,\n",
       " 21.824415,\n",
       " 21.824415,\n",
       " 21.824415,\n",
       " 21.824415,\n",
       " 21.824415,\n",
       " 21.824415,\n",
       " 21.824415,\n",
       " 21.824415,\n",
       " 21.824415,\n",
       " 21.824415,\n",
       " 21.824415,\n",
       " 21.824415,\n",
       " 21.824415,\n",
       " 21.824415,\n",
       " 29.996248,\n",
       " 29.996248,\n",
       " 29.996248,\n",
       " 29.996248,\n",
       " 29.996248,\n",
       " 29.996248,\n",
       " 29.996248,\n",
       " 29.996248,\n",
       " 29.996248,\n",
       " 29.996248,\n",
       " 29.996248,\n",
       " 29.996248,\n",
       " 29.996248,\n",
       " 29.996248,\n",
       " 29.996248,\n",
       " 29.996248,\n",
       " 29.996248,\n",
       " 29.996248,\n",
       " 29.996248,\n",
       " 29.996248,\n",
       " 38.168083,\n",
       " 38.168083,\n",
       " 38.168083,\n",
       " 38.168083,\n",
       " 38.168083,\n",
       " 38.168083,\n",
       " 38.168083,\n",
       " 38.168083,\n",
       " 38.168083,\n",
       " 38.168083,\n",
       " 38.168083,\n",
       " 38.168083,\n",
       " 38.168083,\n",
       " 38.168083,\n",
       " 38.168083,\n",
       " 38.168083,\n",
       " 38.168083,\n",
       " 38.168083,\n",
       " 38.168083,\n",
       " 38.168083,\n",
       " 46.339912,\n",
       " 46.339912,\n",
       " 46.339912,\n",
       " 46.339912,\n",
       " 46.339912,\n",
       " 46.339912,\n",
       " 46.339912,\n",
       " 46.339912,\n",
       " 46.339912,\n",
       " 46.339912,\n",
       " 46.339912,\n",
       " 46.339912,\n",
       " 46.339912,\n",
       " 46.339912,\n",
       " 46.339912,\n",
       " 46.339912,\n",
       " 46.339912,\n",
       " 46.339912,\n",
       " 46.339912,\n",
       " 46.339912,\n",
       " 54.511738,\n",
       " 54.511738,\n",
       " 54.511738,\n",
       " 54.511738,\n",
       " 54.511738,\n",
       " 54.511738,\n",
       " 54.511738,\n",
       " 54.511738,\n",
       " 54.511738,\n",
       " 54.511738,\n",
       " 54.511738,\n",
       " 54.511738,\n",
       " 54.511738,\n",
       " 54.511738,\n",
       " 54.511738,\n",
       " 54.511738,\n",
       " 54.511738,\n",
       " 54.511738,\n",
       " 54.511738,\n",
       " 54.511738,\n",
       " 62.683575,\n",
       " 62.683575,\n",
       " 62.683575,\n",
       " 62.683575,\n",
       " 62.683575,\n",
       " 62.683575,\n",
       " 62.683575,\n",
       " 62.683575,\n",
       " 62.683575,\n",
       " 62.683575,\n",
       " 62.683575,\n",
       " 62.683575,\n",
       " 62.683575,\n",
       " 62.683575,\n",
       " 62.683575,\n",
       " 62.683575,\n",
       " 62.683575,\n",
       " 62.683575,\n",
       " 62.683575,\n",
       " 62.683575,\n",
       " 70.85541,\n",
       " 70.85541,\n",
       " 70.85541,\n",
       " 70.85541,\n",
       " 70.85541,\n",
       " 70.85541,\n",
       " 70.85541,\n",
       " 70.85541,\n",
       " 70.85541,\n",
       " 70.85541,\n",
       " 70.85541,\n",
       " 70.85541,\n",
       " 70.85541,\n",
       " 70.85541,\n",
       " 70.85541,\n",
       " 70.85541,\n",
       " 70.85541,\n",
       " 70.85541,\n",
       " 70.85541,\n",
       " 70.85541,\n",
       " 79.027245,\n",
       " 79.027245,\n",
       " 79.027245,\n",
       " 79.027245,\n",
       " 79.027245,\n",
       " 79.027245,\n",
       " 79.027245,\n",
       " 79.027245,\n",
       " 79.027245,\n",
       " 79.027245,\n",
       " 79.027245,\n",
       " 79.027245,\n",
       " 79.027245,\n",
       " 79.027245,\n",
       " 79.027245,\n",
       " 79.027245,\n",
       " 79.027245,\n",
       " 79.027245,\n",
       " 79.027245,\n",
       " 79.027245,\n",
       " 87.19907,\n",
       " 87.19907,\n",
       " 87.19907,\n",
       " 87.19907,\n",
       " 87.19907,\n",
       " 87.19907,\n",
       " 87.19907,\n",
       " 87.19907,\n",
       " 87.19907,\n",
       " 87.19907,\n",
       " 87.19907,\n",
       " 87.19907,\n",
       " 87.19907,\n",
       " 87.19907,\n",
       " 87.19907,\n",
       " 87.19907,\n",
       " 87.19907,\n",
       " 87.19907,\n",
       " 87.19907,\n",
       " 87.19907,\n",
       " 95.370895,\n",
       " 95.370895,\n",
       " 95.370895,\n",
       " 95.370895,\n",
       " 95.370895,\n",
       " 95.370895,\n",
       " 95.370895,\n",
       " 95.370895,\n",
       " 95.370895,\n",
       " 95.370895,\n",
       " 95.370895,\n",
       " 95.370895,\n",
       " 95.370895,\n",
       " 95.370895,\n",
       " 95.370895,\n",
       " 95.370895,\n",
       " 95.370895,\n",
       " 95.370895,\n",
       " 95.370895,\n",
       " 95.370895,\n",
       " 103.542725,\n",
       " 103.542725,\n",
       " 103.542725,\n",
       " 103.542725,\n",
       " 103.542725,\n",
       " 103.542725,\n",
       " 103.542725,\n",
       " 103.542725,\n",
       " 103.542725,\n",
       " 103.542725,\n",
       " 103.542725,\n",
       " 103.542725,\n",
       " 103.542725,\n",
       " 103.542725,\n",
       " 103.542725,\n",
       " 103.542725,\n",
       " 103.542725,\n",
       " 103.542725,\n",
       " 103.542725,\n",
       " 103.542725,\n",
       " 111.71457,\n",
       " 111.71457,\n",
       " 111.71457,\n",
       " 111.71457,\n",
       " 111.71457,\n",
       " 111.71457,\n",
       " 111.71457,\n",
       " 111.71457,\n",
       " 111.71457,\n",
       " 111.71457,\n",
       " 111.71457,\n",
       " 111.71457,\n",
       " 111.71457,\n",
       " 111.71457,\n",
       " 111.71457,\n",
       " 111.71457,\n",
       " 111.71457,\n",
       " 111.71457,\n",
       " 111.71457,\n",
       " 111.71457,\n",
       " 119.88638,\n",
       " 119.88638,\n",
       " 119.88638,\n",
       " 119.88638,\n",
       " 119.88638,\n",
       " 119.88638,\n",
       " 119.88638,\n",
       " 119.88638,\n",
       " 119.88638,\n",
       " 119.88638,\n",
       " 119.88638,\n",
       " 119.88638,\n",
       " 119.88638,\n",
       " 119.88638,\n",
       " 119.88638,\n",
       " 119.88638,\n",
       " 119.88638,\n",
       " 119.88638,\n",
       " 119.88638,\n",
       " 119.88638,\n",
       " 128.05823,\n",
       " 128.05823,\n",
       " 128.05823,\n",
       " 128.05823,\n",
       " 128.05823,\n",
       " 128.05823,\n",
       " 128.05823,\n",
       " 128.05823,\n",
       " 128.05823,\n",
       " 128.05823,\n",
       " 128.05823,\n",
       " 128.05823,\n",
       " 128.05823,\n",
       " 128.05823,\n",
       " 128.05823,\n",
       " 128.05823,\n",
       " 128.05823,\n",
       " 128.05823,\n",
       " 128.05823,\n",
       " 128.05823,\n",
       " 136.23006,\n",
       " 136.23006,\n",
       " 136.23006,\n",
       " 136.23006,\n",
       " 136.23006,\n",
       " 136.23006,\n",
       " 136.23006,\n",
       " 136.23006,\n",
       " 136.23006,\n",
       " 136.23006,\n",
       " 136.23006,\n",
       " 136.23006,\n",
       " 136.23006,\n",
       " 136.23006,\n",
       " 136.23006,\n",
       " 136.23006,\n",
       " 136.23006,\n",
       " 136.23006,\n",
       " 136.23006,\n",
       " 136.23006,\n",
       " 144.40189,\n",
       " 144.40189,\n",
       " 144.40189,\n",
       " 144.40189,\n",
       " 144.40189,\n",
       " 144.40189,\n",
       " 144.40189,\n",
       " 144.40189,\n",
       " 144.40189,\n",
       " 144.40189,\n",
       " 144.40189,\n",
       " 144.40189,\n",
       " 144.40189,\n",
       " 144.40189,\n",
       " 144.40189,\n",
       " 144.40189,\n",
       " 144.40189,\n",
       " 144.40189,\n",
       " 144.40189,\n",
       " 144.40189,\n",
       " 152.57373,\n",
       " 152.57373,\n",
       " 152.57373,\n",
       " 152.57373,\n",
       " 152.57373,\n",
       " 152.57373,\n",
       " 152.57373,\n",
       " 152.57373,\n",
       " 152.57373,\n",
       " 152.57373,\n",
       " 152.57373,\n",
       " 152.57373,\n",
       " 152.57373,\n",
       " 152.57373,\n",
       " 152.57373,\n",
       " 152.57373,\n",
       " 152.57373,\n",
       " 152.57373,\n",
       " 152.57373,\n",
       " 152.57373,\n",
       " 160.74557,\n",
       " 160.74557,\n",
       " 160.74557,\n",
       " 160.74557,\n",
       " 160.74557,\n",
       " 160.74557,\n",
       " 160.74557,\n",
       " 160.74557,\n",
       " 160.74557,\n",
       " 160.74557,\n",
       " 160.74557,\n",
       " 160.74557,\n",
       " 160.74557,\n",
       " 160.74557,\n",
       " 160.74557,\n",
       " 160.74557,\n",
       " 160.74557,\n",
       " 160.74557,\n",
       " 160.74557,\n",
       " 160.74557,\n",
       " 166.3516,\n",
       " 166.3516,\n",
       " 166.3516,\n",
       " 166.3516,\n",
       " 166.3516,\n",
       " 166.3516,\n",
       " 166.3516,\n",
       " 166.3516,\n",
       " 166.3516,\n",
       " 166.3516,\n",
       " 166.3516,\n",
       " 166.3516,\n",
       " 166.3516,\n",
       " 166.3516,\n",
       " 166.3516,\n",
       " 166.3516,\n",
       " 166.3516,\n",
       " 166.3516,\n",
       " 166.3516,\n",
       " 166.3516]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th_max_all = []\n",
    "for i in range(len(th_max)):\n",
    "    th_max_all.extend([th_max[i]] * 20)\n",
    "    \n",
    "th_max_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "60d226b5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12.57151,\n",
       " 20.743341,\n",
       " 28.91517,\n",
       " 37.087006,\n",
       " 45.25883,\n",
       " 53.430668,\n",
       " 61.602497,\n",
       " 69.77434,\n",
       " 77.94616,\n",
       " 86.11799,\n",
       " 92.969315,\n",
       " 97.36485,\n",
       " 101.76039,\n",
       " 106.15594,\n",
       " 110.55147,\n",
       " 114.947014,\n",
       " 119.342545,\n",
       " 123.738075,\n",
       " 128.13348,\n",
       " 132.52527]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th_min = th_max_min['throughput_min'].values\n",
    "th_min = list(th_min)\n",
    "th_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a7379b58",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12.57151,\n",
       " 12.57151,\n",
       " 12.57151,\n",
       " 12.57151,\n",
       " 12.57151,\n",
       " 12.57151,\n",
       " 12.57151,\n",
       " 12.57151,\n",
       " 12.57151,\n",
       " 12.57151,\n",
       " 12.57151,\n",
       " 12.57151,\n",
       " 12.57151,\n",
       " 12.57151,\n",
       " 12.57151,\n",
       " 12.57151,\n",
       " 12.57151,\n",
       " 12.57151,\n",
       " 12.57151,\n",
       " 12.57151,\n",
       " 20.743341,\n",
       " 20.743341,\n",
       " 20.743341,\n",
       " 20.743341,\n",
       " 20.743341,\n",
       " 20.743341,\n",
       " 20.743341,\n",
       " 20.743341,\n",
       " 20.743341,\n",
       " 20.743341,\n",
       " 20.743341,\n",
       " 20.743341,\n",
       " 20.743341,\n",
       " 20.743341,\n",
       " 20.743341,\n",
       " 20.743341,\n",
       " 20.743341,\n",
       " 20.743341,\n",
       " 20.743341,\n",
       " 20.743341,\n",
       " 28.91517,\n",
       " 28.91517,\n",
       " 28.91517,\n",
       " 28.91517,\n",
       " 28.91517,\n",
       " 28.91517,\n",
       " 28.91517,\n",
       " 28.91517,\n",
       " 28.91517,\n",
       " 28.91517,\n",
       " 28.91517,\n",
       " 28.91517,\n",
       " 28.91517,\n",
       " 28.91517,\n",
       " 28.91517,\n",
       " 28.91517,\n",
       " 28.91517,\n",
       " 28.91517,\n",
       " 28.91517,\n",
       " 28.91517,\n",
       " 37.087006,\n",
       " 37.087006,\n",
       " 37.087006,\n",
       " 37.087006,\n",
       " 37.087006,\n",
       " 37.087006,\n",
       " 37.087006,\n",
       " 37.087006,\n",
       " 37.087006,\n",
       " 37.087006,\n",
       " 37.087006,\n",
       " 37.087006,\n",
       " 37.087006,\n",
       " 37.087006,\n",
       " 37.087006,\n",
       " 37.087006,\n",
       " 37.087006,\n",
       " 37.087006,\n",
       " 37.087006,\n",
       " 37.087006,\n",
       " 45.25883,\n",
       " 45.25883,\n",
       " 45.25883,\n",
       " 45.25883,\n",
       " 45.25883,\n",
       " 45.25883,\n",
       " 45.25883,\n",
       " 45.25883,\n",
       " 45.25883,\n",
       " 45.25883,\n",
       " 45.25883,\n",
       " 45.25883,\n",
       " 45.25883,\n",
       " 45.25883,\n",
       " 45.25883,\n",
       " 45.25883,\n",
       " 45.25883,\n",
       " 45.25883,\n",
       " 45.25883,\n",
       " 45.25883,\n",
       " 53.430668,\n",
       " 53.430668,\n",
       " 53.430668,\n",
       " 53.430668,\n",
       " 53.430668,\n",
       " 53.430668,\n",
       " 53.430668,\n",
       " 53.430668,\n",
       " 53.430668,\n",
       " 53.430668,\n",
       " 53.430668,\n",
       " 53.430668,\n",
       " 53.430668,\n",
       " 53.430668,\n",
       " 53.430668,\n",
       " 53.430668,\n",
       " 53.430668,\n",
       " 53.430668,\n",
       " 53.430668,\n",
       " 53.430668,\n",
       " 61.602497,\n",
       " 61.602497,\n",
       " 61.602497,\n",
       " 61.602497,\n",
       " 61.602497,\n",
       " 61.602497,\n",
       " 61.602497,\n",
       " 61.602497,\n",
       " 61.602497,\n",
       " 61.602497,\n",
       " 61.602497,\n",
       " 61.602497,\n",
       " 61.602497,\n",
       " 61.602497,\n",
       " 61.602497,\n",
       " 61.602497,\n",
       " 61.602497,\n",
       " 61.602497,\n",
       " 61.602497,\n",
       " 61.602497,\n",
       " 69.77434,\n",
       " 69.77434,\n",
       " 69.77434,\n",
       " 69.77434,\n",
       " 69.77434,\n",
       " 69.77434,\n",
       " 69.77434,\n",
       " 69.77434,\n",
       " 69.77434,\n",
       " 69.77434,\n",
       " 69.77434,\n",
       " 69.77434,\n",
       " 69.77434,\n",
       " 69.77434,\n",
       " 69.77434,\n",
       " 69.77434,\n",
       " 69.77434,\n",
       " 69.77434,\n",
       " 69.77434,\n",
       " 69.77434,\n",
       " 77.94616,\n",
       " 77.94616,\n",
       " 77.94616,\n",
       " 77.94616,\n",
       " 77.94616,\n",
       " 77.94616,\n",
       " 77.94616,\n",
       " 77.94616,\n",
       " 77.94616,\n",
       " 77.94616,\n",
       " 77.94616,\n",
       " 77.94616,\n",
       " 77.94616,\n",
       " 77.94616,\n",
       " 77.94616,\n",
       " 77.94616,\n",
       " 77.94616,\n",
       " 77.94616,\n",
       " 77.94616,\n",
       " 77.94616,\n",
       " 86.11799,\n",
       " 86.11799,\n",
       " 86.11799,\n",
       " 86.11799,\n",
       " 86.11799,\n",
       " 86.11799,\n",
       " 86.11799,\n",
       " 86.11799,\n",
       " 86.11799,\n",
       " 86.11799,\n",
       " 86.11799,\n",
       " 86.11799,\n",
       " 86.11799,\n",
       " 86.11799,\n",
       " 86.11799,\n",
       " 86.11799,\n",
       " 86.11799,\n",
       " 86.11799,\n",
       " 86.11799,\n",
       " 86.11799,\n",
       " 92.969315,\n",
       " 92.969315,\n",
       " 92.969315,\n",
       " 92.969315,\n",
       " 92.969315,\n",
       " 92.969315,\n",
       " 92.969315,\n",
       " 92.969315,\n",
       " 92.969315,\n",
       " 92.969315,\n",
       " 92.969315,\n",
       " 92.969315,\n",
       " 92.969315,\n",
       " 92.969315,\n",
       " 92.969315,\n",
       " 92.969315,\n",
       " 92.969315,\n",
       " 92.969315,\n",
       " 92.969315,\n",
       " 92.969315,\n",
       " 97.36485,\n",
       " 97.36485,\n",
       " 97.36485,\n",
       " 97.36485,\n",
       " 97.36485,\n",
       " 97.36485,\n",
       " 97.36485,\n",
       " 97.36485,\n",
       " 97.36485,\n",
       " 97.36485,\n",
       " 97.36485,\n",
       " 97.36485,\n",
       " 97.36485,\n",
       " 97.36485,\n",
       " 97.36485,\n",
       " 97.36485,\n",
       " 97.36485,\n",
       " 97.36485,\n",
       " 97.36485,\n",
       " 97.36485,\n",
       " 101.76039,\n",
       " 101.76039,\n",
       " 101.76039,\n",
       " 101.76039,\n",
       " 101.76039,\n",
       " 101.76039,\n",
       " 101.76039,\n",
       " 101.76039,\n",
       " 101.76039,\n",
       " 101.76039,\n",
       " 101.76039,\n",
       " 101.76039,\n",
       " 101.76039,\n",
       " 101.76039,\n",
       " 101.76039,\n",
       " 101.76039,\n",
       " 101.76039,\n",
       " 101.76039,\n",
       " 101.76039,\n",
       " 101.76039,\n",
       " 106.15594,\n",
       " 106.15594,\n",
       " 106.15594,\n",
       " 106.15594,\n",
       " 106.15594,\n",
       " 106.15594,\n",
       " 106.15594,\n",
       " 106.15594,\n",
       " 106.15594,\n",
       " 106.15594,\n",
       " 106.15594,\n",
       " 106.15594,\n",
       " 106.15594,\n",
       " 106.15594,\n",
       " 106.15594,\n",
       " 106.15594,\n",
       " 106.15594,\n",
       " 106.15594,\n",
       " 106.15594,\n",
       " 106.15594,\n",
       " 110.55147,\n",
       " 110.55147,\n",
       " 110.55147,\n",
       " 110.55147,\n",
       " 110.55147,\n",
       " 110.55147,\n",
       " 110.55147,\n",
       " 110.55147,\n",
       " 110.55147,\n",
       " 110.55147,\n",
       " 110.55147,\n",
       " 110.55147,\n",
       " 110.55147,\n",
       " 110.55147,\n",
       " 110.55147,\n",
       " 110.55147,\n",
       " 110.55147,\n",
       " 110.55147,\n",
       " 110.55147,\n",
       " 110.55147,\n",
       " 114.947014,\n",
       " 114.947014,\n",
       " 114.947014,\n",
       " 114.947014,\n",
       " 114.947014,\n",
       " 114.947014,\n",
       " 114.947014,\n",
       " 114.947014,\n",
       " 114.947014,\n",
       " 114.947014,\n",
       " 114.947014,\n",
       " 114.947014,\n",
       " 114.947014,\n",
       " 114.947014,\n",
       " 114.947014,\n",
       " 114.947014,\n",
       " 114.947014,\n",
       " 114.947014,\n",
       " 114.947014,\n",
       " 114.947014,\n",
       " 119.342545,\n",
       " 119.342545,\n",
       " 119.342545,\n",
       " 119.342545,\n",
       " 119.342545,\n",
       " 119.342545,\n",
       " 119.342545,\n",
       " 119.342545,\n",
       " 119.342545,\n",
       " 119.342545,\n",
       " 119.342545,\n",
       " 119.342545,\n",
       " 119.342545,\n",
       " 119.342545,\n",
       " 119.342545,\n",
       " 119.342545,\n",
       " 119.342545,\n",
       " 119.342545,\n",
       " 119.342545,\n",
       " 119.342545,\n",
       " 123.738075,\n",
       " 123.738075,\n",
       " 123.738075,\n",
       " 123.738075,\n",
       " 123.738075,\n",
       " 123.738075,\n",
       " 123.738075,\n",
       " 123.738075,\n",
       " 123.738075,\n",
       " 123.738075,\n",
       " 123.738075,\n",
       " 123.738075,\n",
       " 123.738075,\n",
       " 123.738075,\n",
       " 123.738075,\n",
       " 123.738075,\n",
       " 123.738075,\n",
       " 123.738075,\n",
       " 123.738075,\n",
       " 123.738075,\n",
       " 128.13348,\n",
       " 128.13348,\n",
       " 128.13348,\n",
       " 128.13348,\n",
       " 128.13348,\n",
       " 128.13348,\n",
       " 128.13348,\n",
       " 128.13348,\n",
       " 128.13348,\n",
       " 128.13348,\n",
       " 128.13348,\n",
       " 128.13348,\n",
       " 128.13348,\n",
       " 128.13348,\n",
       " 128.13348,\n",
       " 128.13348,\n",
       " 128.13348,\n",
       " 128.13348,\n",
       " 128.13348,\n",
       " 128.13348,\n",
       " 132.52527,\n",
       " 132.52527,\n",
       " 132.52527,\n",
       " 132.52527,\n",
       " 132.52527,\n",
       " 132.52527,\n",
       " 132.52527,\n",
       " 132.52527,\n",
       " 132.52527,\n",
       " 132.52527,\n",
       " 132.52527,\n",
       " 132.52527,\n",
       " 132.52527,\n",
       " 132.52527,\n",
       " 132.52527,\n",
       " 132.52527,\n",
       " 132.52527,\n",
       " 132.52527,\n",
       " 132.52527,\n",
       " 132.52527]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th_min_all = []\n",
    "for i in range(len(th_min)):\n",
    "    th_min_all.extend([th_min[i]] * 20)\n",
    "    \n",
    "th_min_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6486e753",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>send rates</th>\n",
       "      <th>block size</th>\n",
       "      <th>latency_pred</th>\n",
       "      <th>throughput_pred</th>\n",
       "      <th>latency_min</th>\n",
       "      <th>latency_max</th>\n",
       "      <th>throughput_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.313954</td>\n",
       "      <td>12.571510</td>\n",
       "      <td>0.313954</td>\n",
       "      <td>1.405114</td>\n",
       "      <td>12.571510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.820229</td>\n",
       "      <td>12.628407</td>\n",
       "      <td>0.313954</td>\n",
       "      <td>1.405114</td>\n",
       "      <td>12.571510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>1.092091</td>\n",
       "      <td>12.685304</td>\n",
       "      <td>0.313954</td>\n",
       "      <td>1.405114</td>\n",
       "      <td>12.571510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>1.255364</td>\n",
       "      <td>12.742206</td>\n",
       "      <td>0.313954</td>\n",
       "      <td>1.405114</td>\n",
       "      <td>12.571510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>1.405114</td>\n",
       "      <td>12.799105</td>\n",
       "      <td>0.313954</td>\n",
       "      <td>1.405114</td>\n",
       "      <td>12.571510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>200</td>\n",
       "      <td>160</td>\n",
       "      <td>1.715595</td>\n",
       "      <td>159.231079</td>\n",
       "      <td>0.863849</td>\n",
       "      <td>2.489892</td>\n",
       "      <td>132.525269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>200</td>\n",
       "      <td>170</td>\n",
       "      <td>1.646274</td>\n",
       "      <td>161.011200</td>\n",
       "      <td>0.863849</td>\n",
       "      <td>2.489892</td>\n",
       "      <td>132.525269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>200</td>\n",
       "      <td>180</td>\n",
       "      <td>1.592673</td>\n",
       "      <td>162.791321</td>\n",
       "      <td>0.863849</td>\n",
       "      <td>2.489892</td>\n",
       "      <td>132.525269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>200</td>\n",
       "      <td>190</td>\n",
       "      <td>1.570900</td>\n",
       "      <td>164.571457</td>\n",
       "      <td>0.863849</td>\n",
       "      <td>2.489892</td>\n",
       "      <td>132.525269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>1.548800</td>\n",
       "      <td>166.351593</td>\n",
       "      <td>0.863849</td>\n",
       "      <td>2.489892</td>\n",
       "      <td>132.525269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     send rates  block size  latency_pred  throughput_pred  latency_min  \\\n",
       "0            10          10      0.313954        12.571510     0.313954   \n",
       "1            10          20      0.820229        12.628407     0.313954   \n",
       "2            10          30      1.092091        12.685304     0.313954   \n",
       "3            10          40      1.255364        12.742206     0.313954   \n",
       "4            10          50      1.405114        12.799105     0.313954   \n",
       "..          ...         ...           ...              ...          ...   \n",
       "395         200         160      1.715595       159.231079     0.863849   \n",
       "396         200         170      1.646274       161.011200     0.863849   \n",
       "397         200         180      1.592673       162.791321     0.863849   \n",
       "398         200         190      1.570900       164.571457     0.863849   \n",
       "399         200         200      1.548800       166.351593     0.863849   \n",
       "\n",
       "     latency_max  throughput_min  \n",
       "0       1.405114       12.571510  \n",
       "1       1.405114       12.571510  \n",
       "2       1.405114       12.571510  \n",
       "3       1.405114       12.571510  \n",
       "4       1.405114       12.571510  \n",
       "..           ...             ...  \n",
       "395     2.489892      132.525269  \n",
       "396     2.489892      132.525269  \n",
       "397     2.489892      132.525269  \n",
       "398     2.489892      132.525269  \n",
       "399     2.489892      132.525269  \n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['throughput_min'] = th_min_all\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "bf9a17c1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>send rates</th>\n",
       "      <th>block size</th>\n",
       "      <th>latency_pred</th>\n",
       "      <th>throughput_pred</th>\n",
       "      <th>latency_min</th>\n",
       "      <th>latency_max</th>\n",
       "      <th>throughput_min</th>\n",
       "      <th>throughput_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.313954</td>\n",
       "      <td>12.571510</td>\n",
       "      <td>0.313954</td>\n",
       "      <td>1.405114</td>\n",
       "      <td>12.571510</td>\n",
       "      <td>13.652584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.820229</td>\n",
       "      <td>12.628407</td>\n",
       "      <td>0.313954</td>\n",
       "      <td>1.405114</td>\n",
       "      <td>12.571510</td>\n",
       "      <td>13.652584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>1.092091</td>\n",
       "      <td>12.685304</td>\n",
       "      <td>0.313954</td>\n",
       "      <td>1.405114</td>\n",
       "      <td>12.571510</td>\n",
       "      <td>13.652584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>1.255364</td>\n",
       "      <td>12.742206</td>\n",
       "      <td>0.313954</td>\n",
       "      <td>1.405114</td>\n",
       "      <td>12.571510</td>\n",
       "      <td>13.652584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>1.405114</td>\n",
       "      <td>12.799105</td>\n",
       "      <td>0.313954</td>\n",
       "      <td>1.405114</td>\n",
       "      <td>12.571510</td>\n",
       "      <td>13.652584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>200</td>\n",
       "      <td>160</td>\n",
       "      <td>1.715595</td>\n",
       "      <td>159.231079</td>\n",
       "      <td>0.863849</td>\n",
       "      <td>2.489892</td>\n",
       "      <td>132.525269</td>\n",
       "      <td>166.351593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>200</td>\n",
       "      <td>170</td>\n",
       "      <td>1.646274</td>\n",
       "      <td>161.011200</td>\n",
       "      <td>0.863849</td>\n",
       "      <td>2.489892</td>\n",
       "      <td>132.525269</td>\n",
       "      <td>166.351593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>200</td>\n",
       "      <td>180</td>\n",
       "      <td>1.592673</td>\n",
       "      <td>162.791321</td>\n",
       "      <td>0.863849</td>\n",
       "      <td>2.489892</td>\n",
       "      <td>132.525269</td>\n",
       "      <td>166.351593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>200</td>\n",
       "      <td>190</td>\n",
       "      <td>1.570900</td>\n",
       "      <td>164.571457</td>\n",
       "      <td>0.863849</td>\n",
       "      <td>2.489892</td>\n",
       "      <td>132.525269</td>\n",
       "      <td>166.351593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>1.548800</td>\n",
       "      <td>166.351593</td>\n",
       "      <td>0.863849</td>\n",
       "      <td>2.489892</td>\n",
       "      <td>132.525269</td>\n",
       "      <td>166.351593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     send rates  block size  latency_pred  throughput_pred  latency_min  \\\n",
       "0            10          10      0.313954        12.571510     0.313954   \n",
       "1            10          20      0.820229        12.628407     0.313954   \n",
       "2            10          30      1.092091        12.685304     0.313954   \n",
       "3            10          40      1.255364        12.742206     0.313954   \n",
       "4            10          50      1.405114        12.799105     0.313954   \n",
       "..          ...         ...           ...              ...          ...   \n",
       "395         200         160      1.715595       159.231079     0.863849   \n",
       "396         200         170      1.646274       161.011200     0.863849   \n",
       "397         200         180      1.592673       162.791321     0.863849   \n",
       "398         200         190      1.570900       164.571457     0.863849   \n",
       "399         200         200      1.548800       166.351593     0.863849   \n",
       "\n",
       "     latency_max  throughput_min  throughput_max  \n",
       "0       1.405114       12.571510       13.652584  \n",
       "1       1.405114       12.571510       13.652584  \n",
       "2       1.405114       12.571510       13.652584  \n",
       "3       1.405114       12.571510       13.652584  \n",
       "4       1.405114       12.571510       13.652584  \n",
       "..           ...             ...             ...  \n",
       "395     2.489892      132.525269      166.351593  \n",
       "396     2.489892      132.525269      166.351593  \n",
       "397     2.489892      132.525269      166.351593  \n",
       "398     2.489892      132.525269      166.351593  \n",
       "399     2.489892      132.525269      166.351593  \n",
       "\n",
       "[400 rows x 8 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['throughput_max'] = th_max_all\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9c476a4c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y.to_csv('./latency_throughput_pred_max_min_related1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5872265",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### choose different weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "cba07a41",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>send rates</th>\n",
       "      <th>block size</th>\n",
       "      <th>latency_pred</th>\n",
       "      <th>throughput_pred</th>\n",
       "      <th>latency_min</th>\n",
       "      <th>latency_max</th>\n",
       "      <th>throughput_min</th>\n",
       "      <th>throughput_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.313954</td>\n",
       "      <td>12.571510</td>\n",
       "      <td>0.313954</td>\n",
       "      <td>1.405114</td>\n",
       "      <td>12.57151</td>\n",
       "      <td>13.652584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.820229</td>\n",
       "      <td>12.628407</td>\n",
       "      <td>0.313954</td>\n",
       "      <td>1.405114</td>\n",
       "      <td>12.57151</td>\n",
       "      <td>13.652584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>1.092091</td>\n",
       "      <td>12.685304</td>\n",
       "      <td>0.313954</td>\n",
       "      <td>1.405114</td>\n",
       "      <td>12.57151</td>\n",
       "      <td>13.652584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>1.255364</td>\n",
       "      <td>12.742206</td>\n",
       "      <td>0.313954</td>\n",
       "      <td>1.405114</td>\n",
       "      <td>12.57151</td>\n",
       "      <td>13.652584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>1.405114</td>\n",
       "      <td>12.799105</td>\n",
       "      <td>0.313954</td>\n",
       "      <td>1.405114</td>\n",
       "      <td>12.57151</td>\n",
       "      <td>13.652584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>395</td>\n",
       "      <td>200</td>\n",
       "      <td>160</td>\n",
       "      <td>1.715595</td>\n",
       "      <td>159.231080</td>\n",
       "      <td>0.863849</td>\n",
       "      <td>2.489892</td>\n",
       "      <td>132.52527</td>\n",
       "      <td>166.351600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>396</td>\n",
       "      <td>200</td>\n",
       "      <td>170</td>\n",
       "      <td>1.646274</td>\n",
       "      <td>161.011200</td>\n",
       "      <td>0.863849</td>\n",
       "      <td>2.489892</td>\n",
       "      <td>132.52527</td>\n",
       "      <td>166.351600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>397</td>\n",
       "      <td>200</td>\n",
       "      <td>180</td>\n",
       "      <td>1.592673</td>\n",
       "      <td>162.791320</td>\n",
       "      <td>0.863849</td>\n",
       "      <td>2.489892</td>\n",
       "      <td>132.52527</td>\n",
       "      <td>166.351600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>398</td>\n",
       "      <td>200</td>\n",
       "      <td>190</td>\n",
       "      <td>1.570900</td>\n",
       "      <td>164.571460</td>\n",
       "      <td>0.863849</td>\n",
       "      <td>2.489892</td>\n",
       "      <td>132.52527</td>\n",
       "      <td>166.351600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>399</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>1.548800</td>\n",
       "      <td>166.351600</td>\n",
       "      <td>0.863849</td>\n",
       "      <td>2.489892</td>\n",
       "      <td>132.52527</td>\n",
       "      <td>166.351600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  send rates  block size  latency_pred  throughput_pred  \\\n",
       "0             0          10          10      0.313954        12.571510   \n",
       "1             1          10          20      0.820229        12.628407   \n",
       "2             2          10          30      1.092091        12.685304   \n",
       "3             3          10          40      1.255364        12.742206   \n",
       "4             4          10          50      1.405114        12.799105   \n",
       "..          ...         ...         ...           ...              ...   \n",
       "395         395         200         160      1.715595       159.231080   \n",
       "396         396         200         170      1.646274       161.011200   \n",
       "397         397         200         180      1.592673       162.791320   \n",
       "398         398         200         190      1.570900       164.571460   \n",
       "399         399         200         200      1.548800       166.351600   \n",
       "\n",
       "     latency_min  latency_max  throughput_min  throughput_max  \n",
       "0       0.313954     1.405114        12.57151       13.652584  \n",
       "1       0.313954     1.405114        12.57151       13.652584  \n",
       "2       0.313954     1.405114        12.57151       13.652584  \n",
       "3       0.313954     1.405114        12.57151       13.652584  \n",
       "4       0.313954     1.405114        12.57151       13.652584  \n",
       "..           ...          ...             ...             ...  \n",
       "395     0.863849     2.489892       132.52527      166.351600  \n",
       "396     0.863849     2.489892       132.52527      166.351600  \n",
       "397     0.863849     2.489892       132.52527      166.351600  \n",
       "398     0.863849     2.489892       132.52527      166.351600  \n",
       "399     0.863849     2.489892       132.52527      166.351600  \n",
       "\n",
       "[400 rows x 9 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the processed data directly\n",
    "y = pd.read_csv('./latency_throughput_pred_max_min_related1.csv')\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "0ba9d2f0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "beta = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "7984d96d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "latency_score = alpha * ((y['latency_max'] - y['latency_pred']) / (y['latency_max'] - y['latency_min']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "2d42be6e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "throughput_score = beta * ((y['throughput_pred'] - y['throughput_min']) / (y['throughput_max'] - y['throughput_min']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "8cf3cc36",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1       , 0.10096964, 0.12342132, 0.15582929, 0.18947408,\n",
       "       0.23919705, 0.29292144, 0.34743498, 0.40364173, 0.45061277,\n",
       "       0.49758544, 0.54506418, 0.59258503, 0.64009582, 0.68761084,\n",
       "       0.73512583, 0.78264166, 0.83013237, 0.87696139, 0.92374973,\n",
       "       0.1       , 0.11329457, 0.13400128, 0.15911894, 0.19093054,\n",
       "       0.24089647, 0.28499624, 0.33158109, 0.38246714, 0.4294049 ,\n",
       "       0.47633602, 0.52371698, 0.57125094, 0.61877901, 0.66630296,\n",
       "       0.71383691, 0.76136499, 0.80887057, 0.85564514, 0.90195675,\n",
       "       0.1       , 0.1233097 , 0.15533286, 0.1851285 , 0.21640996,\n",
       "       0.25584254, 0.29240697, 0.33868652, 0.38248324, 0.42796894,\n",
       "       0.47492621, 0.52220454, 0.56972169, 0.61724132, 0.66476093,\n",
       "       0.71228559, 0.75980354, 0.80730096, 0.85410733, 0.9       ,\n",
       "       0.1       , 0.13194943, 0.16609086, 0.20268778, 0.23333539,\n",
       "       0.27042973, 0.3072434 , 0.35046334, 0.38715533, 0.43055113,\n",
       "       0.47547211, 0.52264468, 0.57016267, 0.61767818, 0.66519866,\n",
       "       0.71271416, 0.76022887, 0.80772577, 0.85454781, 0.9       ,\n",
       "       0.1       , 0.1344718 , 0.17262398, 0.20995377, 0.23933477,\n",
       "       0.28065779, 0.3203138 , 0.36142564, 0.39653865, 0.43516705,\n",
       "       0.47879805, 0.52273294, 0.56887778, 0.6157914 , 0.66331089,\n",
       "       0.71083041, 0.75834993, 0.80584875, 0.85326537, 0.90082648,\n",
       "       0.1       , 0.13461461, 0.17359305, 0.21448918, 0.24568284,\n",
       "       0.28711235, 0.32846904, 0.37213863, 0.40677975, 0.44063932,\n",
       "       0.48425959, 0.52787793, 0.57212181, 0.61826018, 0.66439269,\n",
       "       0.71053105, 0.7588965 , 0.8090132 , 0.8584438 , 0.90552601,\n",
       "       0.1       , 0.13358162, 0.17270114, 0.21422125, 0.24755686,\n",
       "       0.29008402, 0.33164685, 0.37309892, 0.4122586 , 0.4436281 ,\n",
       "       0.48458538, 0.52795688, 0.57181845, 0.61579285, 0.66451285,\n",
       "       0.71335436, 0.76219756, 0.81102163, 0.85910577, 0.90472579,\n",
       "       0.1       , 0.13167078, 0.17136088, 0.21021501, 0.24696277,\n",
       "       0.28881999, 0.33066057, 0.3714417 , 0.40745491, 0.44504386,\n",
       "       0.47941322, 0.52339267, 0.56981294, 0.61648835, 0.66315548,\n",
       "       0.71191885, 0.76097088, 0.81000406, 0.85819406, 0.90237561,\n",
       "       0.1       , 0.12910775, 0.1694907 , 0.20231428, 0.24233897,\n",
       "       0.28413971, 0.32560753, 0.36521949, 0.39894511, 0.4366978 ,\n",
       "       0.47624014, 0.52407501, 0.57093018, 0.61749144, 0.66404262,\n",
       "       0.71059888, 0.75939207, 0.80868472, 0.85702156, 0.9       ,\n",
       "       0.1       , 0.12421888, 0.1700693 , 0.19566795, 0.24162513,\n",
       "       0.28401775, 0.32555714, 0.36540059, 0.39846144, 0.43723971,\n",
       "       0.47567505, 0.52105395, 0.56996676, 0.61821363, 0.66644381,\n",
       "       0.71467067, 0.76290919, 0.81212266, 0.86034876, 0.90545072,\n",
       "       0.1       , 0.56890675, 0.6167813 , 0.60266467, 0.63627618,\n",
       "       0.65393704, 0.67158966, 0.68410634, 0.68885156, 0.70134515,\n",
       "       0.71383121, 0.7294123 , 0.75216058, 0.77523576, 0.79808616,\n",
       "       0.82012805, 0.84217365, 0.86419424, 0.88531705, 0.90435906,\n",
       "       0.09997051, 0.29105388, 0.61866281, 0.80327271, 0.85509494,\n",
       "       0.86049634, 0.86486349, 0.86064394, 0.84717136, 0.84247811,\n",
       "       0.83957531, 0.83368812, 0.84411319, 0.85699124, 0.86750435,\n",
       "       0.8783955 , 0.88892498, 0.89858592, 0.90521384, 0.90988156,\n",
       "       0.05310306, 0.17414748, 0.42189888, 0.50040172, 0.72168249,\n",
       "       0.88543287, 0.91022537, 0.90383127, 0.88989408, 0.88028388,\n",
       "       0.87492761, 0.86740704, 0.86398926, 0.87551428, 0.88815863,\n",
       "       0.89596406, 0.90344668, 0.91074922, 0.91410153, 0.91349403,\n",
       "       0.03559633, 0.13225881, 0.32296025, 0.35004945, 0.55286915,\n",
       "       0.68341663, 0.79984919, 0.90569087, 0.93246553, 0.92361266,\n",
       "       0.92000512, 0.91363384, 0.90375741, 0.91027629, 0.91827508,\n",
       "       0.92811315, 0.93546545, 0.94088652, 0.94329073, 0.94250895,\n",
       "       0.03247887, 0.11761752, 0.25586964, 0.27454206, 0.449389  ,\n",
       "       0.55757096, 0.64891295, 0.7335928 , 0.8164395 , 0.8998853 ,\n",
       "       0.94632516, 0.94367829, 0.93691829, 0.93706451, 0.94034464,\n",
       "       0.94524978, 0.95136633, 0.95761936, 0.95874518, 0.95830829,\n",
       "       0.02420042, 0.10026166, 0.21115219, 0.22582986, 0.36186235,\n",
       "       0.47638322, 0.55151602, 0.62035654, 0.68705251, 0.75147564,\n",
       "       0.82168168, 0.89283584, 0.94382881, 0.94550971, 0.95145798,\n",
       "       0.95537853, 0.95952308, 0.96457678, 0.96520807, 0.96399124,\n",
       "       0.01887866, 0.08889546, 0.1813565 , 0.19179821, 0.29999181,\n",
       "       0.41883701, 0.4835966 , 0.53783849, 0.59182194, 0.64580648,\n",
       "       0.70373674, 0.7640253 , 0.82431315, 0.88460135, 0.94844194,\n",
       "       0.95621895, 0.96399448, 0.97149314, 0.97166227, 0.97183284,\n",
       "       0.01919493, 0.0840794 , 0.16234082, 0.16668068, 0.25536224,\n",
       "       0.37530632, 0.43336151, 0.47947676, 0.52559232, 0.57170787,\n",
       "       0.62012966, 0.67222968, 0.72433002, 0.77643035, 0.83354241,\n",
       "       0.89454601, 0.95554262, 0.96721679, 0.97178556, 0.97697746,\n",
       "       0.01910456, 0.08200708, 0.15076509, 0.14738301, 0.21837504,\n",
       "       0.33874316, 0.39476216, 0.43368443, 0.47344135, 0.51319799,\n",
       "       0.55381245, 0.59950649, 0.64520112, 0.69089491, 0.73821788,\n",
       "       0.79274371, 0.84681976, 0.89977335, 0.95031945, 0.96888658,\n",
       "       0.01680582, 0.08204823, 0.14435575, 0.14217765, 0.20175961,\n",
       "       0.31681489, 0.38428106, 0.4213447 , 0.45840805, 0.49547168,\n",
       "       0.53253528, 0.57496309, 0.6190902 , 0.66321757, 0.70749325,\n",
       "       0.75816643, 0.8097923 , 0.86045147, 0.90915378, 0.9578762 ])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_score = latency_score.values + throughput_score.values\n",
    "y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e15293db",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y['score'] = y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0b986b97",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y.to_csv('./latency_throughput_score_alpha' + str(alpha) + '_beta' + str(beta) + '_related1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "fd5fe833",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>send rates</th>\n",
       "      <th>block size</th>\n",
       "      <th>latency_pred</th>\n",
       "      <th>throughput_pred</th>\n",
       "      <th>latency_min</th>\n",
       "      <th>latency_max</th>\n",
       "      <th>throughput_min</th>\n",
       "      <th>throughput_max</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.313954</td>\n",
       "      <td>12.571510</td>\n",
       "      <td>0.313954</td>\n",
       "      <td>1.405114</td>\n",
       "      <td>12.57151</td>\n",
       "      <td>13.652584</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.820229</td>\n",
       "      <td>12.628407</td>\n",
       "      <td>0.313954</td>\n",
       "      <td>1.405114</td>\n",
       "      <td>12.57151</td>\n",
       "      <td>13.652584</td>\n",
       "      <td>0.100970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>1.092091</td>\n",
       "      <td>12.685304</td>\n",
       "      <td>0.313954</td>\n",
       "      <td>1.405114</td>\n",
       "      <td>12.57151</td>\n",
       "      <td>13.652584</td>\n",
       "      <td>0.123421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>1.255364</td>\n",
       "      <td>12.742206</td>\n",
       "      <td>0.313954</td>\n",
       "      <td>1.405114</td>\n",
       "      <td>12.57151</td>\n",
       "      <td>13.652584</td>\n",
       "      <td>0.155829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>1.405114</td>\n",
       "      <td>12.799105</td>\n",
       "      <td>0.313954</td>\n",
       "      <td>1.405114</td>\n",
       "      <td>12.57151</td>\n",
       "      <td>13.652584</td>\n",
       "      <td>0.189474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>395</td>\n",
       "      <td>200</td>\n",
       "      <td>160</td>\n",
       "      <td>1.715595</td>\n",
       "      <td>159.231080</td>\n",
       "      <td>0.863849</td>\n",
       "      <td>2.489892</td>\n",
       "      <td>132.52527</td>\n",
       "      <td>166.351600</td>\n",
       "      <td>0.758166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>396</td>\n",
       "      <td>200</td>\n",
       "      <td>170</td>\n",
       "      <td>1.646274</td>\n",
       "      <td>161.011200</td>\n",
       "      <td>0.863849</td>\n",
       "      <td>2.489892</td>\n",
       "      <td>132.52527</td>\n",
       "      <td>166.351600</td>\n",
       "      <td>0.809792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>397</td>\n",
       "      <td>200</td>\n",
       "      <td>180</td>\n",
       "      <td>1.592673</td>\n",
       "      <td>162.791320</td>\n",
       "      <td>0.863849</td>\n",
       "      <td>2.489892</td>\n",
       "      <td>132.52527</td>\n",
       "      <td>166.351600</td>\n",
       "      <td>0.860451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>398</td>\n",
       "      <td>200</td>\n",
       "      <td>190</td>\n",
       "      <td>1.570900</td>\n",
       "      <td>164.571460</td>\n",
       "      <td>0.863849</td>\n",
       "      <td>2.489892</td>\n",
       "      <td>132.52527</td>\n",
       "      <td>166.351600</td>\n",
       "      <td>0.909154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>399</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>1.548800</td>\n",
       "      <td>166.351600</td>\n",
       "      <td>0.863849</td>\n",
       "      <td>2.489892</td>\n",
       "      <td>132.52527</td>\n",
       "      <td>166.351600</td>\n",
       "      <td>0.957876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  send rates  block size  latency_pred  throughput_pred  \\\n",
       "0             0          10          10      0.313954        12.571510   \n",
       "1             1          10          20      0.820229        12.628407   \n",
       "2             2          10          30      1.092091        12.685304   \n",
       "3             3          10          40      1.255364        12.742206   \n",
       "4             4          10          50      1.405114        12.799105   \n",
       "..          ...         ...         ...           ...              ...   \n",
       "395         395         200         160      1.715595       159.231080   \n",
       "396         396         200         170      1.646274       161.011200   \n",
       "397         397         200         180      1.592673       162.791320   \n",
       "398         398         200         190      1.570900       164.571460   \n",
       "399         399         200         200      1.548800       166.351600   \n",
       "\n",
       "     latency_min  latency_max  throughput_min  throughput_max     score  \n",
       "0       0.313954     1.405114        12.57151       13.652584  0.100000  \n",
       "1       0.313954     1.405114        12.57151       13.652584  0.100970  \n",
       "2       0.313954     1.405114        12.57151       13.652584  0.123421  \n",
       "3       0.313954     1.405114        12.57151       13.652584  0.155829  \n",
       "4       0.313954     1.405114        12.57151       13.652584  0.189474  \n",
       "..           ...          ...             ...             ...       ...  \n",
       "395     0.863849     2.489892       132.52527      166.351600  0.758166  \n",
       "396     0.863849     2.489892       132.52527      166.351600  0.809792  \n",
       "397     0.863849     2.489892       132.52527      166.351600  0.860451  \n",
       "398     0.863849     2.489892       132.52527      166.351600  0.909154  \n",
       "399     0.863849     2.489892       132.52527      166.351600  0.957876  \n",
       "\n",
       "[400 rows x 10 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "3986c7c3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for name, group in y_filter.groupby('send rates', sort=False):\n",
    "#     print(name)\n",
    "#     print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "3f885ea1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>send rates</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.957629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.935767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.975530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.959464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.948897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.942622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.937040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.932751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.931587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 max\n",
       "send rates          \n",
       "110         0.900000\n",
       "120         0.957629\n",
       "130         0.935767\n",
       "140         0.975530\n",
       "150         0.959464\n",
       "160         0.948897\n",
       "170         0.942622\n",
       "180         0.937040\n",
       "190         0.932751\n",
       "200         0.931587"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_max = y_filter.groupby('send rates', sort=False)['score'].agg(['max'])\n",
    "score_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "cd9c2cef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>send rates</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.957629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.935767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.975530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.959464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.948897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.942622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.937040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.932751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.931587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            score_max\n",
       "send rates           \n",
       "110          0.900000\n",
       "120          0.957629\n",
       "130          0.935767\n",
       "140          0.975530\n",
       "150          0.959464\n",
       "160          0.948897\n",
       "170          0.942622\n",
       "180          0.937040\n",
       "190          0.932751\n",
       "200          0.931587"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_col=['score_max']\n",
    "score_max.columns = score_col\n",
    "score_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b140c14a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>send rates</th>\n",
       "      <th>score_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120</td>\n",
       "      <td>0.957629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130</td>\n",
       "      <td>0.935767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140</td>\n",
       "      <td>0.975530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150</td>\n",
       "      <td>0.959464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>160</td>\n",
       "      <td>0.948897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>170</td>\n",
       "      <td>0.942622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>180</td>\n",
       "      <td>0.937040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>190</td>\n",
       "      <td>0.932751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>200</td>\n",
       "      <td>0.931587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   send rates  score_max\n",
       "0         110   0.900000\n",
       "1         120   0.957629\n",
       "2         130   0.935767\n",
       "3         140   0.975530\n",
       "4         150   0.959464\n",
       "5         160   0.948897\n",
       "6         170   0.942622\n",
       "7         180   0.937040\n",
       "8         190   0.932751\n",
       "9         200   0.931587"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_max.reset_index(inplace=True)\n",
    "score_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "74a67524",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9,\n",
       " 0.9576292009793012,\n",
       " 0.935766542296804,\n",
       " 0.9755297281665295,\n",
       " 0.9594641954417422,\n",
       " 0.948897047652697,\n",
       " 0.9426218442660812,\n",
       " 0.9370401678061414,\n",
       " 0.9327513508027239,\n",
       " 0.9315867846142339]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_max = score_max['score_max'].values\n",
    "score_max = list(score_max)\n",
    "score_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "caa9ad9b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9576292009793012,\n",
       " 0.9576292009793012,\n",
       " 0.9576292009793012,\n",
       " 0.9576292009793012,\n",
       " 0.9576292009793012,\n",
       " 0.9576292009793012,\n",
       " 0.9576292009793012,\n",
       " 0.9576292009793012,\n",
       " 0.9576292009793012,\n",
       " 0.9576292009793012,\n",
       " 0.9576292009793012,\n",
       " 0.9576292009793012,\n",
       " 0.9576292009793012,\n",
       " 0.9576292009793012,\n",
       " 0.9576292009793012,\n",
       " 0.9576292009793012,\n",
       " 0.9576292009793012,\n",
       " 0.9576292009793012,\n",
       " 0.9576292009793012,\n",
       " 0.9576292009793012,\n",
       " 0.935766542296804,\n",
       " 0.935766542296804,\n",
       " 0.935766542296804,\n",
       " 0.935766542296804,\n",
       " 0.935766542296804,\n",
       " 0.935766542296804,\n",
       " 0.935766542296804,\n",
       " 0.935766542296804,\n",
       " 0.935766542296804,\n",
       " 0.935766542296804,\n",
       " 0.935766542296804,\n",
       " 0.935766542296804,\n",
       " 0.935766542296804,\n",
       " 0.935766542296804,\n",
       " 0.935766542296804,\n",
       " 0.935766542296804,\n",
       " 0.935766542296804,\n",
       " 0.935766542296804,\n",
       " 0.935766542296804,\n",
       " 0.935766542296804,\n",
       " 0.9755297281665295,\n",
       " 0.9755297281665295,\n",
       " 0.9755297281665295,\n",
       " 0.9755297281665295,\n",
       " 0.9755297281665295,\n",
       " 0.9755297281665295,\n",
       " 0.9755297281665295,\n",
       " 0.9755297281665295,\n",
       " 0.9755297281665295,\n",
       " 0.9755297281665295,\n",
       " 0.9755297281665295,\n",
       " 0.9755297281665295,\n",
       " 0.9755297281665295,\n",
       " 0.9755297281665295,\n",
       " 0.9755297281665295,\n",
       " 0.9755297281665295,\n",
       " 0.9755297281665295,\n",
       " 0.9755297281665295,\n",
       " 0.9755297281665295,\n",
       " 0.9755297281665295,\n",
       " 0.9594641954417422,\n",
       " 0.9594641954417422,\n",
       " 0.9594641954417422,\n",
       " 0.9594641954417422,\n",
       " 0.9594641954417422,\n",
       " 0.9594641954417422,\n",
       " 0.9594641954417422,\n",
       " 0.9594641954417422,\n",
       " 0.9594641954417422,\n",
       " 0.9594641954417422,\n",
       " 0.9594641954417422,\n",
       " 0.9594641954417422,\n",
       " 0.9594641954417422,\n",
       " 0.9594641954417422,\n",
       " 0.9594641954417422,\n",
       " 0.9594641954417422,\n",
       " 0.9594641954417422,\n",
       " 0.9594641954417422,\n",
       " 0.9594641954417422,\n",
       " 0.9594641954417422,\n",
       " 0.948897047652697,\n",
       " 0.948897047652697,\n",
       " 0.948897047652697,\n",
       " 0.948897047652697,\n",
       " 0.948897047652697,\n",
       " 0.948897047652697,\n",
       " 0.948897047652697,\n",
       " 0.948897047652697,\n",
       " 0.948897047652697,\n",
       " 0.948897047652697,\n",
       " 0.948897047652697,\n",
       " 0.948897047652697,\n",
       " 0.948897047652697,\n",
       " 0.948897047652697,\n",
       " 0.948897047652697,\n",
       " 0.948897047652697,\n",
       " 0.948897047652697,\n",
       " 0.948897047652697,\n",
       " 0.948897047652697,\n",
       " 0.948897047652697,\n",
       " 0.9426218442660812,\n",
       " 0.9426218442660812,\n",
       " 0.9426218442660812,\n",
       " 0.9426218442660812,\n",
       " 0.9426218442660812,\n",
       " 0.9426218442660812,\n",
       " 0.9426218442660812,\n",
       " 0.9426218442660812,\n",
       " 0.9426218442660812,\n",
       " 0.9426218442660812,\n",
       " 0.9426218442660812,\n",
       " 0.9426218442660812,\n",
       " 0.9426218442660812,\n",
       " 0.9426218442660812,\n",
       " 0.9426218442660812,\n",
       " 0.9426218442660812,\n",
       " 0.9426218442660812,\n",
       " 0.9426218442660812,\n",
       " 0.9426218442660812,\n",
       " 0.9426218442660812,\n",
       " 0.9370401678061414,\n",
       " 0.9370401678061414,\n",
       " 0.9370401678061414,\n",
       " 0.9370401678061414,\n",
       " 0.9370401678061414,\n",
       " 0.9370401678061414,\n",
       " 0.9370401678061414,\n",
       " 0.9370401678061414,\n",
       " 0.9370401678061414,\n",
       " 0.9370401678061414,\n",
       " 0.9370401678061414,\n",
       " 0.9370401678061414,\n",
       " 0.9370401678061414,\n",
       " 0.9370401678061414,\n",
       " 0.9370401678061414,\n",
       " 0.9370401678061414,\n",
       " 0.9370401678061414,\n",
       " 0.9370401678061414,\n",
       " 0.9370401678061414,\n",
       " 0.9370401678061414,\n",
       " 0.9327513508027239,\n",
       " 0.9327513508027239,\n",
       " 0.9327513508027239,\n",
       " 0.9327513508027239,\n",
       " 0.9327513508027239,\n",
       " 0.9327513508027239,\n",
       " 0.9327513508027239,\n",
       " 0.9327513508027239,\n",
       " 0.9327513508027239,\n",
       " 0.9327513508027239,\n",
       " 0.9327513508027239,\n",
       " 0.9327513508027239,\n",
       " 0.9327513508027239,\n",
       " 0.9327513508027239,\n",
       " 0.9327513508027239,\n",
       " 0.9327513508027239,\n",
       " 0.9327513508027239,\n",
       " 0.9327513508027239,\n",
       " 0.9327513508027239,\n",
       " 0.9327513508027239,\n",
       " 0.9315867846142339,\n",
       " 0.9315867846142339,\n",
       " 0.9315867846142339,\n",
       " 0.9315867846142339,\n",
       " 0.9315867846142339,\n",
       " 0.9315867846142339,\n",
       " 0.9315867846142339,\n",
       " 0.9315867846142339,\n",
       " 0.9315867846142339,\n",
       " 0.9315867846142339,\n",
       " 0.9315867846142339,\n",
       " 0.9315867846142339,\n",
       " 0.9315867846142339,\n",
       " 0.9315867846142339,\n",
       " 0.9315867846142339,\n",
       " 0.9315867846142339,\n",
       " 0.9315867846142339,\n",
       " 0.9315867846142339,\n",
       " 0.9315867846142339,\n",
       " 0.9315867846142339]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_max_all = []\n",
    "for i in range(len(score_max)):\n",
    "    score_max_all.extend([score_max[i]] * 20)\n",
    "    \n",
    "score_max_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "59714a97",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cswan\\AppData\\Local\\Temp\\ipykernel_1808\\1654378504.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_filter['score_max'] = score_max_all\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>send rates</th>\n",
       "      <th>block size</th>\n",
       "      <th>latency_pred</th>\n",
       "      <th>throughput_pred</th>\n",
       "      <th>latency_min</th>\n",
       "      <th>latency_max</th>\n",
       "      <th>throughput_min</th>\n",
       "      <th>throughput_max</th>\n",
       "      <th>score</th>\n",
       "      <th>score_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>200</td>\n",
       "      <td>110</td>\n",
       "      <td>10</td>\n",
       "      <td>0.116099</td>\n",
       "      <td>92.969315</td>\n",
       "      <td>0.116099</td>\n",
       "      <td>0.824487</td>\n",
       "      <td>92.969315</td>\n",
       "      <td>95.370895</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>201</td>\n",
       "      <td>110</td>\n",
       "      <td>20</td>\n",
       "      <td>0.451027</td>\n",
       "      <td>94.346720</td>\n",
       "      <td>0.116099</td>\n",
       "      <td>0.824487</td>\n",
       "      <td>92.969315</td>\n",
       "      <td>95.370895</td>\n",
       "      <td>0.531831</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>202</td>\n",
       "      <td>110</td>\n",
       "      <td>30</td>\n",
       "      <td>0.262916</td>\n",
       "      <td>94.403610</td>\n",
       "      <td>0.116099</td>\n",
       "      <td>0.824487</td>\n",
       "      <td>92.969315</td>\n",
       "      <td>95.370895</td>\n",
       "      <td>0.773194</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>203</td>\n",
       "      <td>110</td>\n",
       "      <td>40</td>\n",
       "      <td>0.513995</td>\n",
       "      <td>94.460520</td>\n",
       "      <td>0.116099</td>\n",
       "      <td>0.824487</td>\n",
       "      <td>92.969315</td>\n",
       "      <td>95.370895</td>\n",
       "      <td>0.456569</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>204</td>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>0.426948</td>\n",
       "      <td>94.517420</td>\n",
       "      <td>0.116099</td>\n",
       "      <td>0.824487</td>\n",
       "      <td>92.969315</td>\n",
       "      <td>95.370895</td>\n",
       "      <td>0.569531</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>395</td>\n",
       "      <td>200</td>\n",
       "      <td>160</td>\n",
       "      <td>1.715595</td>\n",
       "      <td>159.231080</td>\n",
       "      <td>0.863849</td>\n",
       "      <td>2.489892</td>\n",
       "      <td>132.525270</td>\n",
       "      <td>166.351600</td>\n",
       "      <td>0.507516</td>\n",
       "      <td>0.931587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>396</td>\n",
       "      <td>200</td>\n",
       "      <td>170</td>\n",
       "      <td>1.646274</td>\n",
       "      <td>161.011200</td>\n",
       "      <td>0.863849</td>\n",
       "      <td>2.489892</td>\n",
       "      <td>132.525270</td>\n",
       "      <td>166.351600</td>\n",
       "      <td>0.551147</td>\n",
       "      <td>0.931587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>397</td>\n",
       "      <td>200</td>\n",
       "      <td>180</td>\n",
       "      <td>1.592673</td>\n",
       "      <td>162.791320</td>\n",
       "      <td>0.863849</td>\n",
       "      <td>2.489892</td>\n",
       "      <td>132.525270</td>\n",
       "      <td>166.351600</td>\n",
       "      <td>0.586077</td>\n",
       "      <td>0.931587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>398</td>\n",
       "      <td>200</td>\n",
       "      <td>190</td>\n",
       "      <td>1.570900</td>\n",
       "      <td>164.571460</td>\n",
       "      <td>0.863849</td>\n",
       "      <td>2.489892</td>\n",
       "      <td>132.525270</td>\n",
       "      <td>166.351600</td>\n",
       "      <td>0.603391</td>\n",
       "      <td>0.931587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>399</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>1.548800</td>\n",
       "      <td>166.351600</td>\n",
       "      <td>0.863849</td>\n",
       "      <td>2.489892</td>\n",
       "      <td>132.525270</td>\n",
       "      <td>166.351600</td>\n",
       "      <td>0.620886</td>\n",
       "      <td>0.931587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  send rates  block size  latency_pred  throughput_pred  \\\n",
       "200         200         110          10      0.116099        92.969315   \n",
       "201         201         110          20      0.451027        94.346720   \n",
       "202         202         110          30      0.262916        94.403610   \n",
       "203         203         110          40      0.513995        94.460520   \n",
       "204         204         110          50      0.426948        94.517420   \n",
       "..          ...         ...         ...           ...              ...   \n",
       "395         395         200         160      1.715595       159.231080   \n",
       "396         396         200         170      1.646274       161.011200   \n",
       "397         397         200         180      1.592673       162.791320   \n",
       "398         398         200         190      1.570900       164.571460   \n",
       "399         399         200         200      1.548800       166.351600   \n",
       "\n",
       "     latency_min  latency_max  throughput_min  throughput_max     score  \\\n",
       "200     0.116099     0.824487       92.969315       95.370895  0.900000   \n",
       "201     0.116099     0.824487       92.969315       95.370895  0.531831   \n",
       "202     0.116099     0.824487       92.969315       95.370895  0.773194   \n",
       "203     0.116099     0.824487       92.969315       95.370895  0.456569   \n",
       "204     0.116099     0.824487       92.969315       95.370895  0.569531   \n",
       "..           ...          ...             ...             ...       ...   \n",
       "395     0.863849     2.489892      132.525270      166.351600  0.507516   \n",
       "396     0.863849     2.489892      132.525270      166.351600  0.551147   \n",
       "397     0.863849     2.489892      132.525270      166.351600  0.586077   \n",
       "398     0.863849     2.489892      132.525270      166.351600  0.603391   \n",
       "399     0.863849     2.489892      132.525270      166.351600  0.620886   \n",
       "\n",
       "     score_max  \n",
       "200   0.900000  \n",
       "201   0.900000  \n",
       "202   0.900000  \n",
       "203   0.900000  \n",
       "204   0.900000  \n",
       "..         ...  \n",
       "395   0.931587  \n",
       "396   0.931587  \n",
       "397   0.931587  \n",
       "398   0.931587  \n",
       "399   0.931587  \n",
       "\n",
       "[200 rows x 11 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_filter['score_max'] = score_max_all\n",
    "y_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d9ace851",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>send rates</th>\n",
       "      <th>block size</th>\n",
       "      <th>latency_pred</th>\n",
       "      <th>throughput_pred</th>\n",
       "      <th>latency_min</th>\n",
       "      <th>latency_max</th>\n",
       "      <th>throughput_min</th>\n",
       "      <th>throughput_max</th>\n",
       "      <th>score</th>\n",
       "      <th>score_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>200</td>\n",
       "      <td>110</td>\n",
       "      <td>10</td>\n",
       "      <td>0.116099</td>\n",
       "      <td>92.969315</td>\n",
       "      <td>0.116099</td>\n",
       "      <td>0.824487</td>\n",
       "      <td>92.969315</td>\n",
       "      <td>95.370895</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>222</td>\n",
       "      <td>120</td>\n",
       "      <td>30</td>\n",
       "      <td>0.307015</td>\n",
       "      <td>100.925110</td>\n",
       "      <td>0.307015</td>\n",
       "      <td>0.866201</td>\n",
       "      <td>97.364850</td>\n",
       "      <td>103.542725</td>\n",
       "      <td>0.957629</td>\n",
       "      <td>0.957629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>242</td>\n",
       "      <td>130</td>\n",
       "      <td>30</td>\n",
       "      <td>0.326867</td>\n",
       "      <td>105.320656</td>\n",
       "      <td>0.326867</td>\n",
       "      <td>0.896848</td>\n",
       "      <td>101.760390</td>\n",
       "      <td>111.714570</td>\n",
       "      <td>0.935767</td>\n",
       "      <td>0.935767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>266</td>\n",
       "      <td>140</td>\n",
       "      <td>70</td>\n",
       "      <td>0.410121</td>\n",
       "      <td>116.836700</td>\n",
       "      <td>0.408295</td>\n",
       "      <td>1.135574</td>\n",
       "      <td>106.155940</td>\n",
       "      <td>119.886380</td>\n",
       "      <td>0.975530</td>\n",
       "      <td>0.975530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>286</td>\n",
       "      <td>150</td>\n",
       "      <td>70</td>\n",
       "      <td>0.427485</td>\n",
       "      <td>121.232240</td>\n",
       "      <td>0.425659</td>\n",
       "      <td>1.488943</td>\n",
       "      <td>110.551470</td>\n",
       "      <td>128.058230</td>\n",
       "      <td>0.959464</td>\n",
       "      <td>0.959464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>306</td>\n",
       "      <td>160</td>\n",
       "      <td>70</td>\n",
       "      <td>0.444849</td>\n",
       "      <td>125.627770</td>\n",
       "      <td>0.443023</td>\n",
       "      <td>1.719399</td>\n",
       "      <td>114.947014</td>\n",
       "      <td>136.230060</td>\n",
       "      <td>0.948897</td>\n",
       "      <td>0.948897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>326</td>\n",
       "      <td>170</td>\n",
       "      <td>70</td>\n",
       "      <td>0.506402</td>\n",
       "      <td>130.023300</td>\n",
       "      <td>0.506402</td>\n",
       "      <td>1.949942</td>\n",
       "      <td>119.342545</td>\n",
       "      <td>144.401890</td>\n",
       "      <td>0.942622</td>\n",
       "      <td>0.942622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>346</td>\n",
       "      <td>180</td>\n",
       "      <td>70</td>\n",
       "      <td>0.661163</td>\n",
       "      <td>134.418850</td>\n",
       "      <td>0.661163</td>\n",
       "      <td>2.181794</td>\n",
       "      <td>123.738075</td>\n",
       "      <td>152.573730</td>\n",
       "      <td>0.937040</td>\n",
       "      <td>0.937040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>366</td>\n",
       "      <td>190</td>\n",
       "      <td>70</td>\n",
       "      <td>0.806855</td>\n",
       "      <td>138.814380</td>\n",
       "      <td>0.806855</td>\n",
       "      <td>2.339685</td>\n",
       "      <td>128.133480</td>\n",
       "      <td>160.745570</td>\n",
       "      <td>0.932751</td>\n",
       "      <td>0.932751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>386</td>\n",
       "      <td>200</td>\n",
       "      <td>70</td>\n",
       "      <td>0.863849</td>\n",
       "      <td>143.209920</td>\n",
       "      <td>0.863849</td>\n",
       "      <td>2.489892</td>\n",
       "      <td>132.525270</td>\n",
       "      <td>166.351600</td>\n",
       "      <td>0.931587</td>\n",
       "      <td>0.931587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  send rates  block size  latency_pred  throughput_pred  \\\n",
       "200         200         110          10      0.116099        92.969315   \n",
       "222         222         120          30      0.307015       100.925110   \n",
       "242         242         130          30      0.326867       105.320656   \n",
       "266         266         140          70      0.410121       116.836700   \n",
       "286         286         150          70      0.427485       121.232240   \n",
       "306         306         160          70      0.444849       125.627770   \n",
       "326         326         170          70      0.506402       130.023300   \n",
       "346         346         180          70      0.661163       134.418850   \n",
       "366         366         190          70      0.806855       138.814380   \n",
       "386         386         200          70      0.863849       143.209920   \n",
       "\n",
       "     latency_min  latency_max  throughput_min  throughput_max     score  \\\n",
       "200     0.116099     0.824487       92.969315       95.370895  0.900000   \n",
       "222     0.307015     0.866201       97.364850      103.542725  0.957629   \n",
       "242     0.326867     0.896848      101.760390      111.714570  0.935767   \n",
       "266     0.408295     1.135574      106.155940      119.886380  0.975530   \n",
       "286     0.425659     1.488943      110.551470      128.058230  0.959464   \n",
       "306     0.443023     1.719399      114.947014      136.230060  0.948897   \n",
       "326     0.506402     1.949942      119.342545      144.401890  0.942622   \n",
       "346     0.661163     2.181794      123.738075      152.573730  0.937040   \n",
       "366     0.806855     2.339685      128.133480      160.745570  0.932751   \n",
       "386     0.863849     2.489892      132.525270      166.351600  0.931587   \n",
       "\n",
       "     score_max  \n",
       "200   0.900000  \n",
       "222   0.957629  \n",
       "242   0.935767  \n",
       "266   0.975530  \n",
       "286   0.959464  \n",
       "306   0.948897  \n",
       "326   0.942622  \n",
       "346   0.937040  \n",
       "366   0.932751  \n",
       "386   0.931587  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = y_filter[y_filter['score'] == y_filter['score_max']]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "29c00a76",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result.to_csv('./best_block_size_alpha' + str(alpha) + '_beta' + str(beta) + '_related1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "280.281px",
    "left": "1365.86px",
    "top": "537.052px",
    "width": "297.438px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}